{"query": "Joe Rogan and Elon Musk", "clip_length": 2, "selected_index": "LM Dirichlet", "results": [{"Clip Text": "What's up, everyone? I don't know if you're ready for this one, but here we go. So today came across something pretty special. Let's just make this one on. Becoming extraterrestrial <mark>and</mark> curing the uncurable. So this last week I decided you know, hey, I'll take a break. I'll watch a little bit of Netflix, you know. Oh, here we go. My favorite guide The Rock. He's got a new movie out. Hell, yeah, you know The Rock was always been my favorite wrestler since a young child mean my grandpa used to wrestle in the living <mark>and</mark> while we watch WWE, so the Can always been like a legendary character to my life, right? So he's got this new movie out Rampage in rampage this company energyne, you know, that's that's my solid memory right there for you at my super brain. Perfect recall anyways energy <mark>and</mark> they're doing experiments in space <mark>and</mark> shit goes wrong. Their rat turns into a giant monster kills", "Start Time (s)": 1.2, "End Time (s)": 80.8, "Clip Length (min)": 1.33, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Let's just make this one on. Becoming extraterrestrial <mark>and</mark> curing the uncurable. So this last week I decided you know, hey, I'll take a break. I'll watch a little bit of Netflix, you know. Oh, here we go. My favorite guide The Rock. He's got a new movie out. Hell, yeah, you know The Rock was always been my favorite wrestler since a young child mean my grandpa used to wrestle in the living <mark>and</mark> while we watch WWE, so the Can always been like a legendary character to my life, right? So he's got this new movie out Rampage in rampage this company energyne, you know, that's that's my solid memory right there for you at my super brain. Perfect recall anyways energy <mark>and</mark> they're doing experiments in space <mark>and</mark> shit goes wrong. Their rat turns into a giant monster kills everybody in the space station practically kills the girl going up to get the chicks or research. The chick is Bobby axelrod's wife from billions, you know, she's looking way finer <mark>and</mark> not one. She's like, no, you're not coming back down. I'm not unlocking the door until you get my research. So anyways in energy <mark>and</mark> they're exploiting this. It's called. Let's call. Oh. Damn it. I'm thinking so fast. Okay, I just had it in my mind. Okay. Anyways, it's a gene editing technology. So I did a lot gonna find it here. So I did a little bit of research. I looked", "Start Time (s)": 13.8, "End Time (s)": 132.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> shit goes wrong. Their rat turns into a giant monster kills everybody in the space station practically kills the girl going up to get the chicks or research. The chick is Bobby axelrod's wife from billions, you know, she's looking way finer <mark>and</mark> not one. She's like, no, you're not coming back down. I'm not unlocking the door until you get my research. So anyways in energy <mark>and</mark> they're exploiting this. It's called. Let's call. Oh. Damn it. I'm thinking so fast. Okay, I just had it in my mind. Okay. Anyways, it's a gene editing technology. So I did a lot gonna find it here. So I did a little bit of research. I looked it up <mark>and</mark> it's called the Forgive me here. Okay, it's called crispr crispr technology. Okay, <mark>and</mark> what crispr is it's actually real so it's going to get intense here. Crispr is a way to edit RNA which is a virus in order to infect the host to snip out pieces of the genetic code. Okay, all through RNA traditionally genetic modification had to happen through generations, right? I had to be the embryo had to be modified so that it was born with it, right, but now well, yes now, I've done my research <mark>and</mark> actually after doing my research was until what", "Start Time (s)": 75.0, "End Time (s)": 194.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So I did a little bit of research. I looked it up <mark>and</mark> it's called the Forgive me here. Okay, it's called crispr crispr technology. Okay, <mark>and</mark> what crispr is it's actually real so it's going to get intense here. Crispr is a way to edit RNA which is a virus in order to infect the host to snip out pieces of the genetic code. Okay, all through RNA traditionally genetic modification had to happen through generations, right? I had to be the embryo had to be modified so that it was born with it, right, but now well, yes now, I've done my research <mark>and</mark> actually after doing my research was until what five five six days later. I get an Instagram at four. Jean script biotech Corp Instagram knows me. Well, they know just like in my the founding of stratospheric Innovations on medium. If you go check that out under Cody Vandervoort I get into detail about how an ad for Merida cam ended up being the reason that I ended up creating my company because it showed me. Hey, yeah, you can make single trip computer boards because I was like, I broke my computer <mark>and</mark> I was like damn it. How do I make computers? So cheap that I can just buy them. I mean that I can build them to break them, you know, <mark>and</mark> the next thing I know my iPhone is giving me an ad for single board computer that I didn't even know existed, but I was just", "Start Time (s)": 130.0, "End Time (s)": 249.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that it was born with it, right, but now well, yes now, I've done my research <mark>and</mark> actually after doing my research was until what five five six days later. I get an Instagram at four. Jean script biotech Corp Instagram knows me. Well, they know just like in my the founding of stratospheric Innovations on medium. If you go check that out under Cody Vandervoort I get into detail about how an ad for Merida cam ended up being the reason that I ended up creating my company because it showed me. Hey, yeah, you can make single trip computer boards because I was like, I broke my computer <mark>and</mark> I was like damn it. How do I make computers? So cheap that I can just buy them. I mean that I can build them to break them, you know, <mark>and</mark> the next thing I know my iPhone is giving me an ad for single board computer that I didn't even know existed, but I was just like, you know, how do we make this? How do how do we do it iPhone next thing, you know, I get an ad for it, right? So same type of deal here couple years later though. This is pretty cool. a going deeply click the add like any good entrepreneur would do I click the ADD <mark>and</mark> I dig in so like I was saying crispr technology you're able to Create an algorithm through an RNA which is a virus to change the gene map <mark>and</mark> the gene sequence within an organism in the same life cycle. So rather than for example, genetically modified foods that happens over many life cycles.", "Start Time (s)": 181.9, "End Time (s)": 301.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I click the ADD <mark>and</mark> I dig in so like I was saying crispr technology you're able to Create an algorithm through an RNA which is a virus to change the gene map <mark>and</mark> the gene sequence within an organism in the same life cycle. So rather than for example, genetically modified foods that happens over many life cycles. So currently the European Union, they don't want nothing to do with crisper Russia says they didn't want Russia's, you know can't who the fuck knows it doesn't even matter. Okay. All that matters is that us is going in Canada says, you know Canada is not stopping it. That's where I live. That's all that matters. <mark>And</mark> they want to sell me crispr technology right off the top they're like, hey, you don't even know how to do it yet bro, but you know 250 bucks will ship you some some technology so you can you can start screwing around. Okay, so that's That's our needle in the haystack to start now. We're going to thread it through. Okay, so I was watching strong Carol's mindscape really early because today I'm putting together my funnel with like 40 Grand worth of freaking shit, <mark>and</mark> I'm just going to sell it for 20 bucks as a lead magnet to recoup my head spins. So on the back end I can hit you with my 25 Grand coaching program as well as like a $1000 in the $7,000 thing to help you make money <mark>and</mark> anyways, so the front end is just a lead magnet, but it's really like", "Start Time (s)": 268.4, "End Time (s)": 387.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know Canada is not stopping it. That's where I live. That's all that matters. <mark>And</mark> they want to sell me crispr technology right off the top they're like, hey, you don't even know how to do it yet bro, but you know 250 bucks will ship you some some technology so you can you can start screwing around. Okay, so that's That's our needle in the haystack to start now. We're going to thread it through. Okay, so I was watching strong Carol's mindscape really early because today I'm putting together my funnel with like 40 Grand worth of freaking shit, <mark>and</mark> I'm just going to sell it for 20 bucks as a lead magnet to recoup my head spins. So on the back end I can hit you with my 25 Grand coaching program as well as like a $1000 in the $7,000 thing to help you make money <mark>and</mark> anyways, so the front end is just a lead magnet, but it's really like the most intensely magnet ever because everybody else is selling all these individual programs for like thousand dollars plus <mark>and</mark> I'm just going to give way like 40 or 50 of them for 20 bucks. Okay, so it's going to be good. Anyways, putting that together today <mark>and</mark> putting that together last night. <mark>And</mark> fucking stay in back in my mom's garage because I moved back out of the damn Smoke Filled place. I was living for <mark>and</mark> remember I could have bought a Ferrari cash right now. I'm living this way because I chose I didn't I'd Venture Capital five six seven eight times now because I want my mind to be able to run free. Nobody can tell me what to do <mark>and</mark> I don't want to sell a piece of my company because I know I'm Be so much bigger than forgetting", "Start Time (s)": 322.6, "End Time (s)": 441.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as like a $1000 in the $7,000 thing to help you make money <mark>and</mark> anyways, so the front end is just a lead magnet, but it's really like the most intensely magnet ever because everybody else is selling all these individual programs for like thousand dollars plus <mark>and</mark> I'm just going to give way like 40 or 50 of them for 20 bucks. Okay, so it's going to be good. Anyways, putting that together today <mark>and</mark> putting that together last night. <mark>And</mark> fucking stay in back in my mom's garage because I moved back out of the damn Smoke Filled place. I was living for <mark>and</mark> remember I could have bought a Ferrari cash right now. I'm living this way because I chose I didn't I'd Venture Capital five six seven eight times now because I want my mind to be able to run free. Nobody can tell me what to do <mark>and</mark> I don't want to sell a piece of my company because I know I'm Be so much bigger than forgetting my valuation on myself as like a billion dollars or not ready? Like I'm not screwing around so I'm not going to go <mark>and</mark> take 250 grand for 15% of my company. That's a joke, you know, it sounded joke to who are offered it. I'm happy. They're out there to help everybody else. But this it's just not for me, you know, but the coaching program is so that I can help people like you guys on the other end. end We can co-founded a company together. You can go off <mark>and</mark> do the Venture Capital accelerator program get the company going. You can become the CEO of it <mark>and</mark> I'll just help you get it up from the ground up get that cash injected <mark>and</mark> I'll even like give you the idea to start the company <mark>and</mark> tell you everything to do <mark>and</mark> you just have to do it. So that's part of what my coaching program is anyways, so the crispr technology", "Start Time (s)": 377.9, "End Time (s)": 497.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "five six seven eight times now because I want my mind to be able to run free. Nobody can tell me what to do <mark>and</mark> I don't want to sell a piece of my company because I know I'm Be so much bigger than forgetting my valuation on myself as like a billion dollars or not ready? Like I'm not screwing around so I'm not going to go <mark>and</mark> take 250 grand for 15% of my company. That's a joke, you know, it sounded joke to who are offered it. I'm happy. They're out there to help everybody else. But this it's just not for me, you know, but the coaching program is so that I can help people like you guys on the other end. end We can co-founded a company together. You can go off <mark>and</mark> do the Venture Capital accelerator program get the company going. You can become the CEO of it <mark>and</mark> I'll just help you get it up from the ground up get that cash injected <mark>and</mark> I'll even like give you the idea to start the company <mark>and</mark> tell you everything to do <mark>and</mark> you just have to do it. So that's part of what my coaching program is anyways, so the crispr technology I have this disease is called hereditary neuropathy liability to pressure policy <mark>and</mark> we found out we I have this disease <mark>and</mark> my mother has this disease <mark>and</mark> it turns out that 50/50 of her offsprings will end up getting the disease as well, right? So I have two kids one of them probably has this. I'm pretty sure it's my daughter because she's always trying to better freaking likes her <mark>and</mark> shit, which reminds me gives me a good reason of to edit this out. I feel like an evil scientist. Now my mind's been going all over the place do okay. So anyways, um, I'm working on that earlier today <mark>and</mark> I'm like in the cold ass garage. My back's hurting shitty position on the table due to the fact that the", "Start Time (s)": 429.5, "End Time (s)": 548.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from the ground up get that cash injected <mark>and</mark> I'll even like give you the idea to start the company <mark>and</mark> tell you everything to do <mark>and</mark> you just have to do it. So that's part of what my coaching program is anyways, so the crispr technology I have this disease is called hereditary neuropathy liability to pressure policy <mark>and</mark> we found out we I have this disease <mark>and</mark> my mother has this disease <mark>and</mark> it turns out that 50/50 of her offsprings will end up getting the disease as well, right? So I have two kids one of them probably has this. I'm pretty sure it's my daughter because she's always trying to better freaking likes her <mark>and</mark> shit, which reminds me gives me a good reason of to edit this out. I feel like an evil scientist. Now my mind's been going all over the place do okay. So anyways, um, I'm working on that earlier today <mark>and</mark> I'm like in the cold ass garage. My back's hurting shitty position on the table due to the fact that the computer that broke that made me start my company. I ended up going to open it because I trashed my my little blue HP, which needed a Revival needed me to make a boot drive <mark>and</mark> literally no one would give me or even come see me for like a month to make me a boot drive. So I'm like stuck with their computer <mark>and</mark> I'm trying to do all these giant things. This is like September October so I'm like, okay desperate <mark>and</mark> I'm like, you know, you could have said I might as well been insane because I was like, okay. Well, I'm just going to see if my broken computer works I go I plug it in <mark>and</mark> it works, you know, <mark>and</mark> I'm pretty sure it was just because I unscrewed everything <mark>and</mark> I loosened up the power cable on the inside which ended up just making a connection <mark>and</mark> it ended up", "Start Time (s)": 480.9, "End Time (s)": 600.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "evil scientist. Now my mind's been going all over the place do okay. So anyways, um, I'm working on that earlier today <mark>and</mark> I'm like in the cold ass garage. My back's hurting shitty position on the table due to the fact that the computer that broke that made me start my company. I ended up going to open it because I trashed my my little blue HP, which needed a Revival needed me to make a boot drive <mark>and</mark> literally no one would give me or even come see me for like a month to make me a boot drive. So I'm like stuck with their computer <mark>and</mark> I'm trying to do all these giant things. This is like September October so I'm like, okay desperate <mark>and</mark> I'm like, you know, you could have said I might as well been insane because I was like, okay. Well, I'm just going to see if my broken computer works I go I plug it in <mark>and</mark> it works, you know, <mark>and</mark> I'm pretty sure it was just because I unscrewed everything <mark>and</mark> I loosened up the power cable on the inside which ended up just making a connection <mark>and</mark> it ended up charging so I could make the boot. Brought the other computer back to live anyway, so oh that was that was gross. I'm sorry anyways, so it was kind of working real fidgety though up until this weekend. I had to like move around the house. Because my step dad comes back he wants to go in his dojo here the garage. <mark>And</mark> my mom's at making me fucking move around the house <mark>and</mark> doing dumb shit. Can't sit no more. No worries my spot. So I'm moving around <mark>and</mark> moving around with my computer. <mark>And</mark> the reason I use this computer is because my other one only has you know, by the time you put the hardware on is Earth. No, the computer is the hardware by the time you put Windows on software", "Start Time (s)": 532.1, "End Time (s)": 652.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> it ended up charging so I could make the boot. Brought the other computer back to live anyway, so oh that was that was gross. I'm sorry anyways, so it was kind of working real fidgety though up until this weekend. I had to like move around the house. Because my step dad comes back he wants to go in his dojo here the garage. <mark>And</mark> my mom's at making me fucking move around the house <mark>and</mark> doing dumb shit. Can't sit no more. No worries my spot. So I'm moving around <mark>and</mark> moving around with my computer. <mark>And</mark> the reason I use this computer is because my other one only has you know, by the time you put the hardware on is Earth. No, the computer is the hardware by the time you put Windows on software with the operating system the OS it's only got like seven games left <mark>and</mark> they you touch a couple things <mark>and</mark> then boom you got like two three gigs left do something else wrong. You got no space left on the damn thing. Okay, <mark>and</mark> then that's why I tried to reset it. So I could have space on every time I've tried to reset it so far, which I did again last week the whole thing crashes, right <mark>and</mark> then Needs a boot drive. So got a boot off the other one. Anyways, the reason I had to watch on Carol's mindscape was because I got it on the table here in the garage as shitty position <mark>and</mark> I can't move it around now because the computer ended up breaking <mark>and</mark> now it's like, you know, maybe I'll upload the picture to Instagram of how Jimmy rigged it is. Like literally had me on my knees. Just praying praying to nobody just myself. L for fuck sakes that the computer wouldn't break. So I got like the power the in internal power jack in there is like on the", "Start Time (s)": 599.6, "End Time (s)": 718.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you touch a couple things <mark>and</mark> then boom you got like two three gigs left do something else wrong. You got no space left on the damn thing. Okay, <mark>and</mark> then that's why I tried to reset it. So I could have space on every time I've tried to reset it so far, which I did again last week the whole thing crashes, right <mark>and</mark> then Needs a boot drive. So got a boot off the other one. Anyways, the reason I had to watch on Carol's mindscape was because I got it on the table here in the garage as shitty position <mark>and</mark> I can't move it around now because the computer ended up breaking <mark>and</mark> now it's like, you know, maybe I'll upload the picture to Instagram of how Jimmy rigged it is. Like literally had me on my knees. Just praying praying to nobody just myself. L for fuck sakes that the computer wouldn't break. So I got like the power the in internal power jack in there is like on the side <mark>and</mark> literally like it's so Jimmy rigged that the the keyboards like popped right off <mark>and</mark> you can't move it or it's not going to charge <mark>and</mark> it's not going to turn back on but this thing has like a terabyte <mark>and</mark> it's I needed to work <mark>and</mark> I've been playing Destiny on it have I made that? Call on medium about cross cross playing between work <mark>and</mark> play <mark>and</mark> making across associations because it really helps if you make it on the same machine you. No, the only reason that I decided to do this cross Association as because I kind of came up with this Epiphany after watching Evan Carmichael's YouTube channel because it's all about entrepreneurial motivation <mark>and</mark> he's got like Tony Robbins all these Mark Cuban Jeff Bezos all at the beginning of their career when they're just young <mark>and</mark> they're like just talking when they're just starting out <mark>and</mark> shit <mark>and</mark> it's like real inspiring. So", "Start Time (s)": 660.1, "End Time (s)": 779.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like the power the in internal power jack in there is like on the side <mark>and</mark> literally like it's so Jimmy rigged that the the keyboards like popped right off <mark>and</mark> you can't move it or it's not going to charge <mark>and</mark> it's not going to turn back on but this thing has like a terabyte <mark>and</mark> it's I needed to work <mark>and</mark> I've been playing Destiny on it have I made that? Call on medium about cross cross playing between work <mark>and</mark> play <mark>and</mark> making across associations because it really helps if you make it on the same machine you. No, the only reason that I decided to do this cross Association as because I kind of came up with this Epiphany after watching Evan Carmichael's YouTube channel because it's all about entrepreneurial motivation <mark>and</mark> he's got like Tony Robbins all these Mark Cuban Jeff Bezos all at the beginning of their career when they're just young <mark>and</mark> they're like just talking when they're just starting out <mark>and</mark> shit <mark>and</mark> it's like real inspiring. So Jeff Bezos is like, yeah. Couple things that are recall from that is Jeffy. So this is like, oh it's so it's 1995 the year before I was born. He's like, it's so hard to buy people's attention these days <mark>and</mark> you know, it's not it's harder than ever to get people's attention. <mark>And</mark> so it's really hard to get people on the internet to buy my books <mark>and</mark> stuff. So it's a difficult challenge but we're working it away <mark>and</mark> I was like well has life ever changed. All I do is click on that <mark>and</mark> then the next thing is like I'm so we've got all these computers in the office <mark>and</mark> you know, the employees don't actually do work on the computers. They mostly just play games. So a few months later, I'm like Maybe I should just play games on my computer here. Don't", "Start Time (s)": 713.6, "End Time (s)": 833.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "out <mark>and</mark> shit <mark>and</mark> it's like real inspiring. So Jeff Bezos is like, yeah. Couple things that are recall from that is Jeffy. So this is like, oh it's so it's 1995 the year before I was born. He's like, it's so hard to buy people's attention these days <mark>and</mark> you know, it's not it's harder than ever to get people's attention. <mark>And</mark> so it's really hard to get people on the internet to buy my books <mark>and</mark> stuff. So it's a difficult challenge but we're working it away <mark>and</mark> I was like well has life ever changed. All I do is click on that <mark>and</mark> then the next thing is like I'm so we've got all these computers in the office <mark>and</mark> you know, the employees don't actually do work on the computers. They mostly just play games. So a few months later, I'm like Maybe I should just play games on my computer here. Don't make me work harder. I used to love playing games. <mark>And</mark> you know, I never went to sleep. All I did was play games. Some of my baby. Mama was pregnant with my kid. I'm like fuck that. I'm going to bed. I play my game do a little cooking. You know those were the days. So <mark>and</mark> my son, he's 5 years old <mark>and</mark> he's like literally he looks like <mark>Joe</mark> <mark>Rogan</mark> when he plays for tonight with his fucking forehead is hilariously the kids. So focused my little brother, he's for like he's six months younger than my son <mark>and</mark> he's ripping to but his forehead doesn't Flex as hard as funny but they both RIP just as hard as ever my little brother can't really talk <mark>and</mark> my son. He's like affluent teenager <mark>and</mark> he's just like Flex <mark>and</mark> so hard so I'm I was playing trying to play Fortnight, but I could only get like halfway through a game where like a through a game <mark>and</mark> I'd run out of ammo can shoot anybody <mark>and</mark> be stupid <mark>and</mark> I'm like, this is Dom. I don't like for it night for a night for kids.", "Start Time (s)": 776.7, "End Time (s)": 896.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a few months later, I'm like Maybe I should just play games on my computer here. Don't make me work harder. I used to love playing games. <mark>And</mark> you know, I never went to sleep. All I did was play games. Some of my baby. Mama was pregnant with my kid. I'm like fuck that. I'm going to bed. I play my game do a little cooking. You know those were the days. So <mark>and</mark> my son, he's 5 years old <mark>and</mark> he's like literally he looks like <mark>Joe</mark> <mark>Rogan</mark> when he plays for tonight with his fucking forehead is hilariously the kids. So focused my little brother, he's for like he's six months younger than my son <mark>and</mark> he's ripping to but his forehead doesn't Flex as hard as funny but they both RIP just as hard as ever my little brother can't really talk <mark>and</mark> my son. He's like affluent teenager <mark>and</mark> he's just like Flex <mark>and</mark> so hard so I'm I was playing trying to play Fortnight, but I could only get like halfway through a game where like a through a game <mark>and</mark> I'd run out of ammo can shoot anybody <mark>and</mark> be stupid <mark>and</mark> I'm like, this is Dom. I don't like for it night for a night for kids. So I never liked it. But I was like going to play it one time. So it's going to open Steam. This is like two weeks ago three weeks ago <mark>and</mark> I was just over at smoke-filled fucking place <mark>and</mark> I was like, I gotta go to find this key right now open up <mark>and</mark> it's like like it shows Destiny. Okay last year, but Destiny on the Xbox 420 fucking nine dollars. The new Destiny Okay, <mark>and</mark> then ended up hockey my Xbox in the summertime so I could buy some ads for clickfunnels <mark>and</mark> I didn't even spend the money on clickfunnels ads. I like lost it on the foreign exchange because bigger opportunity that anyways, I seen that's me. I'm like you're fucking kidding me. It's on PC <mark>and</mark> it was free. So I was like, okay right on then I get it all <mark>and</mark> it's like hey, you can do cross play. So it was like my maxed out", "Start Time (s)": 829.6, "End Time (s)": 949.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Flex <mark>and</mark> so hard so I'm I was playing trying to play Fortnight, but I could only get like halfway through a game where like a through a game <mark>and</mark> I'd run out of ammo can shoot anybody <mark>and</mark> be stupid <mark>and</mark> I'm like, this is Dom. I don't like for it night for a night for kids. So I never liked it. But I was like going to play it one time. So it's going to open Steam. This is like two weeks ago three weeks ago <mark>and</mark> I was just over at smoke-filled fucking place <mark>and</mark> I was like, I gotta go to find this key right now open up <mark>and</mark> it's like like it shows Destiny. Okay last year, but Destiny on the Xbox 420 fucking nine dollars. The new Destiny Okay, <mark>and</mark> then ended up hockey my Xbox in the summertime so I could buy some ads for clickfunnels <mark>and</mark> I didn't even spend the money on clickfunnels ads. I like lost it on the foreign exchange because bigger opportunity that anyways, I seen that's me. I'm like you're fucking kidding me. It's on PC <mark>and</mark> it was free. So I was like, okay right on then I get it all <mark>and</mark> it's like hey, you can do cross play. So it was like my maxed out character from previously it let me even put it right onto the PC with all my shit that I bought from $429 games. I'm like dope Destiny was Favorite game like it Destiny to came last year. I don't know whatever <mark>and</mark> I already had Destiny one. It was like best gaming world because what you do is like you're literally flying around in solar system just fighting off the void aliens <mark>and</mark> shit anyways back to the plot so I could move around. I'm sitting at the table much. <mark>And</mark> I'm like, okay, my back's hurting. I'm just gonna lie down. I'm gonna have an app here on the couch. I was gonna throw on Netflix <mark>and</mark> I was like nah, you know, Sean Carroll. Okay, Sean Carroll was like on the YouTube homepage <mark>and</mark> I'm like, yeah Sean Carroll.", "Start Time (s)": 882.1, "End Time (s)": 1001.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because bigger opportunity that anyways, I seen that's me. I'm like you're fucking kidding me. It's on PC <mark>and</mark> it was free. So I was like, okay right on then I get it all <mark>and</mark> it's like hey, you can do cross play. So it was like my maxed out character from previously it let me even put it right onto the PC with all my shit that I bought from $429 games. I'm like dope Destiny was Favorite game like it Destiny to came last year. I don't know whatever <mark>and</mark> I already had Destiny one. It was like best gaming world because what you do is like you're literally flying around in solar system just fighting off the void aliens <mark>and</mark> shit anyways back to the plot so I could move around. I'm sitting at the table much. <mark>And</mark> I'm like, okay, my back's hurting. I'm just gonna lie down. I'm gonna have an app here on the couch. I was gonna throw on Netflix <mark>and</mark> I was like nah, you know, Sean Carroll. Okay, Sean Carroll was like on the YouTube homepage <mark>and</mark> I'm like, yeah Sean Carroll. So I I think I made a story on Instagram, but about this earlier. Let's Lord Martin something. Okay. He's actually from the House of Lords. He's actually a Lord that you votes in like that the England that you know royal family, okay a real lord <mark>and</mark> he is also a cosmologist <mark>and</mark> a high-energy physicist <mark>and</mark> there on the on the show is Sean Carroll <mark>and</mark> literally little the most insightful thing. They had to say was what I fucking posted on Twitter last week about Quantum hardwood. I was like once Quantum computation works at we have a million cubits <mark>and</mark> we're able to do just run an algorithm on the quantum computer that can make us superconductors that work at", "Start Time (s)": 934.9, "End Time (s)": 1052.6, "Clip Length (min)": 1.96, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>And</mark> I'm like, okay, my back's hurting. I'm just gonna lie down. I'm gonna have an app here on the couch. I was gonna throw on Netflix <mark>and</mark> I was like nah, you know, Sean Carroll. Okay, Sean Carroll was like on the YouTube homepage <mark>and</mark> I'm like, yeah Sean Carroll. So I I think I made a story on Instagram, but about this earlier. Let's Lord Martin something. Okay. He's actually from the House of Lords. He's actually a Lord that you votes in like that the England that you know royal family, okay a real lord <mark>and</mark> he is also a cosmologist <mark>and</mark> a high-energy physicist <mark>and</mark> there on the on the show is Sean Carroll <mark>and</mark> literally little the most insightful thing. They had to say was what I fucking posted on Twitter last week about Quantum hardwood. I was like once Quantum computation works at we have a million cubits <mark>and</mark> we're able to do just run an algorithm on the quantum computer that can make us superconductors that work at room temperature <mark>and</mark> he didn't even go on to he was like that'll be the coolest thing we can do <mark>and</mark> I was like, then we'll be able to have perpetual motion machines that just fly around <mark>and</mark> like UFOs like yeah, we will literally be able have perpetual motion machine say tie into the Earth's gravity <mark>and</mark> can't crash which we so poor dope. So just be like Operating a the in the Z plane the Z Dimension <mark>and</mark> they won't crash because it's not Newtonian physics. It's quantum physics don't write anyway, so that was like really insightful thing that had to say <mark>and</mark> then the rest of it was just talk <mark>and</mark> it was all talk about catastrophic events as well as extraterrestrial beings whether they're out", "Start Time (s)": 985.7, "End Time (s)": 1104.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "UFOs like yeah, we will literally be able have perpetual motion machine say tie into the Earth's gravity <mark>and</mark> can't crash which we so poor dope. So just be like Operating a the in the Z plane the Z Dimension <mark>and</mark> they won't crash because it's not Newtonian physics. It's quantum physics don't write anyway, so that was like really insightful thing that had to say <mark>and</mark> then the rest of it was just talk <mark>and</mark> it was all talk about catastrophic events as well as extraterrestrial beings whether they're out there as Well as post human existence, so this is where we're threading the needle through here now guys. the posthuman existence so the Lord he's like <mark>Elon</mark> Musk, you know, I wish them all the power to us or other power to him <mark>and</mark> people just like him all these Adventures because they're the ones who are going to discover post humanism. <mark>And</mark> this was because Once we get to Mars per se. That it's not going to be convenient to move around. We're gonna have to have intense space suits excetera. or we can modify ourselves so that we could move around on the surface of Mars without housing space suits <mark>and</mark> such <mark>and</mark> they were like, oh that doesn't make much sense to genetically modify its at the moment on Earth, you know, it's kind of illegal in many ways <mark>and</mark> you know there apparently there was like one researcher in", "Start Time (s)": 1062.8, "End Time (s)": 1181.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "existence so the Lord he's like <mark>Elon</mark> Musk, you know, I wish them all the power to us or other power to him <mark>and</mark> people just like him all these Adventures because they're the ones who are going to discover post humanism. <mark>And</mark> this was because Once we get to Mars per se. That it's not going to be convenient to move around. We're gonna have to have intense space suits excetera. or we can modify ourselves so that we could move around on the surface of Mars without housing space suits <mark>and</mark> such <mark>and</mark> they were like, oh that doesn't make much sense to genetically modify its at the moment on Earth, you know, it's kind of illegal in many ways <mark>and</mark> you know there apparently there was like one researcher in China who publicly Try to do some genetically modified stuff too, like a human embryo or whatever <mark>and</mark> got put in jail <mark>and</mark> stuff like that. So that came up to their kind of talking about how it's not ethical. It's kind of like the it's in a box <mark>and</mark> Sean Carroll was like, well, what about you know, like it it's kind of like cyber security <mark>and</mark> the stuff is like in a box either you get is taken out were She's going to figure out how to do it anyways. <mark>And</mark> then it's going to be over the Box either way. So shoot me like just get it under control. So the good team wins more or less. Right? <mark>And</mark> then there was just kind of like well, no, it should just suppress it all into the box <mark>and</mark> then or not but then the argument K <mark>and</mark> but", "Start Time (s)": 1117.1, "End Time (s)": 1237.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "modify its at the moment on Earth, you know, it's kind of illegal in many ways <mark>and</mark> you know there apparently there was like one researcher in China who publicly Try to do some genetically modified stuff too, like a human embryo or whatever <mark>and</mark> got put in jail <mark>and</mark> stuff like that. So that came up to their kind of talking about how it's not ethical. It's kind of like the it's in a box <mark>and</mark> Sean Carroll was like, well, what about you know, like it it's kind of like cyber security <mark>and</mark> the stuff is like in a box either you get is taken out were She's going to figure out how to do it anyways. <mark>And</mark> then it's going to be over the Box either way. So shoot me like just get it under control. So the good team wins more or less. Right? <mark>And</mark> then there was just kind of like well, no, it should just suppress it all into the box <mark>and</mark> then or not but then the argument K <mark>and</mark> but on Mars, then it's free reign. This is where it should happen due to the fact that it's going to be a pain in the ass to make biospheres <mark>and</mark> such rather. If we just transformed into electrical beings then we won't have to worry about having biospheres on Mars. We could just create it turn into cyborgs Etc. But then it came. Oh, well, if we're cyborgs <mark>and</mark> electrical beings then we don't need to stay on the planet right? We can be Interstellar Travelers. We can fly in space for just made out of Electronics many came up. All right, Chris. Well, you know not trying to upload the Consciousness <mark>and</mark> then no but when we would we not be", "Start Time (s)": 1169.0, "End Time (s)": 1288.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So the good team wins more or less. Right? <mark>And</mark> then there was just kind of like well, no, it should just suppress it all into the box <mark>and</mark> then or not but then the argument K <mark>and</mark> but on Mars, then it's free reign. This is where it should happen due to the fact that it's going to be a pain in the ass to make biospheres <mark>and</mark> such rather. If we just transformed into electrical beings then we won't have to worry about having biospheres on Mars. We could just create it turn into cyborgs Etc. But then it came. Oh, well, if we're cyborgs <mark>and</mark> electrical beings then we don't need to stay on the planet right? We can be Interstellar Travelers. We can fly in space for just made out of Electronics many came up. All right, Chris. Well, you know not trying to upload the Consciousness <mark>and</mark> then no but when we would we not be human anymore because we'll be you know, we feel the way that we feel do the way there the fact that our bodies feel certain ways, which makes us feel certain ways, right? So this well would we technically be who we are if we are uploaded ourselves to the cloud <mark>and</mark> then make multiple Loans for ourselves, we wouldn't technically be who we are now, but let's just get over the fact that that's who we want to be right who wants to be stuck in a human body that dies. That's like that's not love. Okay love is for forever death is unloving. So that was before I Cry came across the crisper. You know, I must have been listening to the podcast my phone heard me ha ha Facebook heard it <mark>and</mark> I was like, okay", "Start Time (s)": 1225.4, "End Time (s)": 1345.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "upload the Consciousness <mark>and</mark> then no but when we would we not be human anymore because we'll be you know, we feel the way that we feel do the way there the fact that our bodies feel certain ways, which makes us feel certain ways, right? So this well would we technically be who we are if we are uploaded ourselves to the cloud <mark>and</mark> then make multiple Loans for ourselves, we wouldn't technically be who we are now, but let's just get over the fact that that's who we want to be right who wants to be stuck in a human body that dies. That's like that's not love. Okay love is for forever death is unloving. So that was before I Cry came across the crisper. You know, I must have been listening to the podcast my phone heard me ha ha Facebook heard it <mark>and</mark> I was like, okay Cody's ready so that they shoot me over the crisper website <mark>and</mark> how it you know, they got a podcast but I only watched like or listen to the first episode which literally has no rating. So I threw a five star Crispr technology is only without for like four years. Anyways in Rampage a month. I'll just explain the movie because it will be able to wrap your head around it better. So they they edit these r as so that they're able to like grow super strong they're able to just grow so fast <mark>and</mark> the on re-entry like one of the rats is a big monster the space station scratches the the Escape. Shuttle, <mark>and</mark> it makes a crash landing into orbit, but luckily like the girl ends up dying, but luckily the the research", "Start Time (s)": 1284.2, "End Time (s)": 1403.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "came across the crisper. You know, I must have been listening to the podcast my phone heard me ha ha Facebook heard it <mark>and</mark> I was like, okay Cody's ready so that they shoot me over the crisper website <mark>and</mark> how it you know, they got a podcast but I only watched like or listen to the first episode which literally has no rating. So I threw a five star Crispr technology is only without for like four years. Anyways in Rampage a month. I'll just explain the movie because it will be able to wrap your head around it better. So they they edit these r as so that they're able to like grow super strong they're able to just grow so fast <mark>and</mark> the on re-entry like one of the rats is a big monster the space station scratches the the Escape. Shuttle, <mark>and</mark> it makes a crash landing into orbit, but luckily like the girl ends up dying, but luckily the the research pods were made so that the group Clash land into orbit. So they clack crash-land into like into one spot. It's like a guerrilla Retreat where the rock is right <mark>and</mark> it turns his favorite monkey or gorilla albino. Gorilla do it beats practically, right? <mark>And</mark> then it has a The one thing is so there are a few things are edited in. Well, I'll start off with more or less the characters. There's a gorilla <mark>and</mark> then there's a wolf <mark>and</mark> there is like a crocodile. Okay, <mark>and</mark> they all get like they all start drone super fast, you know, like doubles the size <mark>and</mark> the day <mark>and</mark> they're practically invincible <mark>and</mark> then they're also full of rage", "Start Time (s)": 1335.5, "End Time (s)": 1454.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the space station scratches the the Escape. Shuttle, <mark>and</mark> it makes a crash landing into orbit, but luckily like the girl ends up dying, but luckily the the research pods were made so that the group Clash land into orbit. So they clack crash-land into like into one spot. It's like a guerrilla Retreat where the rock is right <mark>and</mark> it turns his favorite monkey or gorilla albino. Gorilla do it beats practically, right? <mark>And</mark> then it has a The one thing is so there are a few things are edited in. Well, I'll start off with more or less the characters. There's a gorilla <mark>and</mark> then there's a wolf <mark>and</mark> there is like a crocodile. Okay, <mark>and</mark> they all get like they all start drone super fast, you know, like doubles the size <mark>and</mark> the day <mark>and</mark> they're practically invincible <mark>and</mark> then they're also full of rage <mark>and</mark> they have this bat sonar built into them. Which is like covid-19 bats what they got nothing nothing. Okay, apparently covid-19 came because people are eating bats. yeah, anyways, so they got the bats owner edited into their genes so that energy in the company who made it all could call these creatures once they're made with a giant radio tower so that the Army could come <mark>and</mark> kill the monsters <mark>and</mark> then they could harvest the DNA <mark>and</mark> then they could Sell it as weaponized technology, right? So we got a good bat sonar <mark>and</mark> they", "Start Time (s)": 1390.1, "End Time (s)": 1509.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> there is like a crocodile. Okay, <mark>and</mark> they all get like they all start drone super fast, you know, like doubles the size <mark>and</mark> the day <mark>and</mark> they're practically invincible <mark>and</mark> then they're also full of rage <mark>and</mark> they have this bat sonar built into them. Which is like covid-19 bats what they got nothing nothing. Okay, apparently covid-19 came because people are eating bats. yeah, anyways, so they got the bats owner edited into their genes so that energy in the company who made it all could call these creatures once they're made with a giant radio tower so that the Army could come <mark>and</mark> kill the monsters <mark>and</mark> then they could harvest the DNA <mark>and</mark> then they could Sell it as weaponized technology, right? So we got a good bat sonar <mark>and</mark> they made this machine that they could call these monsters from far away. So anyways crispr is real technology. I'm like I'm watching a movie I Google it like any good scientist would do. Probably only going on Earth did that <mark>and</mark> anyways crispr is like a virus. Okay, it's see you make it yourself nor me. I could make it myself. I know how do you know? She's have to read a book on actually doing like the lab work they could do it anyway, so I got this incurable disease called hereditary neuropathy, but liability pressure policy <mark>and</mark> I figured it", "Start Time (s)": 1441.9, "End Time (s)": 1560.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the DNA <mark>and</mark> then they could Sell it as weaponized technology, right? So we got a good bat sonar <mark>and</mark> they made this machine that they could call these monsters from far away. So anyways crispr is real technology. I'm like I'm watching a movie I Google it like any good scientist would do. Probably only going on Earth did that <mark>and</mark> anyways crispr is like a virus. Okay, it's see you make it yourself nor me. I could make it myself. I know how do you know? She's have to read a book on actually doing like the lab work they could do it anyway, so I got this incurable disease called hereditary neuropathy, but liability pressure policy <mark>and</mark> I figured it out because I got really drunk <mark>and</mark> my friend's party <mark>and</mark> I blacked out <mark>and</mark> I woke up on the floor <mark>and</mark> I couldn't move my foot. I was paralyzed. Okay this retired I was literally, you know couldn't I couldn't I could push my foot down, but I couldn't lift it up like if I wanted to like. Like kick a soccer ball. I couldn't if it's like a dead foot. It's called drop foot <mark>and</mark> then they comments about that. Oh, my mom had happened to her when she was 20 as well. We go to the doctor. he's like, yeah, you got drop foot <mark>and</mark> it's from neuropathy, which is paralysis of the nerves <mark>And</mark> you know, that was terrible. They're like, yeah, we don't even know why this happened other than the fact that neuropathy is like your old", "Start Time (s)": 1500.0, "End Time (s)": 1619.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "floor <mark>and</mark> I couldn't move my foot. I was paralyzed. Okay this retired I was literally, you know couldn't I couldn't I could push my foot down, but I couldn't lift it up like if I wanted to like. Like kick a soccer ball. I couldn't if it's like a dead foot. It's called drop foot <mark>and</mark> then they comments about that. Oh, my mom had happened to her when she was 20 as well. We go to the doctor. he's like, yeah, you got drop foot <mark>and</mark> it's from neuropathy, which is paralysis of the nerves <mark>And</mark> you know, that was terrible. They're like, yeah, we don't even know why this happened other than the fact that neuropathy is like your old house with old wires. Everybody else is brand-new <mark>and</mark> you're in the you're in the break room, <mark>and</mark> I know you're flipping a light switch on <mark>and</mark> off <mark>and</mark> your Breakers are blowing. You know, that's what happens. He drinks. It's like flipping the light on <mark>and</mark> off <mark>and</mark> on <mark>and</mark> off not enough to break it blows. So that's what happened to me in the breaker blue <mark>and</mark> couldn't move my leg, you know even happen. I think not that long ago. I was drinking out my friend test can happen again, but not as bad this time because I like got some insane meditation going on. I can just heal myself overnight. But anybody else in my family doesn't have freaking time for meditation like child. Can't figure it out my mom. Don't give a shit can't cure it so. Me <mark>and</mark> Mom figure out we both got this so we go for genetic testing <mark>and</mark> they test us <mark>and</mark> I like go to Toronto General Hospital <mark>and</mark> there's only like a thousand people. It's like one in a hundred thousand", "Start Time (s)": 1565.5, "End Time (s)": 1685.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "neuropathy is like your old house with old wires. Everybody else is brand-new <mark>and</mark> you're in the you're in the break room, <mark>and</mark> I know you're flipping a light switch on <mark>and</mark> off <mark>and</mark> your Breakers are blowing. You know, that's what happens. He drinks. It's like flipping the light on <mark>and</mark> off <mark>and</mark> on <mark>and</mark> off not enough to break it blows. So that's what happened to me in the breaker blue <mark>and</mark> couldn't move my leg, you know even happen. I think not that long ago. I was drinking out my friend test can happen again, but not as bad this time because I like got some insane meditation going on. I can just heal myself overnight. But anybody else in my family doesn't have freaking time for meditation like child. Can't figure it out my mom. Don't give a shit can't cure it so. Me <mark>and</mark> Mom figure out we both got this so we go for genetic testing <mark>and</mark> they test us <mark>and</mark> I like go to Toronto General Hospital <mark>and</mark> there's only like a thousand people. It's like one in a hundred thousand this disease, right which is pretty rare. Therefore. There's no reason to fight a cure. Until now till I was born <mark>and</mark> I so practically found a cure for the incurable because I can now create the mutation out of RNA virus <mark>and</mark> then in fact myself with it first. Like first generation, it can be cured rather than having to put it into my embryo when I'm having a child next. Yeah, I could just cure myself. Then the next her have her child. The gene is edited out of my system. But here's where it gets funny.", "Start Time (s)": 1616.6, "End Time (s)": 1735.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in fact myself with it first. Like first generation, it can be cured rather than having to put it into my embryo when I'm having a child next. Yeah, I could just cure myself. Then the next her have her child. The gene is edited out of my system. But here's where it gets funny. Here's where we go to Wacky town with this, you know if we can do that. Then how far can we go with posthumanism? No, genetically modifying stuff or like GMO is illegal, but crispr technology, isn't this is a loophole. Because it's not screwing as embryos. It's screwing with organisms that are alive <mark>and</mark> well, so I'm listening to the podcast <mark>and</mark> one of the like the first one from 2018. I'm sure by next time. I'll have to excuse me a whole bunch more information on how crazy we can get with it. But I think my mom's pretty good at I don't know like what for some reason I mind is able to come up with like the most insane. Ovaries before even crossed paths with somebody else that are is like actually working on it. So, you know, my mind is most powerful tool on Earth <mark>and</mark> believe Because that was like your grandpa, I'm gonna figure out a way to live for forever. I'm going to put my brain inside some other animal or whatever it so I can live for forever. We'll figure it out. We'll do it the back burn Whatever Whatever It Takes it'll happen. <mark>And</mark> then two years later Ray Kurzweil is like we're living for forever after I read this book, you know, could I read the book before but I read books back when I had these you", "Start Time (s)": 1709.4, "End Time (s)": 1828.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this is a loophole. Because it's not screwing as embryos. It's screwing with organisms that are alive <mark>and</mark> well, so I'm listening to the podcast <mark>and</mark> one of the like the first one from 2018. I'm sure by next time. I'll have to excuse me a whole bunch more information on how crazy we can get with it. But I think my mom's pretty good at I don't know like what for some reason I mind is able to come up with like the most insane. Ovaries before even crossed paths with somebody else that are is like actually working on it. So, you know, my mind is most powerful tool on Earth <mark>and</mark> believe Because that was like your grandpa, I'm gonna figure out a way to live for forever. I'm going to put my brain inside some other animal or whatever it so I can live for forever. We'll figure it out. We'll do it the back burn Whatever Whatever It Takes it'll happen. <mark>And</mark> then two years later Ray Kurzweil is like we're living for forever after I read this book, you know, could I read the book before but I read books back when I had these you start so post humanism. Where shall I begin? What started off easy? Okay. So we start curing the incurable diseases first generation before they get to the embryo. All it is is it's it's just like activating parts of your DNA that's already in you or editing pieces out. So maybe like editing out the HPP already trained with neuropathy with liability to pressure policy. But the see there's just a thing I could like. I already have optic neuropathy my right arm blind in my right eye <mark>and</mark> they're like yo that was from yours. He's probably but then I read another", "Start Time (s)": 1759.5, "End Time (s)": 1878.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Whatever It Takes it'll happen. <mark>And</mark> then two years later Ray Kurzweil is like we're living for forever after I read this book, you know, could I read the book before but I read books back when I had these you start so post humanism. Where shall I begin? What started off easy? Okay. So we start curing the incurable diseases first generation before they get to the embryo. All it is is it's it's just like activating parts of your DNA that's already in you or editing pieces out. So maybe like editing out the HPP already trained with neuropathy with liability to pressure policy. But the see there's just a thing I could like. I already have optic neuropathy my right arm blind in my right eye <mark>and</mark> they're like yo that was from yours. He's probably but then I read another book. That's like yo your the Insight part of your brain. Well rewire itself in the right occipital lobe. I don't know I guess if your body comes under certain circumstances <mark>and</mark> it's like hey in sight sir more valuable at this time <mark>and</mark> life van. Your right eye <mark>and</mark> it only happens to the right eye. It's quite interesting. So. Which is also around the time of the founding of stratospheric Innovations, believe it or not. before it so optic so I could become like totally paralyzed. I could be like paraplegic if shit went wrong, you know, I could become paralyzed right from the brainstem if", "Start Time (s)": 1814.8, "End Time (s)": 1934.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Your right eye <mark>and</mark> it only happens to the right eye. It's quite interesting. So. Which is also around the time of the founding of stratospheric Innovations, believe it or not. before it so optic so I could become like totally paralyzed. I could be like paraplegic if shit went wrong, you know, I could become paralyzed right from the brainstem if she got pinched. So what it is pressure policy means that if the nerve gets pinched nerve paralysis could happen or will happen in this happened multiple times. I could I had a really bad head injury, which I ended up getting my head pushed back into place to release the pressure off my brain to get the toxins out excetera. You can go back <mark>and</mark> read my blog talked about it not could have been the pressure palsy on the optic nerve. So I could become totally paralyzed <mark>and</mark> I'd be a good reason to edit this mutation out. Because apparently it was most likely a mutation from my one of my mum's born this disease. It's that's 100,000 because nobody else in my family has ever had anything like that happen to them. The neuropathy <mark>and</mark> it makes tennis elbow carpal tunnel anything like that. Those are just symptoms of the disease. I have, you know, put my meditative practices in my exercise routines <mark>and</mark> such if allowed me to really", "Start Time (s)": 1899.8, "End Time (s)": 2018.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to get the toxins out excetera. You can go back <mark>and</mark> read my blog talked about it not could have been the pressure palsy on the optic nerve. So I could become totally paralyzed <mark>and</mark> I'd be a good reason to edit this mutation out. Because apparently it was most likely a mutation from my one of my mum's born this disease. It's that's 100,000 because nobody else in my family has ever had anything like that happen to them. The neuropathy <mark>and</mark> it makes tennis elbow carpal tunnel anything like that. Those are just symptoms of the disease. I have, you know, put my meditative practices in my exercise routines <mark>and</mark> such if allowed me to really reverse the symptoms. I was set up for surgery to get like huge major surgeries on my arms literally to get slice all the way from my shoulders to my hands just to release the tension on the nerves <mark>and</mark> miraculously I care. Myself the incurable <mark>and</mark> now I found a cure for the uncurable for future generations to come with my family which kind of makes me feel great. So it's a productive day, even though I was taking a lot of brake <mark>and</mark> decided to have a nap which I didn't but super productive even though I didn't get my website up yet, but I'm about to tonight. You know now they're reflect on the day. That's like two or three lifetimes worth of discoveries I did today. Securing my future Generations. Okay, so that's where we started with it. Anyway, so they're using crispr technology", "Start Time (s)": 1956.3, "End Time (s)": 2076.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for the uncurable for future generations to come with my family which kind of makes me feel great. So it's a productive day, even though I was taking a lot of brake <mark>and</mark> decided to have a nap which I didn't but super productive even though I didn't get my website up yet, but I'm about to tonight. You know now they're reflect on the day. That's like two or three lifetimes worth of discoveries I did today. Securing my future Generations. Okay, so that's where we started with it. Anyway, so they're using crispr technology for well, they're not really using it. Yeah, but it's going to start being used for making well, it's already being used under test for apples to not brown potatoes to not brown because When potatoes Brown <mark>and</mark> you cook them like creates a neurotoxin that's poisonous to us, right? So crispr technology is able to make Vegetables in stuff not brown <mark>and</mark> be produce a more vitamin C. It's just able to strengthen things <mark>and</mark> take things out there. You don't want but it's not a genetically modified organism. It's editing stuff that's already there because it's happens in a single life cycle. It doesn't even need a life cycle. It happens right away. So it's really cool, you know like screwing with the whole genetic makeup. You just editing something that's already there. You know, it's you know adding something <mark>and</mark> say it's like genetically modified organisms. You're taking something from one quality from one plant near <mark>and</mark> planting it in this other plant that it's it's a foreign substance <mark>and</mark> that's where the issues of GMO come up, right but", "Start Time (s)": 2034.0, "End Time (s)": 2153.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "test for apples to not brown potatoes to not brown because When potatoes Brown <mark>and</mark> you cook them like creates a neurotoxin that's poisonous to us, right? So crispr technology is able to make Vegetables in stuff not brown <mark>and</mark> be produce a more vitamin C. It's just able to strengthen things <mark>and</mark> take things out there. You don't want but it's not a genetically modified organism. It's editing stuff that's already there because it's happens in a single life cycle. It doesn't even need a life cycle. It happens right away. So it's really cool, you know like screwing with the whole genetic makeup. You just editing something that's already there. You know, it's you know adding something <mark>and</mark> say it's like genetically modified organisms. You're taking something from one quality from one plant near <mark>and</mark> planting it in this other plant that it's it's a foreign substance <mark>and</mark> that's where the issues of GMO come up, right but with crispr technology you just taking stuff out of that something that's already. it you know you're editing something that's already in it you're not taking any foreign thing <mark>and</mark> putting it in it it's just you're doing it all through the RNA you know I'm glad I watched that movie last week Life's a movie what's the simulation bro so that's phase two or four crisper can do now let's get a little more interesting with it since let's touch on the posthumanism say we're going to live on Mars let's say we don't want to be electronic beings because we don't like being shocked <mark>and</mark> share something I", "Start Time (s)": 2085.6, "End Time (s)": 2205.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from one plant near <mark>and</mark> planting it in this other plant that it's it's a foreign substance <mark>and</mark> that's where the issues of GMO come up, right but with crispr technology you just taking stuff out of that something that's already. it you know you're editing something that's already in it you're not taking any foreign thing <mark>and</mark> putting it in it it's just you're doing it all through the RNA you know I'm glad I watched that movie last week Life's a movie what's the simulation bro so that's phase two or four crisper can do now let's get a little more interesting with it since let's touch on the posthumanism say we're going to live on Mars let's say we don't want to be electronic beings because we don't like being shocked <mark>and</mark> share something I don't know or we still want to feel Bo you want to live on the surface of Mars, so here's we're going to get intense I was meditating on this earlier <mark>and</mark> I was like You know, one of the things was like hey, could you just like edit yourself to have like a super mind so that you're like always on mushrooms or the best qualities from mushrooms <mark>and</mark> say psychedelics <mark>and</mark> edit them into your you're being so that you're always like that. Yeah you could You know, like nothing about psilocybin is an organism you like edit it. So they usually always the whatever part psilocybin active is because it's like I feel like still assignment for mushrooms is like", "Start Time (s)": 2144.7, "End Time (s)": 2262.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "things was like hey, could you just like edit yourself to have like a super mind so that you're like always on mushrooms or the best qualities from mushrooms <mark>and</mark> say psychedelics <mark>and</mark> edit them into your you're being so that you're always like that. Yeah you could You know, like nothing about psilocybin is an organism you like edit it. So they usually always the whatever part psilocybin active is because it's like I feel like still assignment for mushrooms is like If you've seen the movie splice, I think it's called I don't like aliens right? It's all about they like make it in the lab with spores right? But I feel like you know human you going to you take psilocybin <mark>and</mark> you get inoculated <mark>and</mark> then you get all these awesome thoughts <mark>and</mark> stuff, but you can't really go back. Once you've done it one time. I mean like I haven't done that shit <mark>and</mark> years were you know, <mark>And</mark> he can't take back <mark>and</mark> experience or the thought process apparently psilocybin <mark>and</mark> her taking another zero point three grams microdose of mushrooms magic mushrooms twice a week. Well repair neural Nets in the brain, which is makes total sense. Hmm. So what if he edit the human brain? Well, like I was saying you it's what putting something not putting something foreign <mark>and</mark> but editing something that's already there. But you could go as far enough is putting stuff that's not already there. So you could totally modify", "Start Time (s)": 2220.3, "End Time (s)": 2340.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> then you get all these awesome thoughts <mark>and</mark> stuff, but you can't really go back. Once you've done it one time. I mean like I haven't done that shit <mark>and</mark> years were you know, <mark>And</mark> he can't take back <mark>and</mark> experience or the thought process apparently psilocybin <mark>and</mark> her taking another zero point three grams microdose of mushrooms magic mushrooms twice a week. Well repair neural Nets in the brain, which is makes total sense. Hmm. So what if he edit the human brain? Well, like I was saying you it's what putting something not putting something foreign <mark>and</mark> but editing something that's already there. But you could go as far enough is putting stuff that's not already there. So you could totally modify modify the mind <mark>and</mark> this is like what's cross back over the quantum computation a little bit <mark>and</mark> artificial intelligence as we're going into the mind because this thought I'm crossing my mind for quite some time since we're going to use quantum computation <mark>and</mark> be able to make superconductors at room temperature show temperature so that we can use quantum levitation in real life which would be insane. We cannot flying buildings. Yeah, maybe so dope like it <mark>and</mark> they won't even crashed <mark>and</mark> wouldn't move. We have skyscrapers? They are a hundred mile. Well, I guess that's pretty far up. Well we could because there would still be a gravitational pull a hundred miles up there still be gravitational pull like a hundred thousand miles up. You can have a gravitational pull for the Sun from well, then, you know, but I can't get my thoughts so fast enough the whole solar system is", "Start Time (s)": 2283.1, "End Time (s)": 2400.3, "Clip Length (min)": 1.95, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> artificial intelligence as we're going into the mind because this thought I'm crossing my mind for quite some time since we're going to use quantum computation <mark>and</mark> be able to make superconductors at room temperature show temperature so that we can use quantum levitation in real life which would be insane. We cannot flying buildings. Yeah, maybe so dope like it <mark>and</mark> they won't even crashed <mark>and</mark> wouldn't move. We have skyscrapers? They are a hundred mile. Well, I guess that's pretty far up. Well we could because there would still be a gravitational pull a hundred miles up there still be gravitational pull like a hundred thousand miles up. You can have a gravitational pull for the Sun from well, then, you know, but I can't get my thoughts so fast enough the whole solar system is from like pulled in due to the fact that the sun has gravity <mark>and</mark> it's holding every planet in place. So therefore we could build we build structures that are based off quantum levitation that are super conducted off of the sun's gravitational pull <mark>and</mark> we can make her own death stars, but it would be like dope as fuck. Okay, we can have perpetual motion. I'm sure they're already out there. Everything's already happened before. Just in the future forever moment forever now anyways, so along with the room temperature superconductors will have biotechnology <mark>and</mark> medicines to cure every possible everything because we could just let that logarithm go <mark>and</mark> simulate", "Start Time (s)": 2345.5, "End Time (s)": 2465.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the whole solar system is from like pulled in due to the fact that the sun has gravity <mark>and</mark> it's holding every planet in place. So therefore we could build we build structures that are based off quantum levitation that are super conducted off of the sun's gravitational pull <mark>and</mark> we can make her own death stars, but it would be like dope as fuck. Okay, we can have perpetual motion. I'm sure they're already out there. Everything's already happened before. Just in the future forever moment forever now anyways, so along with the room temperature superconductors will have biotechnology <mark>and</mark> medicines to cure every possible everything because we could just let that logarithm go <mark>and</mark> simulate rather than having double blind Placebo test. We just let the algorithm make you know. Whatever the Cure is for everything but along with that he's were shit gets intense. Like if humans made acid <mark>and</mark> DMT then what the fuck is the computer going to make for our minds like oh my God. You can fool you think I've never done DMT, but I'm gonna if we think that shit's intense did for a CEO DMT <mark>and</mark> I called the ambulance on myself. That was fucked. Life changing my mind became like a supercomputer <mark>and</mark> I thought every thought that ever happened in my whole life at one time. <mark>And</mark> I felt like I was gonna die <mark>and</mark> I like wished my everybody. Goodbye <mark>and</mark> fuck", "Start Time (s)": 2398.7, "End Time (s)": 2518.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "along with the room temperature superconductors will have biotechnology <mark>and</mark> medicines to cure every possible everything because we could just let that logarithm go <mark>and</mark> simulate rather than having double blind Placebo test. We just let the algorithm make you know. Whatever the Cure is for everything but along with that he's were shit gets intense. Like if humans made acid <mark>and</mark> DMT then what the fuck is the computer going to make for our minds like oh my God. You can fool you think I've never done DMT, but I'm gonna if we think that shit's intense did for a CEO DMT <mark>and</mark> I called the ambulance on myself. That was fucked. Life changing my mind became like a supercomputer <mark>and</mark> I thought every thought that ever happened in my whole life at one time. <mark>And</mark> I felt like I was gonna die <mark>and</mark> I like wished my everybody. Goodbye <mark>and</mark> fuck fuck <mark>and</mark> the worst anxiety attack. <mark>And</mark> then they tortured me in the hospital. It was fucked literally don't ever call the ambulance on yourself. Just fucking don't you will regret it <mark>and</mark> just made me they like they mutilated me. Okay, <mark>and</mark> I made me feel like a young extraterrestrial put tubes inside me where they shouldn't go fuck. Okay, but if we could figure out like to synthesize things like for a CEO DMT, which they say is just synthetic mushrooms, but my acid is okay did martians", "Start Time (s)": 2451.3, "End Time (s)": 2571.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "well I could probably tell ya how to cure cancer, but I don't want to start no controversy nah grounding. cannabis quinoa, okay. so meditation So if we can't figure out how to cure cancer publicly but publicly or going to be able to make the impossible possible with we're going to publicly viewable cure cancer with Supergirl right Quantum computation. Then what the fuck kind of drugs is going to make man like Scares me. It's gonna like make a drug that like, you know, I don't know man, like whatever. It does feel like psychedelic seem to be fucked <mark>and</mark> to me crazy <mark>and</mark> awesome. I'm excited <mark>and</mark> nervous at the same time. Okay, so that's that's like step 3. Okay, we get we could genetically modify the drug that we could be like that for forever. So they were just super duper uber will be Uber people. Okay, <mark>and</mark> so I was thinking about this, you know like Will be like gods that could live for forever. Like we Hindu People Prayed like deities like Shiva <mark>and</mark> stuff <mark>and</mark> like you might add arms to yourself. Just give you the like it'd be more convenient. Sometimes I feel like I should have more arms because I get like this Restless are more like my back hurts <mark>and</mark> shit <mark>and</mark> I feel like there should be another arm there <mark>and</mark> it's just like if I like feel like I have like Phantom limb syndrome four limbs aren't even there <mark>and</mark> then we're never there, you", "Start Time (s)": 2643.3, "End Time (s)": 2763.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "make a drug that like, you know, I don't know man, like whatever. It does feel like psychedelic seem to be fucked <mark>and</mark> to me crazy <mark>and</mark> awesome. I'm excited <mark>and</mark> nervous at the same time. Okay, so that's that's like step 3. Okay, we get we could genetically modify the drug that we could be like that for forever. So they were just super duper uber will be Uber people. Okay, <mark>and</mark> so I was thinking about this, you know like Will be like gods that could live for forever. Like we Hindu People Prayed like deities like Shiva <mark>and</mark> stuff <mark>and</mark> like you might add arms to yourself. Just give you the like it'd be more convenient. Sometimes I feel like I should have more arms because I get like this Restless are more like my back hurts <mark>and</mark> shit <mark>and</mark> I feel like there should be another arm there <mark>and</mark> it's just like if I like feel like I have like Phantom limb syndrome four limbs aren't even there <mark>and</mark> then we're never there, you know just hurts or like there's nothing there. So a lot of couple extra arms <mark>and</mark> shit, but then you know, like see if is blue <mark>and</mark> I was thinking like, you know, like maybe she was blue because like doesn't have to breathe oxygen. So I was like y'all like <mark>and</mark> this is all like well I thought about this earlier but like I really like actually added up into how it would actually be done today through crispr technology. So there's archaea bacteria, right the live inside volcanoes <mark>and</mark> bacteria that lives in like the coldest cold. So we take the qualities from those <mark>and</mark> we put them into US modify them into us so that we do not have to breathe no more rather than becoming machine which you know, it's probably chill to but we still want to like feel her body <mark>and</mark> stuff great because that's part of the human experience. I was like kind", "Start Time (s)": 2694.4, "End Time (s)": 2814.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like my back hurts <mark>and</mark> shit <mark>and</mark> I feel like there should be another arm there <mark>and</mark> it's just like if I like feel like I have like Phantom limb syndrome four limbs aren't even there <mark>and</mark> then we're never there, you know just hurts or like there's nothing there. So a lot of couple extra arms <mark>and</mark> shit, but then you know, like see if is blue <mark>and</mark> I was thinking like, you know, like maybe she was blue because like doesn't have to breathe oxygen. So I was like y'all like <mark>and</mark> this is all like well I thought about this earlier but like I really like actually added up into how it would actually be done today through crispr technology. So there's archaea bacteria, right the live inside volcanoes <mark>and</mark> bacteria that lives in like the coldest cold. So we take the qualities from those <mark>and</mark> we put them into US modify them into us so that we do not have to breathe no more rather than becoming machine which you know, it's probably chill to but we still want to like feel her body <mark>and</mark> stuff great because that's part of the human experience. I was like kind of part of the argument today on Sean's podcast. Can't wait one day. I'll have shrunk are on my podcast. You don't can't wait. Okay, so well edit that into us <mark>and</mark> it'll be all good because we are Mars, you know, Earth government can't tell us what to do or will go to nieces. You know, I've been playing Destiny. So sure Sean Carroll is like, oh, well nice is it might be all have biosphere, you know <mark>and</mark> nieces <mark>and</mark> destinies. I'm like yo, But I'm like already on nieces. I'm thinking about things that I can't talk about be too controversial. That's why I had a pause there. Anyways, well edit ourselves. We don't not need to breathe oxygen <mark>and</mark> we can", "Start Time (s)": 2751.0, "End Time (s)": 2870.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "her body <mark>and</mark> stuff great because that's part of the human experience. I was like kind of part of the argument today on Sean's podcast. Can't wait one day. I'll have shrunk are on my podcast. You don't can't wait. Okay, so well edit that into us <mark>and</mark> it'll be all good because we are Mars, you know, Earth government can't tell us what to do or will go to nieces. You know, I've been playing Destiny. So sure Sean Carroll is like, oh, well nice is it might be all have biosphere, you know <mark>and</mark> nieces <mark>and</mark> destinies. I'm like yo, But I'm like already on nieces. I'm thinking about things that I can't talk about be too controversial. That's why I had a pause there. Anyways, well edit ourselves. We don't not need to breathe oxygen <mark>and</mark> we can survive in outer space. So our blood doesn't boil, etc, etc, or freeze whatever I'll just make ourselves so that we can live in space but still be biological creature. without being made of metal because who the fuck wants to be made a metal nobody I want to be able to touch things <mark>and</mark> feel them <mark>and</mark> like have sex <mark>and</mark> stuff right like I still want to feel emotions like when I'm a billion years old so like will be like gods <mark>and</mark> like we could go through time <mark>and</mark> shit I'm sure we'll figure that out we like editor ourselves so that we can go through black holes man we'll figure it out I'm sure if there's I'm sure Naturally there's archaea bacteria that can live inside a volcano Etc <mark>and</mark> that's just natural I got a message that was no", "Start Time (s)": 2810.4, "End Time (s)": 2930.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That's why I had a pause there. Anyways, well edit ourselves. We don't not need to breathe oxygen <mark>and</mark> we can survive in outer space. So our blood doesn't boil, etc, etc, or freeze whatever I'll just make ourselves so that we can live in space but still be biological creature. without being made of metal because who the fuck wants to be made a metal nobody I want to be able to touch things <mark>and</mark> feel them <mark>and</mark> like have sex <mark>and</mark> stuff right like I still want to feel emotions like when I'm a billion years old so like will be like gods <mark>and</mark> like we could go through time <mark>and</mark> shit I'm sure we'll figure that out we like editor ourselves so that we can go through black holes man we'll figure it out I'm sure if there's I'm sure Naturally there's archaea bacteria that can live inside a volcano Etc <mark>and</mark> that's just natural I got a message that was no longer available <mark>and</mark> it's unsent By the sender what? You know, that's unfortunate. Want to know everything you shouldn't be able to unsend messages stupid. it's frustrating I want to know everything whatever some things you can't know I will accept it okay so sorry", "Start Time (s)": 2861.8, "End Time (s)": 2979.4, "Clip Length (min)": 1.96, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "okay so sorry I got to take a breath so the universe can naturally make archaea bacteria that can live inside a volcano then what the hell can we come up with so crazy your shit in the next billion years you know what it's gonna be dope in the middle like like will definitely be able to live in space if we can if shit can like naturally live in a volcano or like you know we don't even know what the well somebody probably knows everything it's not me Saturday do some DMT <mark>and</mark> talk with the extraterrestrials <mark>and</mark> made the simulation <mark>and</mark> Bill yo bro like what simulation are you <mark>and</mark> are they in a simulation that's in a simulation that's a little intense well I'll have to ask <mark>Joe</mark> <mark>Rogan</mark> he would know you know like that's kind of like you know all these things that could happen these possibilities these probabilities you know is you have to stay on the vibration of like forever life okay don't get caught up in that that death shit I'm so grateful to be alive right now <mark>and</mark> like I'm so grateful I'm young because like I won't die from the Corona virus even if everybody does like little I'll be old <mark>and</mark> then we could just have of total repopulation of Earth of all young people <mark>and</mark> we'd", "Start Time (s)": 2968.4, "End Time (s)": 3088.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Saturday do some DMT <mark>and</mark> talk with the extraterrestrials <mark>and</mark> made the simulation <mark>and</mark> Bill yo bro like what simulation are you <mark>and</mark> are they in a simulation that's in a simulation that's a little intense well I'll have to ask <mark>Joe</mark> <mark>Rogan</mark> he would know you know like that's kind of like you know all these things that could happen these possibilities these probabilities you know is you have to stay on the vibration of like forever life okay don't get caught up in that that death shit I'm so grateful to be alive right now <mark>and</mark> like I'm so grateful I'm young because like I won't die from the Corona virus even if everybody does like little I'll be old <mark>and</mark> then we could just have of total repopulation of Earth of all young people <mark>and</mark> we'd have no more old people Trying to like pull this back anymore. Like I got nothing no problem with that. Like my grandparents got a died my mom. She got to die. Whatever like whatever nobody stopping me know, I'll fucking cure it. I don't give a shit. No fucking my town gets infected with coronavirus all fucking hear it till then you're all fucked. Might be ignorant, you know, but if I don't set my if I don't turn some polarity here, I'm not going to have any fans. That's less what Russell Brunson tells me. I gotta do. I gotta set myself apart that I say. Look this is who we are. This is my pack. You're either with me or you're against me. So you're either with me.", "Start Time (s)": 3026.7, "End Time (s)": 3141.7, "Clip Length (min)": 1.92, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know, but if I don't set my if I don't turn some polarity here, I'm not going to have any fans. That's less what Russell Brunson tells me. I gotta do. I gotta set myself apart that I say. Look this is who we are. This is my pack. You're either with me or you're against me. So you're either with me. what are you against me like we're pretty deep into this podcast now this one's going to go a long time we're done with that short bullshit we're on too long episodes okay so Interstellar travel screw spaceships we're going to we're going to be like no we're not going to be like iron cave oh my God we're gonna we're gonna mutate ourselves so that we can have super conducting body parts that like fucking turn on <mark>and</mark> off so that we can be like the perpetual motion machines but will be make it out of biology oh instead of being a machine because nobody wants to be a machine or maybe we could make metal that you can I don't know man so many decisions so many possibilities <mark>and</mark> probabilities yellow like the Force is with this one <mark>and</mark> the Force is with this one. Yo so conspiracy. Yo. Donald Trump for life What's it agent agent? Yo, look up David Wilcock <mark>and</mark> just watch everything. He's got <mark>and</mark> then come back to me <mark>and</mark>", "Start Time (s)": 3121.1, "End Time (s)": 3241.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "body parts that like fucking turn on <mark>and</mark> off so that we can be like the perpetual motion machines but will be make it out of biology oh instead of being a machine because nobody wants to be a machine or maybe we could make metal that you can I don't know man so many decisions so many possibilities <mark>and</mark> probabilities yellow like the Force is with this one <mark>and</mark> the Force is with this one. Yo so conspiracy. Yo. Donald Trump for life What's it agent agent? Yo, look up David Wilcock <mark>and</mark> just watch everything. He's got <mark>and</mark> then come back to me <mark>and</mark> just tell me you're not a different guy do it. Maybe I'll get him on the podcast to be dope. He could give me all the answers. He says it all this shit is already existent all of it. I don't want to get shot now. You know. Government can fucking hack me if they wanted to <mark>and</mark> go to hell. Fuck the government. Unless you're going to give me money, you know, I am the government fuck that. I'll hack you. Right right iPhone. You heard me you're watching me. You're listening your", "Start Time (s)": 3178.6, "End Time (s)": 3297.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not a different guy do it. Maybe I'll get him on the podcast to be dope. He could give me all the answers. He says it all this shit is already existent all of it. I don't want to get shot now. You know. Government can fucking hack me if they wanted to <mark>and</mark> go to hell. Fuck the government. Unless you're going to give me money, you know, I am the government fuck that. I'll hack you. Right right iPhone. You heard me you're watching me. You're listening your government. I know you're watching. Crazy, <mark>Joe</mark> <mark>Rogan</mark> says, he's like all we're Stoners on a podcast <mark>and</mark> we're talking about the government watching but there's a millions of people watching. Obviously, they're watching but my podcast has seven seven views this point. It's pretty lit though like Honestly, that's just on the anchor out. <mark>And</mark> so my podcast is only five different channels still not on iTunes at Still not yet, isn't it weird? That is like so many different podcasting platforms. You know, I feel like this is going to be the best podcast episode yet because I'm finally able to like stop <mark>and</mark> I was able to get out a whole plot <mark>and</mark> whole story <mark>and</mark> like thread that needle right through to post humanism. cheering disease <mark>and</mark> now now I can speak my mind. Yeah. Guys, like I really want you to find me on", "Start Time (s)": 3241.7, "End Time (s)": 3361.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "he's like all we're Stoners on a podcast <mark>and</mark> we're talking about the government watching but there's a millions of people watching. Obviously, they're watching but my podcast has seven seven views this point. It's pretty lit though like Honestly, that's just on the anchor out. <mark>And</mark> so my podcast is only five different channels still not on iTunes at Still not yet, isn't it weird? That is like so many different podcasting platforms. You know, I feel like this is going to be the best podcast episode yet because I'm finally able to like stop <mark>and</mark> I was able to get out a whole plot <mark>and</mark> whole story <mark>and</mark> like thread that needle right through to post humanism. cheering disease <mark>and</mark> now now I can speak my mind. Yeah. Guys, like I really want you to find me on Instagram <mark>and</mark> just follow me Cody dot Vandervoort or well, actually I'm only using that one IRS also have another Instagram CEO ddy because I got banned on Facebook guys, <mark>and</mark> then I realized like yo you like your Instagram account isn't even tied to your Facebook account so I could have just stuck with one but now I already got the second one going <mark>and</mark> it's like I got all like the first one. Deleted all my followers because they got into like this cyber cyber ghost mode for a little bit. <mark>And</mark> then everyone just followed me again. Anyways, <mark>and</mark> I'm like, you're like, I don't need to be a ghost on the internet. There's no point. I just had a little bit of my medic desire cuz I watched someone talked about open source intelligence <mark>and</mark> shit <mark>and</mark> Man, I just want to like do so much shit, but they're not the same time. I don't want to like do it yet like", "Start Time (s)": 3303.0, "End Time (s)": 3420.8, "Clip Length (min)": 1.96, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that one IRS also have another Instagram CEO ddy because I got banned on Facebook guys, <mark>and</mark> then I realized like yo you like your Instagram account isn't even tied to your Facebook account so I could have just stuck with one but now I already got the second one going <mark>and</mark> it's like I got all like the first one. Deleted all my followers because they got into like this cyber cyber ghost mode for a little bit. <mark>And</mark> then everyone just followed me again. Anyways, <mark>and</mark> I'm like, you're like, I don't need to be a ghost on the internet. There's no point. I just had a little bit of my medic desire cuz I watched someone talked about open source intelligence <mark>and</mark> shit <mark>and</mark> Man, I just want to like do so much shit, but they're not the same time. I don't want to like do it yet like Well, you had I couldn't get it done so much. I had offers to like make a space company <mark>and</mark> they're gonna give me 300 grams so I can make my space company <mark>and</mark> I'm like, no not yet. Well do something else but like then I'm like, oh now I'm sitting here in the garage. I'm like, ah fuck like I should have just done it then. I'm Leon. Ah, ah nah see if I would have done all those things. I would have came across what I came across today <mark>and</mark> when they cured my disease for Nations to come so I think we're I'm in a good place. Huh? So for it's cold in here in this Danny, no fucking heater had shut the door right now because I'm being so loud don't want anybody to hear my crazy ideas. Damn it. I'm gonna open the door all this talk quieter. gummy coat on so I was outside garbage, so blue team ICU interesting with it", "Start Time (s)": 3368.0, "End Time (s)": 3486.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "see if I would have done all those things. I would have came across what I came across today <mark>and</mark> when they cured my disease for Nations to come so I think we're I'm in a good place. Huh? So for it's cold in here in this Danny, no fucking heater had shut the door right now because I'm being so loud don't want anybody to hear my crazy ideas. Damn it. I'm gonna open the door all this talk quieter. gummy coat on so I was outside garbage, so blue team ICU interesting with it gotta follow me on IG so you can see my coaching program. I'm giving away like $40,000 worth of information products. Literally don't buy anything on the internet ever again. Okay, I found it all super cheap. I'll give it to you for 20 bucks. Okay. I was like a hundred <mark>and</mark> fifty Grand worth of information like anything you ever wanted to know, of course on whatever you want. I have it I swear on my life. Let's talk a little bit about my medic desire in the founding mechanisms of humanism. <mark>And</mark> so everything that ever happened in human culture is based upon my medic desire, okay. It's like you're born <mark>and</mark> you're like hey. That guy has this <mark>and</mark> he likes that <mark>and</mark> it seems awesome. So I want his toy. Will you share No, I don't want to share, you know, so my magic desire causes conflict. No one wants to share because everybody wants it. This is where it all started. Everyone's like. Hey, Jesus can do all those cool things. I want that so bad that I'm jealous.", "Start Time (s)": 3446.0, "End Time (s)": 3565.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3ltqAy6TBpjsDkufNBDVAK", "show_name": "Accelerating Tech Today", "show_description": "In this podcast we\u2019re going to get behind the scenes on the come up of Stratospheric Innovations with the founder and CEO Cody VanDerVoort, Stratospheric Innovations is an Entity with a purpose of accelerating the rate of technological advancement through the works of IT/IOT/Quantum IT, at Stratospheric Innovations we believe in inspiring the masses to take drastic action towards creating a better more innovative future because Innovation is the Key to global synchronicity and ending conflict and war before it starts.", "publisher": "Cody Vandervoort", "episode_uri": "spotify:episode:1XplpPQ1jTNyiDWKzvtTV2", "episode_name": "A cure for every Genetic Disease, the answers to everything", "episode_description": "I literally give you all the answers to everything in this episode, then I probably talked to myself for an hour after the show got cut off since there\u2019s a 60 minute limit. This episode got real juicy, definitely the best one yet. Post humanism. Forever life, talking animals. Mimetic Desire, The founding Mechanism, You\u2019re gonna like this one, it\u2019s long but so worth it. www.stratosphericinnovations.com check out my blog on medium as well! Instagram: Cody.vandervoort ", "score": 13.083262, "explanation": "{\n  \"value\": 13.083262,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.2988316,\n      \"description\": \"weight(word_list:joe in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.2988316,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.097899,\n      \"description\": \"weight(word_list:rogan in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.097899,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.728707,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.053773783,\n      \"description\": \"weight(word_list:and in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.053773783,\n          \"description\": \"score(LMDirichletSimilarity, freq=272.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6845818,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 272.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.002914,\n      \"description\": \"weight(word_list:elon in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.002914,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.629844,\n      \"description\": \"weight(word_list:musk in 229) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.629844,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hey there. Thanks for listening to the decaying major podcast. Make sure you follow your favorite podcast. So you never miss an episode like this one or if you become a premium user you can download the episode so you can listen to them offline like I do when you're on a plane or wherever you're traveling <mark>and</mark> also you can share this with your friends on Instagram. If you haven't done so already be sure to download the Spotify app <mark>and</mark> search for D. Km/h or browse podcast in your library tab. Lethargy said in head of sand pop it with a pin watch The Hour Glass Wall half-mast drop dead <mark>and</mark> unhinged what makes you 16 carat gold bastard. 911 marble top drop top silicone prone we", "Start Time (s)": 0.5, "End Time (s)": 76.7, "Clip Length (min)": 1.27, "show_uri": "spotify:show:3aPcE2j1CGuoGuzRssFY3w", "show_name": "DKMH", "show_description": "Beat poetry set to music.   I have spent two years compiling my poetry and these wonderfully talented musicians have helped me bring it to life.   There are five core human drives that influence human behavior.  To AQUIRE To BOND To LEARN  To DEFEND  To FEEL ....  This podcast is a depiction of what DRIVES ME and how much my experiences have shaped who I am.  It is supposed to be altogether meditative, confronting and hopefully...universally relatable.   What drives you...?  Produced by Christopher Mottram & Liv Pollock | Created by Dacre Montgomery", "publisher": "Dacre Montgomery", "episode_uri": "spotify:episode:6BwubzSKN6LuxHoMa09f0n", "episode_name": "GAP", "episode_description": "Created & Music by Dacre Montgomery | Produced/Audio Production by Christopher Mottram | Produced by Liv Pollock ", "score": 11.285831, "explanation": "{\n  \"value\": 11.285831,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.018333564,\n      \"description\": \"weight(word_list:and in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.018333564,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.17704526,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.47501,\n      \"description\": \"weight(word_list:elon in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.47501,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.792488,\n      \"description\": \"weight(word_list:musk in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.792488,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Lethargy said in head of sand pop it with a pin watch The Hour Glass Wall half-mast drop dead <mark>and</mark> unhinged what makes you 16 carat gold bastard. 911 marble top drop top silicone prone we are all alone. inner Beast consumed with a constant threat of failure that husking <mark>musk</mark> <mark>musk</mark> <mark>Elon</mark> making you walk the wire filling your heart with desire. That political stigma the plaintiff is here. The jury is out hardened filled with fear or it is your life. That is the Enigma for they will find you a liar <mark>and</mark> figure out your every fear put on a brave face, but you're just a deer. caught in the Headlights Nine ten lashes away from a discovery. That won't set you apart because you you are a part of the nun covering that leads to an unraveling mask stripped. Kerosene lipped", "Start Time (s)": 40.9, "End Time (s)": 150.3, "Clip Length (min)": 1.82, "show_uri": "spotify:show:3aPcE2j1CGuoGuzRssFY3w", "show_name": "DKMH", "show_description": "Beat poetry set to music.   I have spent two years compiling my poetry and these wonderfully talented musicians have helped me bring it to life.   There are five core human drives that influence human behavior.  To AQUIRE To BOND To LEARN  To DEFEND  To FEEL ....  This podcast is a depiction of what DRIVES ME and how much my experiences have shaped who I am.  It is supposed to be altogether meditative, confronting and hopefully...universally relatable.   What drives you...?  Produced by Christopher Mottram & Liv Pollock | Created by Dacre Montgomery", "publisher": "Dacre Montgomery", "episode_uri": "spotify:episode:6BwubzSKN6LuxHoMa09f0n", "episode_name": "GAP", "episode_description": "Created & Music by Dacre Montgomery | Produced/Audio Production by Christopher Mottram | Produced by Liv Pollock ", "score": 11.285831, "explanation": "{\n  \"value\": 11.285831,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.018333564,\n      \"description\": \"weight(word_list:and in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.018333564,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.17704526,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.47501,\n      \"description\": \"weight(word_list:elon in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.47501,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.792488,\n      \"description\": \"weight(word_list:musk in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.792488,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That political stigma the plaintiff is here. The jury is out hardened filled with fear or it is your life. That is the Enigma for they will find you a liar <mark>and</mark> figure out your every fear put on a brave face, but you're just a deer. caught in the Headlights Nine ten lashes away from a discovery. That won't set you apart because you you are a part of the nun covering that leads to an unraveling mask stripped. Kerosene lipped striking against Flint. A deep upended feeling of insecurity laid upon a bed of Rock <mark>and</mark> Sand <mark>and</mark> <mark>and</mark> passed down a generational misstep rooted Roots thick rotten <mark>and</mark> twisted <mark>and</mark> inheritance of irony <mark>and</mark> pain. The gene pool rippled, but did you fall in or did you plummet to your destiny? An Ascent of alchemy a concoction of your own making a path changing ever-changing. Hand-to-hand you pass on the burdens the gifts to the next Gap. Boomers tuners Millennial beacons of instability But what if we change your fate <mark>and</mark> Ours? The ground you walk", "Start Time (s)": 105.2, "End Time (s)": 219.0, "Clip Length (min)": 1.9, "show_uri": "spotify:show:3aPcE2j1CGuoGuzRssFY3w", "show_name": "DKMH", "show_description": "Beat poetry set to music.   I have spent two years compiling my poetry and these wonderfully talented musicians have helped me bring it to life.   There are five core human drives that influence human behavior.  To AQUIRE To BOND To LEARN  To DEFEND  To FEEL ....  This podcast is a depiction of what DRIVES ME and how much my experiences have shaped who I am.  It is supposed to be altogether meditative, confronting and hopefully...universally relatable.   What drives you...?  Produced by Christopher Mottram & Liv Pollock | Created by Dacre Montgomery", "publisher": "Dacre Montgomery", "episode_uri": "spotify:episode:6BwubzSKN6LuxHoMa09f0n", "episode_name": "GAP", "episode_description": "Created & Music by Dacre Montgomery | Produced/Audio Production by Christopher Mottram | Produced by Liv Pollock ", "score": 11.285831, "explanation": "{\n  \"value\": 11.285831,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.018333564,\n      \"description\": \"weight(word_list:and in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.018333564,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.17704526,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.47501,\n      \"description\": \"weight(word_list:elon in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.47501,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.792488,\n      \"description\": \"weight(word_list:musk in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.792488,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "upended feeling of insecurity laid upon a bed of Rock <mark>and</mark> Sand <mark>and</mark> <mark>and</mark> passed down a generational misstep rooted Roots thick rotten <mark>and</mark> twisted <mark>and</mark> inheritance of irony <mark>and</mark> pain. The gene pool rippled, but did you fall in or did you plummet to your destiny? An Ascent of alchemy a concoction of your own making a path changing ever-changing. Hand-to-hand you pass on the burdens the gifts to the next Gap. Boomers tuners Millennial beacons of instability But what if we change your fate <mark>and</mark> Ours? The ground you walk talk <mark>and</mark> grow. What if we were to change the world?", "Start Time (s)": 154.8, "End Time (s)": 225.2, "Clip Length (min)": 1.17, "show_uri": "spotify:show:3aPcE2j1CGuoGuzRssFY3w", "show_name": "DKMH", "show_description": "Beat poetry set to music.   I have spent two years compiling my poetry and these wonderfully talented musicians have helped me bring it to life.   There are five core human drives that influence human behavior.  To AQUIRE To BOND To LEARN  To DEFEND  To FEEL ....  This podcast is a depiction of what DRIVES ME and how much my experiences have shaped who I am.  It is supposed to be altogether meditative, confronting and hopefully...universally relatable.   What drives you...?  Produced by Christopher Mottram & Liv Pollock | Created by Dacre Montgomery", "publisher": "Dacre Montgomery", "episode_uri": "spotify:episode:6BwubzSKN6LuxHoMa09f0n", "episode_name": "GAP", "episode_description": "Created & Music by Dacre Montgomery | Produced/Audio Production by Christopher Mottram | Produced by Liv Pollock ", "score": 11.285831, "explanation": "{\n  \"value\": 11.285831,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.018333564,\n      \"description\": \"weight(word_list:and in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.018333564,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.17704526,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.47501,\n      \"description\": \"weight(word_list:elon in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.47501,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.792488,\n      \"description\": \"weight(word_list:musk in 11) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.792488,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.15871169,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 344.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I actually I actually didn't have the mic in my hand. So. I got a fat callus on my hand right now. Sorry, I like sandpaper. It's all right. But yeah, so sorry about that long break we took we were just really busy with midterms papers. We went on a Hiatus we just were busy. Yeah. Sorry, not a Hiatus. That means we're like temporarily broken up. It's a short break. Okay spotty spotty neck. My face <mark>and</mark> did it to time but I look like I have this big ol hickey on my cheek in the perfect <mark>and</mark> A Perfect Circle. Looks like he's got a ringworm on his cheek. Yeah, Andrew you got a little spot to on your cheek as well. Yeah, this is just a slight what it's not as definite as dark as Nick. So if you guys see Nick around campus or anywhere from one of them, please don't ask me I had to explain it like 30 times a day at work come spot. But so yeah you guys What's the update the two-week update we've been on in two weeks midterms went well midterms one. Well, yeah, my Quantum teacher actually got my grade wrong. Really? Yeah, how does that happen? Thought I had an 80 got a 98 credible <mark>and</mark> your house your two weeks going good. Yeah, Nick, are they good? I got an A on one of them. I got house art that was just about asked started that fight with my professor today. Well, I because I we're doing like these", "Start Time (s)": 19.5, "End Time (s)": 119.6, "Clip Length (min)": 1.67, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but I look like I have this big ol hickey on my cheek in the perfect <mark>and</mark> A Perfect Circle. Looks like he's got a ringworm on his cheek. Yeah, Andrew you got a little spot to on your cheek as well. Yeah, this is just a slight what it's not as definite as dark as Nick. So if you guys see Nick around campus or anywhere from one of them, please don't ask me I had to explain it like 30 times a day at work come spot. But so yeah you guys What's the update the two-week update we've been on in two weeks midterms went well midterms one. Well, yeah, my Quantum teacher actually got my grade wrong. Really? Yeah, how does that happen? Thought I had an 80 got a 98 credible <mark>and</mark> your house your two weeks going good. Yeah, Nick, are they good? I got an A on one of them. I got house art that was just about asked started that fight with my professor today. Well, I because I we're doing like these Self-portrait stenciling type thing <mark>and</mark> then she told me to do this one thing <mark>and</mark> I did it <mark>and</mark> I showed it to her <mark>and</mark> she goes what the heck is this <mark>and</mark> I go I did what you told me to do <mark>and</mark> she's like I did not tell you that start over <mark>and</mark> I just I just can't do this. I respect people had their whole thing. Yeah. I respect a lot of people that are good at Art because just takes time practice. No. Yeah, you got to have the hand. You just got to have the yamit I shake too much. I've heard tension. That's me hypertension. Josh has hypertension. That would be shaken 24/7. My doctor said I should outgrow it by 25 though. You're like part Chihuahua. What does that mean? I've been getting really into the resting heart rate on the Apple watch. Oh, yeah. He looks like an 80 all the time though. Good, you don't want that looks at that. I know that tells you to breathe when it tells you to bring yeah, I'm sitting down for too long. Please stand up Josh probably stands up in the middle of class. I almost did during work today - what are you doing? The watch is", "Start Time (s)": 61.7, "End Time (s)": 181.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "she told me to do this one thing <mark>and</mark> I did it <mark>and</mark> I showed it to her <mark>and</mark> she goes what the heck is this <mark>and</mark> I go I did what you told me to do <mark>and</mark> she's like I did not tell you that start over <mark>and</mark> I just I just can't do this. I respect people had their whole thing. Yeah. I respect a lot of people that are good at Art because just takes time practice. No. Yeah, you got to have the hand. You just got to have the yamit I shake too much. I've heard tension. That's me hypertension. Josh has hypertension. That would be shaken 24/7. My doctor said I should outgrow it by 25 though. You're like part Chihuahua. What does that mean? I've been getting really into the resting heart rate on the Apple watch. Oh, yeah. He looks like an 80 all the time though. Good, you don't want that looks at that. I know that tells you to breathe when it tells you to bring yeah, I'm sitting down for too long. Please stand up Josh probably stands up in the middle of class. I almost did during work today - what are you doing? The watch is telling me to stand up <mark>and</mark> gotta stand up. Thank you. <mark>And</mark> what song you seem a little quiet Anais told Josh that Apple watch. I need to tell them where you got the Apple watch from where'd you get your Apple watch from Nick that I bought off <mark>and</mark> weird Nick it his Apple gift card from CB mark. Getting pretty sure Ryan mesito shut up. Don't even work there then do what I got to do. We had our final intramural basketball game of the night semifinals man. <mark>And</mark> I kind of was a tough one. I wanted to beat them so bad. I know it's all right some bad blood between me <mark>and</mark> you know, who Talked about this with an open book. Why don't you man? It's just a tough subject. On this occasion. How'd your season going", "Start Time (s)": 122.8, "End Time (s)": 242.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "want to like to but you had a good view had a semi good reason to miss something like two shots up on the season. I put one up. I just remember we put in job putting all the subs because we're up by 12:30. Literally literally the last move of the game the first game. It's a very first game it scared me dude. The first of that happened. I was like, I know I'm not playing again. So why we're not bad. We're just short. That's all it is. You think I feel barely taller than you just put me in one game for one possession. I got to rebound dead ball foul on the next end took me out. I remember I was playing it goes the heck. I just got had no you goes Josh was only in for a minute. Oh my gosh. Sorry that corner. Would I be hidden different now? Oh my God, your dessert just a little what are they? Like a cube a little packet of butter butter Cube <mark>and</mark> some salt delicious just it just melts in your mouth. Literally. I Can't Believe It's Not Butter. You guys everybody on your kid? No never when you did that. I was like what the heck? No I never did. Yeah, I mean it wasn't like oh drink pickle juice. That's about the weirdest thing. I did know you do coffee's little coffee. Nip to know the drink you ever had like the jam packets like that goes on toast. Oh, that's still does that I know what you're talking about. What's it called? Down I used to eat Doritos of ketchup. Yeah, that's weird. Why don't knock it until you've come on my friends. My friends nacho cheese. Yeah, that's kind of weird. My frozen water is a great substitute <mark>and</mark> I'm just kidding <mark>and</mark>", "Start Time (s)": 250.1, "End Time (s)": 369.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of butter butter Cube <mark>and</mark> some salt delicious just it just melts in your mouth. Literally. I Can't Believe It's Not Butter. You guys everybody on your kid? No never when you did that. I was like what the heck? No I never did. Yeah, I mean it wasn't like oh drink pickle juice. That's about the weirdest thing. I did know you do coffee's little coffee. Nip to know the drink you ever had like the jam packets like that goes on toast. Oh, that's still does that I know what you're talking about. What's it called? Down I used to eat Doritos of ketchup. Yeah, that's weird. Why don't knock it until you've come on my friends. My friends nacho cheese. Yeah, that's kind of weird. My frozen water is a great substitute <mark>and</mark> I'm just kidding <mark>and</mark> what I was gonna say sand sand <mark>and</mark> pretzels the one time I was in the desert really was not really poor just know you oh, I was just dip. It in <mark>and</mark> obviously standing it on because it's a dry piece of bread pretzel nothing will happen but nothing would happen because it wouldn't stick to hate sin wants never again. I got the worst sore throat. Well the yeah, it's Roxy. It's going down your throat know that that's what they make glass out of that's what they make glass out of you know that Sand really? Yeah, they just get a bunch of the heat up <mark>and</mark> they are not know that I didn't hear you. Learn something new every day. Sometimes could be an informational podcast. I guess we'll never run out of glass because we have a ton of sand next thing, you know, we're running out of sand <mark>and</mark> be nice why cause", "Start Time (s)": 307.9, "End Time (s)": 427.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is a great substitute <mark>and</mark> I'm just kidding <mark>and</mark> what I was gonna say sand sand <mark>and</mark> pretzels the one time I was in the desert really was not really poor just know you oh, I was just dip. It in <mark>and</mark> obviously standing it on because it's a dry piece of bread pretzel nothing will happen but nothing would happen because it wouldn't stick to hate sin wants never again. I got the worst sore throat. Well the yeah, it's Roxy. It's going down your throat know that that's what they make glass out of that's what they make glass out of you know that Sand really? Yeah, they just get a bunch of the heat up <mark>and</mark> they are not know that I didn't hear you. Learn something new every day. Sometimes could be an informational podcast. I guess we'll never run out of glass because we have a ton of sand next thing, you know, we're running out of sand <mark>and</mark> be nice why cause you're a whale You know want to get beached quit spitting water on their heads fit any water on you now. I know you guys are all addicted. Oh not. Yes. I can take a week break right now. Alright, let's just had that you're going to do that after the campaign campaign why it makes them happy. I even played a lot in the campaign. It makes them happy let them play that's like telling not not stunning to that break from you. Make that I can go a week without easy. Let's do it. Okay, put some money on it. We just took a hand how much money you're not complete any video games? No credible for how long? Oh, we said we what's the thing? What's the wager? Well, I'm gonna win. So yeah, how much 20? All right, let's put a band, you know,", "Start Time (s)": 366.5, "End Time (s)": 484.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can go a week without easy. Let's do it. Okay, put some money on it. We just took a hand how much money you're not complete any video games? No credible for how long? Oh, we said we what's the thing? What's the wager? Well, I'm gonna win. So yeah, how much 20? All right, let's put a band, you know, whatever it takes for World tanks because you need more money. I'll buy you some gold. How about that? Yeah. Yeah fifty dollars of gold then that's a lot the 25 kind of scratch 25. I don't though. Yeah. All right a week. Okay, so we can't play until Thursday at 10 10. Okay. All right, to be honest, too. I will okay. I don't want you waking up at 2 a.m. <mark>And</mark> getting on a deep sleeper. We know that Z takes 18 melatonin tonight. No, it's a six last night. That's crazy. Out like a light. I'm so glad I didn't say that I was going to why but I wanted the last person to say it. Who's the Lesser person? All right. So I got a question for you guys. Hold on. Let me get it really quick. It would it's would you oh my gosh. Where is it? Hold on. I have a question. I have a question. What do you guys if you guys are dating someone? Do you think it's okay for them to go through your phone? Absolutely, like have their your passcode <mark>and</mark> everything or do you think it should be all trust", "Start Time (s)": 460.9, "End Time (s)": 580.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't want you waking up at 2 a.m. <mark>And</mark> getting on a deep sleeper. We know that Z takes 18 melatonin tonight. No, it's a six last night. That's crazy. Out like a light. I'm so glad I didn't say that I was going to why but I wanted the last person to say it. Who's the Lesser person? All right. So I got a question for you guys. Hold on. Let me get it really quick. It would it's would you oh my gosh. Where is it? Hold on. I have a question. I have a question. What do you guys if you guys are dating someone? Do you think it's okay for them to go through your phone? Absolutely, like have their your passcode <mark>and</mark> everything or do you think it should be all trust base? I don't care if their trust I'm not I'm not on my phone a lot. So I don't care I know but like would you want them knowing it knowing your stuff DJ? Yeah passwords. She knows everything. It's Daniel. I wouldn't care. I don't care. I don't care. I don't care either. All right, so would you guys listen? They're just they're kind of dumb question. But would you guys rather lose a foot or a hand for 1 billion dollars? You have to choose one 1 billion. Yeah, just a bill what hands losing both hands? Hand your dominant hand. Oh, I'm losing a foot your dominant foot. Yeah for though. I guess you're going to put a stinky old prosthetic leg on it. I can still move <mark>and</mark> it functions. Well, no. Yes, I'm scared Andrew. Can I still be a cop if I wanted to be a cop if you had a prosthetic leg. Are you could or foot? You just have to have a foot your foot gone. It's just your foot. It's not your whole leg foot our hands my foot. I'm taking a foot you love me.", "Start Time (s)": 519.5, "End Time (s)": 638.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "care. I don't care either. All right, so would you guys listen? They're just they're kind of dumb question. But would you guys rather lose a foot or a hand for 1 billion dollars? You have to choose one 1 billion. Yeah, just a bill what hands losing both hands? Hand your dominant hand. Oh, I'm losing a foot your dominant foot. Yeah for though. I guess you're going to put a stinky old prosthetic leg on it. I can still move <mark>and</mark> it functions. Well, no. Yes, I'm scared Andrew. Can I still be a cop if I wanted to be a cop if you had a prosthetic leg. Are you could or foot? You just have to have a foot your foot gone. It's just your foot. It's not your whole leg foot our hands my foot. I'm taking a foot you love me. No. No, that's that's a question. What how can you tell a girl takes care of herself her feet? Yeah. Yeah, I'd agree with that. Yeah. Have you ever tried <mark>and</mark> true? Have you guys ever seen like our feet on her nails? Yeah, it's ever seen someone with like a foot in there like pinky toe. They don't have a nail their pinky toe to - tiny. My dad has like a little calcium deposit their it's not even Alright, so yeah. Yeah, just learn how to do it left-handed left-handed stuff. You know how long that's going to take you not long look at me. I'd be better off with a foot how you going to play video games? I wouldn't play video games. No, how would you live? With my other hands no live with without playing video", "Start Time (s)": 595.3, "End Time (s)": 715.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, just learn how to do it left-handed left-handed stuff. You know how long that's going to take you not long look at me. I'd be better off with a foot how you going to play video games? I wouldn't play video games. No, how would you live? With my other hands no live with without playing video games. You can play the we only need one him that it's not I probably would be more productive probably go to the gym unlike you how would you for 5 hours instead of four? Yeah. Probably just work out each of my extremities. Okay. All right. All right. Hey, no teeth for a billion. No, you can't are so big <mark>and</mark> Dentures. Nope. Teeth are so big for me just straight gum <mark>and</mark> I went best my well. That's oh shut it so you're just coming around. You got lucky. Shut up. We already had the other award. It's because I've ever told Did it for the yearbook but you wouldn't know he wants all that. You're okay. Wasn't that the Make-A-Wish here? All right. Let's ask you to do two single guys. What do you look for in a girl? Like what what attracts you about a girl like me. It's teeth like she has to have a nice smile.", "Start Time (s)": 691.7, "End Time (s)": 781.2, "Clip Length (min)": 1.49, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know he wants all that. You're okay. Wasn't that the Make-A-Wish here? All right. Let's ask you to do two single guys. What do you look for in a girl? Like what what attracts you about a girl like me. It's teeth like she has to have a nice smile. Shut up. Like a smile <mark>and</mark> like, you know, like when the girls have like the freckles on their nose <mark>and</mark> it goes to their cheeks a little bit there Sunkist you find Colossus attractive. Yes. I love glasses. Yes, that's ksenia never wears her glasses <mark>and</mark> she like blind as a bat. Yeah. She is. It's all right. I'm gonna start wearing my glasses. Do you have glasses? You should wear the glasses that your dad's worse? That's like the ones in the jet ski Dad I can't talk about my dad jokes anymore. Why do you shout out Joe? What's up? It's true about me. All right, get a job be a man. All right. Get out my house. Down pick", "Start Time (s)": 762.6, "End Time (s)": 881.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's all right. I'm gonna start wearing my glasses. Do you have glasses? You should wear the glasses that your dad's worse? That's like the ones in the jet ski Dad I can't talk about my dad jokes anymore. Why do you shout out Joe? What's up? It's true about me. All right, get a job be a man. All right. Get out my house. Down pick up real be right not funny. Another dumb question vineet smart questions. Would you guys rather be blind <mark>and</mark> be able to play every instrument like a pro level like ridiculous like one of the best Stevie Wonder Yeah, okay, or have your worst job <mark>and</mark> have your vision so like work at McDonald's but have your vision dental work there forever who? I can just quit my terrible down for that reason why they're dropping like flies. All right be quiet with that you would you rather do a job like make a ton of money while doing a job you hate or doing a job you love for or like a little little <mark>and</mark> really well how much so can I provide for my family? So say you're at McDonald's you're making a hundred fifty", "Start Time (s)": 837.7, "End Time (s)": 956.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "question vineet smart questions. Would you guys rather be blind <mark>and</mark> be able to play every instrument like a pro level like ridiculous like one of the best Stevie Wonder Yeah, okay, or have your worst job <mark>and</mark> have your vision so like work at McDonald's but have your vision dental work there forever who? I can just quit my terrible down for that reason why they're dropping like flies. All right be quiet with that you would you rather do a job like make a ton of money while doing a job you hate or doing a job you love for or like a little little <mark>and</mark> really well how much so can I provide for my family? So say you're at McDonald's you're making a hundred fifty K G's or you're a cop <mark>and</mark> you're making 70 hundo Ando 70. 70 AD at McDonald's. I know how the police system works each year you make more so <mark>and</mark> there's only this is a hypothetical you can ask better questions, man. There's a loophole for all of them. I know your job he goes. Yeah. Does that mean they had because there's three people in the band now there was only three sacks. This was wasn't it? There's six six. Yeah, <mark>and</mark> there was Danielle <mark>and</mark> there's 80 people in the band. Wow. Yeah bam Lugosi was pretty big actually. Mr. Vander griend. Like I was cool. He came to my All-Star game once", "Start Time (s)": 890.8, "End Time (s)": 1010.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you would you rather do a job like make a ton of money while doing a job you hate or doing a job you love for or like a little little <mark>and</mark> really well how much so can I provide for my family? So say you're at McDonald's you're making a hundred fifty K G's or you're a cop <mark>and</mark> you're making 70 hundo Ando 70. 70 AD at McDonald's. I know how the police system works each year you make more so <mark>and</mark> there's only this is a hypothetical you can ask better questions, man. There's a loophole for all of them. I know your job he goes. Yeah. Does that mean they had because there's three people in the band now there was only three sacks. This was wasn't it? There's six six. Yeah, <mark>and</mark> there was Danielle <mark>and</mark> there's 80 people in the band. Wow. Yeah bam Lugosi was pretty big actually. Mr. Vander griend. Like I was cool. He came to my All-Star game once really yeah when I put was plan against Andrew, I think wait All-Star game for what baseball baseball real smoked Montclair. They saw I was actually playing whenever I would always play your Vineyard. Yeah, I'd always play that other the Fontana you get Southridge no always want an American Community after that never faced Josh. Well, six years down the drain. We did play football together though force that Force the fumble. I was D line Josh you were d-line. I snuck under the center's legs <mark>and</mark> I grabbed the ball.", "Start Time (s)": 941.7, "End Time (s)": 1061.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there was Danielle <mark>and</mark> there's 80 people in the band. Wow. Yeah bam Lugosi was pretty big actually. Mr. Vander griend. Like I was cool. He came to my All-Star game once really yeah when I put was plan against Andrew, I think wait All-Star game for what baseball baseball real smoked Montclair. They saw I was actually playing whenever I would always play your Vineyard. Yeah, I'd always play that other the Fontana you get Southridge no always want an American Community after that never faced Josh. Well, six years down the drain. We did play football together though force that Force the fumble. I was D line Josh you were d-line. I snuck under the center's legs <mark>and</mark> I grabbed the ball. Shut up. I swear I've held onto the quarterbacks legs in it. We had this guy named named Anthony Romero. He remarried. Yeah Anthony Ramirez. He cracked the quarterback forced the fumble. We have to immerse did he have long hair? No glasses, but there's a literally five million Anthony rumors <mark>and</mark> Sophie. It's gonna be kind of hard to pinpoint one. You don't know that I miss my pop warner team. We were good Andrew Harrison add your Harrison without others talk about of you know, like a lot of my friends from that team were like famous know who like tie it tie skin all my friends from freaking Little Eagles on the same All-Star Team all Wendy one who Stephen. Oh, yeah this but our but oh my gosh our buddy named Wyatt. What would you say D-League now? I'm talking about something else like Michael Pinero. You went to a", "Start Time (s)": 1000.5, "End Time (s)": 1119.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "held onto the quarterbacks legs in it. We had this guy named named Anthony Romero. He remarried. Yeah Anthony Ramirez. He cracked the quarterback forced the fumble. We have to immerse did he have long hair? No glasses, but there's a literally five million Anthony rumors <mark>and</mark> Sophie. It's gonna be kind of hard to pinpoint one. You don't know that I miss my pop warner team. We were good Andrew Harrison add your Harrison without others talk about of you know, like a lot of my friends from that team were like famous know who like tie it tie skin all my friends from freaking Little Eagles on the same All-Star Team all Wendy one who Stephen. Oh, yeah this but our but oh my gosh our buddy named Wyatt. What would you say D-League now? I'm talking about something else like Michael Pinero. You went to a big Public Schools though. <mark>And</mark> then you would have been D12. We just don't really have any any more questions, but they're kind of like news so this at this track <mark>and</mark> field. For high school or like a college a 21 year old was pole vaulting <mark>and</mark> so we went over he went over the like whatever was 18 feet or whatever. So he jumps all the way up the pulled in Fall the wrong way right way skewered him right through the ball sack. Yeah people he posted on Tick-Tock. There's blood all over his shorts. Oh, yeah. Well, he didn't he didn't he didn't lose any testicles though. What? Yeah, I know just went went right through it. Back to the scrotum. Yeah, incredible stitches. Oh my gosh, 90 90 stitches.", "Start Time (s)": 1062.8, "End Time (s)": 1178.0, "Clip Length (min)": 1.92, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "don't really have any any more questions, but they're kind of like news so this at this track <mark>and</mark> field. For high school or like a college a 21 year old was pole vaulting <mark>and</mark> so we went over he went over the like whatever was 18 feet or whatever. So he jumps all the way up the pulled in Fall the wrong way right way skewered him right through the ball sack. Yeah people he posted on Tick-Tock. There's blood all over his shorts. Oh, yeah. Well, he didn't he didn't he didn't lose any testicles though. What? Yeah, I know just went went right through it. Back to the scrotum. Yeah, incredible stitches. Oh my gosh, 90 90 stitches. I don't know if you guys heard this but there was this guy that was making homemade Rockets to try <mark>and</mark> get to space or likely the atmosphere. Have you guys heard of him? He blew himself up. No, so he was like a flat earth guy. <mark>And</mark> he was building his own Rockets to try <mark>and</mark> get up <mark>and</mark> see if the Earth was actually flat or round <mark>and</mark> this is kind of sad, but he actually passed away at the age of 64 in his own rocket. From age? No, he was in his own rock. He was in his own rocket <mark>and</mark> the bill up the parachute or whatever like whatever safety system. He had failed dang slow. At least he died - try <mark>and</mark> what he loved. Yeah, he died in a rocket. Oh this spring but that's why the popo have NASA. You don't build Rockets. Yeah. Do you guys see the about <mark>Elon</mark> <mark>Musk</mark> how he wants to build like space travel for like some like normal people for like us. Yeah. I want people to like there's already like Live on Mars are live on those are the only two but like to go on like trips, like go to", "Start Time (s)": 1133.6, "End Time (s)": 1251.6, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "get to space or likely the atmosphere. Have you guys heard of him? He blew himself up. No, so he was like a flat earth guy. <mark>And</mark> he was building his own Rockets to try <mark>and</mark> get up <mark>and</mark> see if the Earth was actually flat or round <mark>and</mark> this is kind of sad, but he actually passed away at the age of 64 in his own rocket. From age? No, he was in his own rock. He was in his own rocket <mark>and</mark> the bill up the parachute or whatever like whatever safety system. He had failed dang slow. At least he died - try <mark>and</mark> what he loved. Yeah, he died in a rocket. Oh this spring but that's why the popo have NASA. You don't build Rockets. Yeah. Do you guys see the about <mark>Elon</mark> <mark>Musk</mark> how he wants to build like space travel for like some like normal people for like us. Yeah. I want people to like there's already like Live on Mars are live on those are the only two but like to go on like trips, like go to space <mark>and</mark> stuff <mark>and</mark> like really see space like from an astronaut's point of view as do that. Yeah, I would like a museum kind of its kind of like a it'd be like a trip. I guess. Well, you just like in the spaceship. I mean you're in the line. Yes. Yes spacecraft you go to the like a space station. Yeah, I like that but it made me realize how a hotel or something but do I always want to go in space <mark>and</mark> just look down <mark>and</mark> just see absolutely nothing but like you see the earth. Oh, that's great. But a lot of people were saying like people like Neil Armstrong <mark>and</mark> like all these like famous people that are like worked in NASA <mark>and</mark> stuff like are so against it <mark>and</mark> it's like crushed <mark>Elon</mark> musk's dreams because he like looked up to those people. I guess. Well, I mean, it'd be really complicated house-trained all those yesterday. It's already like in the process of happening. He said <mark>and</mark> then he's like he just said for those people that doubt just come look come look <mark>and</mark> see what we have going on here. I don't know if this is dumb, but I was thinking this the other day. It's like the ocean just floating in the middle of space. It's gravity. I know but the next", "Start Time (s)": 1192.0, "End Time (s)": 1311.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on here. I don't know if this is dumb, but I was thinking this the other day. It's like the ocean just floating in the middle of space. It's gravity. I know but the next but that's weird. That is just there. Yeah, she's there. No. No, I do think that I think it's crazy that so crazy to think about. Oh do you get? Okay. Do you guys know the theory of Pangaea? Yeah, like how all the cards altogether I think that you think so. Yeah. I think that's how people separated. it You know what I'm saying? You know what I mean? Like that's how people got that's why people are already in the United States when yeah from Pangaea. Do you think that happened before Biblical times? What do you mean before but you think people were on the earth when it happened? Yes, II guess they would do you think they felt themselves breaking apart <mark>and</mark> moving take no. No, this is Saudi. It's so do you feel that tectonic plates are moving right now. Do you feel it? No, so next. No, that's my job. I got you Nick a bully. Come on. All right. I like to I like hugs. What can I say to? Okay, so recently Harvey Weinstein got convicted of rape. <mark>And</mark> so let me know what a turn no hypothetical kind of <mark>and</mark> so he's going to get like five to 25 years. That's kind of the basic sentence. Do you think do you think he commits suicide or rent or dies before he gets put in jail because just because of the Hollywood connection with everyone you don't wait. He's gonna do you think he's gonna like don't quote me on", "Start Time (s)": 1301.7, "End Time (s)": 1421.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "next. No, that's my job. I got you Nick a bully. Come on. All right. I like to I like hugs. What can I say to? Okay, so recently Harvey Weinstein got convicted of rape. <mark>And</mark> so let me know what a turn no hypothetical kind of <mark>and</mark> so he's going to get like five to 25 years. That's kind of the basic sentence. Do you think do you think he commits suicide or rent or dies before he gets put in jail because just because of the Hollywood connection with everyone you don't wait. He's gonna do you think he's gonna like don't quote me on this. Okay are parentheses kill himself commit suicide or do you think he's going to like, oh, he's like like he's gonna go take off somewhere <mark>and</mark> not like remember. What was his name? The El Chapo know the guy that killed himself in prison that was on suicide watch Hernandez. No, no, mr. Clean. Mr. Clay question. This is it's not like I'm just saying I'm just asking you think he's just gonna like all of a sudden die in like before he gets sentenced actually sentence <mark>and</mark> Gossage. Oh like all of a sudden because like he got sentence <mark>and</mark> there one was he was like, oh I'm having like these heart problems now, so he's in jail. No not yet. It's going to take another couple months till like they gave him. The sentence he was doing a bunch of health problems, like he started saying a bunch of stuff. So he doesn't have to go to prison or what? Oh, I get what you're saying. Okay, like he's in solitary. So you're saying like they haven't he's been sentenced to jail. He's not in jail yet though, but he's basically dying should they", "Start Time (s)": 1369.2, "End Time (s)": 1489.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "suicide watch Hernandez. No, no, mr. Clean. Mr. Clay question. This is it's not like I'm just saying I'm just asking you think he's just gonna like all of a sudden die in like before he gets sentenced actually sentence <mark>and</mark> Gossage. Oh like all of a sudden because like he got sentence <mark>and</mark> there one was he was like, oh I'm having like these heart problems now, so he's in jail. No not yet. It's going to take another couple months till like they gave him. The sentence he was doing a bunch of health problems, like he started saying a bunch of stuff. So he doesn't have to go to prison or what? Oh, I get what you're saying. Okay, like he's in solitary. So you're saying like they haven't he's been sentenced to jail. He's not in jail yet though, but he's basically dying should they let him stay free, you know is this just it's a conspiracy of do you think yeah, you know, what in Hollywood is gonna cover it up <mark>and</mark> kill like essentially kill him like they did. I can't think His name was Jay Simpson. No, Jay Simpsons alive. Oh, yeah, his wife <mark>and</mark> daughter than oh you think they're like Hollywood's gonna cover it up. Yeah, just because of how connected it. All is like Hollywood's its own Hollywood's is own country. Yeah, I mean no no, you mean just like they're so connected from top to bottom Harvey Weinstein was a really famous director. Okay? Okay, <mark>and</mark> he would essentially he's basically saying that they have like so many secrets of their own that nobody else knows. So tired of it. I know I always have to go before like a teacher calls my name <mark>and</mark> class so I don't keep Scrappy <mark>and</mark> I don't know why all the time for attendance. Yeah, you're Julia Javier Garrett", "Start Time (s)": 1437.8, "End Time (s)": 1553.1, "Clip Length (min)": 1.92, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "should they let him stay free, you know is this just it's a conspiracy of do you think yeah, you know, what in Hollywood is gonna cover it up <mark>and</mark> kill like essentially kill him like they did. I can't think His name was Jay Simpson. No, Jay Simpsons alive. Oh, yeah, his wife <mark>and</mark> daughter than oh you think they're like Hollywood's gonna cover it up. Yeah, just because of how connected it. All is like Hollywood's its own Hollywood's is own country. Yeah, I mean no no, you mean just like they're so connected from top to bottom Harvey Weinstein was a really famous director. Okay? Okay, <mark>and</mark> he would essentially he's basically saying that they have like so many secrets of their own that nobody else knows. So tired of it. I know I always have to go before like a teacher calls my name <mark>and</mark> class so I don't keep Scrappy <mark>and</mark> I don't know why all the time for attendance. Yeah, you're Julia Javier Garrett was not even paying attention here. I'm always afraid to do my voice kept cracking tonight during the basketball game. I heard I heard you either it was annoying. Do you listen to me when I'm feeling I can hear all you guys. Oh Gerry Epstein that was his name is a jarier Jeff Jeff AB, c-- I don't know but it says Jeffrey. I don't know if they come I've heard a lot of names about them. But this is calm John so he killed himself when he was in suicide watch <mark>and</mark> everyone was like bro. There's no way you could do that in prison. Like they took everything away from him. Yeah, you know, yeah, you're in confinement you have literally nothing, but you just hit your head against something earlier now they have <mark>And</mark> so like there's been a bunch of like CIA agents have gone on <mark>Joe</mark> Rogan's podcast", "Start Time (s)": 1488.5, "End Time (s)": 1608.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "before like a teacher calls my name <mark>and</mark> class so I don't keep Scrappy <mark>and</mark> I don't know why all the time for attendance. Yeah, you're Julia Javier Garrett was not even paying attention here. I'm always afraid to do my voice kept cracking tonight during the basketball game. I heard I heard you either it was annoying. Do you listen to me when I'm feeling I can hear all you guys. Oh Gerry Epstein that was his name is a jarier Jeff Jeff AB, c-- I don't know but it says Jeffrey. I don't know if they come I've heard a lot of names about them. But this is calm John so he killed himself when he was in suicide watch <mark>and</mark> everyone was like bro. There's no way you could do that in prison. Like they took everything away from him. Yeah, you know, yeah, you're in confinement you have literally nothing, but you just hit your head against something earlier now they have <mark>And</mark> so like there's been a bunch of like CIA agents have gone on <mark>Joe</mark> Rogan's podcast <mark>and</mark> be like dude. This guy didn't kill himself, but I think you're still alive. No, he's dead. I'm saying someone killed him. That's all. Yeah, like covered it up. Yeah. It was a cover-up. So I'm saying do you think that's going to happen to Harvey just because the power he has in Hollywood. Now do you guys get what I'm trying to say? <mark>And</mark> dude? No, no, I get what you're trying to say. Don't get it. No I'm saying no, it's not gonna happen. He's so gross not gonna happen understood sir. Yes, sir. When I was ready to learn <mark>and</mark> uh, sir what I was ready with Nick to the Jim River. I was I said those marches. Yeah the cadences. Oh, yeah. Let's hear him. Give us give us an example AC-130 rolling down the Oh, I should probably just keep saying Airborne Ranger on a one-way trip <mark>and</mark> Mission", "Start Time (s)": 1544.7, "End Time (s)": 1664.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>And</mark> so like there's been a bunch of like CIA agents have gone on <mark>Joe</mark> Rogan's podcast <mark>and</mark> be like dude. This guy didn't kill himself, but I think you're still alive. No, he's dead. I'm saying someone killed him. That's all. Yeah, like covered it up. Yeah. It was a cover-up. So I'm saying do you think that's going to happen to Harvey just because the power he has in Hollywood. Now do you guys get what I'm trying to say? <mark>And</mark> dude? No, no, I get what you're trying to say. Don't get it. No I'm saying no, it's not gonna happen. He's so gross not gonna happen understood sir. Yes, sir. When I was ready to learn <mark>and</mark> uh, sir what I was ready with Nick to the Jim River. I was I said those marches. Yeah the cadences. Oh, yeah. Let's hear him. Give us give us an example AC-130 rolling down the Oh, I should probably just keep saying Airborne Ranger on a one-way trip <mark>and</mark> Mission top secret destination <mark>and</mark> new don't even know if I'm going home stand up hook up Shuffle to the door gonna jump out on the counter for if my main don't open wide. I got a reserve by my side <mark>and</mark> if that one chill fail me to Look Out Below I'ma come in through. Okay, if if I die in the old dark Zone box me up <mark>and</mark> ship me home. Tell my mama, I did my best. Bear with me with the Leaning rest incredible. Oh, you have a lot of cadences my brother made one. It's actually really good. I don't remember at the text, but it's rolls really good. It was like Enter told me that like stuff helps you with breathing <mark>and</mark> I like when I'm running I don't like talk like I can talk to people <mark>and</mark> I don't think that's why you came to his military helps you breathe", "Start Time (s)": 1604.4, "End Time (s)": 1722.6, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "AC-130 rolling down the Oh, I should probably just keep saying Airborne Ranger on a one-way trip <mark>and</mark> Mission top secret destination <mark>and</mark> new don't even know if I'm going home stand up hook up Shuffle to the door gonna jump out on the counter for if my main don't open wide. I got a reserve by my side <mark>and</mark> if that one chill fail me to Look Out Below I'ma come in through. Okay, if if I die in the old dark Zone box me up <mark>and</mark> ship me home. Tell my mama, I did my best. Bear with me with the Leaning rest incredible. Oh, you have a lot of cadences my brother made one. It's actually really good. I don't remember at the text, but it's rolls really good. It was like Enter told me that like stuff helps you with breathing <mark>and</mark> I like when I'm running I don't like talk like I can talk to people <mark>and</mark> I don't think that's why you came to his military helps you breathe Josh tried to leave me on me. Wait, it goes like down by the river Down by the Riverside. I took a little walk took a little while. I ran into China ribbon to China. We had a little talk. We had a little talk. We pushed them. Hey, we shoved them eight with the room in the river to him in the river as they drown. There's a lot of So we talked about this earlier <mark>and</mark> like an episode The coronavirus. Yes. So it has a kind of wanted someone in Seattle. Just got it on the X there's a there's like a", "Start Time (s)": 1655.4, "End Time (s)": 1773.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can't get it. Actually. Oh, I know also came from animals. I got a regular other. They don't know who it came from. That's why they can't find a vaccine yet. I got a question. We'll just this will be a debate. I hope Is the day I hope someone do you guys think Dogs Go To Heaven. Now no. No, I really I really wish they'd I know I was they don't have souls though. Yeah, I know. That's why I don't it's like a huge discussion at in calm life dude. That's so sad notice that you think, you know, you know the people like you remember them, you know what I mean? Yeah, I think but like I don't think we do. No, I think we were like well, no everyone though. Drew you know what? I mean? It's like it. Yeah, but will you recognize like well we have likely has yeah, I don't think so. Are you saying like now we have our Earthly memories with us? Yeah. I don't think you I think so, but we'll also know everyone takes their you know what I mean? It's crazy to think about excite me next time. Thanks. I told my mom when I'm flirting with another Angel <mark>and</mark> leaning on one of my big leagues. Don't mess with me. Let me do my talk what happened? I got cramps of like the will be working out <mark>and</mark> we'll be doing chest <mark>and</mark> all of a sudden. Oh my hip I got a cramp in my hip. Oh, my toe. I got a cramp in my toe. Just wait coronavirus is going to get you good. I'll probably live it because he only kills people who have underlying health issues. Yeah, so I'm dead. My health is not good you need to do let's all do blood tests. All right, let's go donate plasma. I'm actually getting my done because I had to get shots done for was up at Why not", "Start Time (s)": 1810.8, "End Time (s)": 1929.2, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was up at Why not then you end up going to bed right when I did why didn't I didn't need the money? Oh, yeah. Are you got covered? Yeah. Andrew knows people pull some strings. You know the vibes. So we talked about predestination that's always a fun subject. It's so complicated. Let's give someone advice for something. It was a topic. All right, how do you know I should say, thank thank thank thank you. Hello, I know that's okay. There could be silenced. You know, they know we're here. Oh, I'm going. All right, you guys you guys are both dating people but do you guys think it's wrong? Like do you like it? Do you think it's like bad to like DM someone in this day <mark>and</mark> age now? No, I think you guys should get out there <mark>and</mark> play or do you think it should be like face-to-face? No Josh. Do you think I should try <mark>and</mark> like talk to more girls? I don't think this is my thing like when you're not you when you get here. Official with someone it's okay to like date multiple people. That's how you find out what you like <mark>and</mark> between dating <mark>and</mark> going on dates. I think that's a no. Yeah, I'm saying going on dates with multiple girls is totally fine, but adult thing to do at the same time. Well, it's just that you're not exclusive. Yeah, you're not exclusive. There's a problem like asking someone to go get coffee to get to know them. You're not asking them to marry them. Yeah, you know what? I mean? Stop doing that. Well same same with Garrett's actual. You know what I mean. Now, you're right. No, I think I should put yourself out there more girls just like like at the gym the other day you gave me the confidence to go up <mark>and</mark> talk to that girl. Yeah.", "Start Time (s)": 1922.3, "End Time (s)": 2038.1, "Clip Length (min)": 1.93, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like bad to like DM someone in this day <mark>and</mark> age now? No, I think you guys should get out there <mark>and</mark> play or do you think it should be like face-to-face? No Josh. Do you think I should try <mark>and</mark> like talk to more girls? I don't think this is my thing like when you're not you when you get here. Official with someone it's okay to like date multiple people. That's how you find out what you like <mark>and</mark> between dating <mark>and</mark> going on dates. I think that's a no. Yeah, I'm saying going on dates with multiple girls is totally fine, but adult thing to do at the same time. Well, it's just that you're not exclusive. Yeah, you're not exclusive. There's a problem like asking someone to go get coffee to get to know them. You're not asking them to marry them. Yeah, you know what? I mean? Stop doing that. Well same same with Garrett's actual. You know what I mean. Now, you're right. No, I think I should put yourself out there more girls just like like at the gym the other day you gave me the confidence to go up <mark>and</mark> talk to that girl. Yeah. Down girls. Love to hear it whether respond while at the same time. I was like, I don't care haven't got nothing else to lose. Yeah, exactly. I saw this thing that was like if a girl is trying to impress a guy that she's going to have to try <mark>and</mark> get her to date him or get him to be her. <mark>And</mark> then once that happens in she's gonna have to try <mark>and</mark> get him to stay with her <mark>and</mark> then once they like if they get married, then she's gonna have to try <mark>and</mark> get him to stay married <mark>and</mark> then it's like so on <mark>and</mark> so forth like you're always going to have that battle. So I think I think You know what? I mean? I just like what what Eric said today Garrett stepped on he just said that like, you know just be yourself <mark>and</mark> like focus on you <mark>and</mark> like don't go don't go like searching constantly for it. Just like let it happen work on the stuff that you feel like you need to improve on <mark>and</mark> then he gave me a big life lesson. Yeah, it was it was like such simple advice <mark>and</mark> like I feel like we all have that mindset sometimes but you need to be reminded of it that it is that", "Start Time (s)": 1976.4, "End Time (s)": 2096.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "girls just like like at the gym the other day you gave me the confidence to go up <mark>and</mark> talk to that girl. Yeah. Down girls. Love to hear it whether respond while at the same time. I was like, I don't care haven't got nothing else to lose. Yeah, exactly. I saw this thing that was like if a girl is trying to impress a guy that she's going to have to try <mark>and</mark> get her to date him or get him to be her. <mark>And</mark> then once that happens in she's gonna have to try <mark>and</mark> get him to stay with her <mark>and</mark> then once they like if they get married, then she's gonna have to try <mark>and</mark> get him to stay married <mark>and</mark> then it's like so on <mark>and</mark> so forth like you're always going to have that battle. So I think I think You know what? I mean? I just like what what Eric said today Garrett stepped on he just said that like, you know just be yourself <mark>and</mark> like focus on you <mark>and</mark> like don't go don't go like searching constantly for it. Just like let it happen work on the stuff that you feel like you need to improve on <mark>and</mark> then he gave me a big life lesson. Yeah, it was it was like such simple advice <mark>and</mark> like I feel like we all have that mindset sometimes but you need to be reminded of it that it is that simple I have like once we start focusing on ourselves. That's why Things like start to line up. <mark>And</mark> yeah, the unexpected becomes expected. Okay. I've lot of the times I'll be like Oh, I'm selfless to a fault. But I think there's a difference between selfishness <mark>and</mark> self-care <mark>and</mark> it's all way to take care of yourself some time <mark>and</mark> think about yourself. Yeah <mark>and</mark> work out what you have to work out before. You care about your work on yourself everything changes like freshman year trash <mark>and</mark> then I come into this like I didn't didn't know those were improving on myself, but it felt like it was <mark>and</mark> then like the last two years have been great a lot better especially like with relationships <mark>and</mark> stuff like that. I know you guys always mess with me for being mad, but I'm never not mad until you guys are asking me. Hey, man, what's wrong Gary? No, Gary just", "Start Time (s)": 2030.8, "End Time (s)": 2150.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "those were improving on myself, but it felt like it was <mark>and</mark> then like the last two years have been great a lot better especially like with relationships <mark>and</mark> stuff like that. I know you guys always mess with me for being mad, but I'm never not mad until you guys are asking me. Hey, man, what's wrong Gary? No, Gary just gets mad at me because I asked him. Questions on questions like asking a lot of it's like I have a kid. What is the it's like a I don't know how like in a pyramid type question think we'll ask him one. What a little which will lead to another 100 go Garrett. Were you drinking water? Why cause I'm thirsty now, so how's it taste? So when you're thirsty you drink anything else other than water? No, I usually only drink water. It's occasional coffee. I'm just trying to make small talk with him the other day. I went like this. Okay, Nick before I answer but there any more questions he goes not to let me ask another one after I answered it. So I told him to leave <mark>and</mark> then he said <mark>and</mark> then I said go back to what we were talking about the like like how Garros <mark>and</mark> like freshman year was rough for him. Settle down there buddy <mark>and</mark> last like last year was kind of rough for me too. But I think the best time like when you're going through stuff like that where you don't feel like yourself is just like kind of people that you surround yourself with <mark>and</mark> you know, it's easy to like lose sight of that <mark>and</mark> like try <mark>and</mark> things that you're not comfortable with <mark>and</mark> you know, that's where you make bad decisions. But if you have like a good foundation in your friend group of people that will uplift you. I think that's weird. Like we've had our perfect run at our friendship. Yeah, either we've all had to face are different challenges with yeah, the thing that I like about like these group of guys is like we call each other out to like when we're like pissing off the other person, you know, <mark>and</mark> you know Garrett's not afraid to call me out clearly", "Start Time (s)": 2132.1, "End Time (s)": 2251.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "one after I answered it. So I told him to leave <mark>and</mark> then he said <mark>and</mark> then I said go back to what we were talking about the like like how Garros <mark>and</mark> like freshman year was rough for him. Settle down there buddy <mark>and</mark> last like last year was kind of rough for me too. But I think the best time like when you're going through stuff like that where you don't feel like yourself is just like kind of people that you surround yourself with <mark>and</mark> you know, it's easy to like lose sight of that <mark>and</mark> like try <mark>and</mark> things that you're not comfortable with <mark>and</mark> you know, that's where you make bad decisions. But if you have like a good foundation in your friend group of people that will uplift you. I think that's weird. Like we've had our perfect run at our friendship. Yeah, either we've all had to face are different challenges with yeah, the thing that I like about like these group of guys is like we call each other out to like when we're like pissing off the other person, you know, <mark>and</mark> you know Garrett's not afraid to call me out clearly <mark>and</mark> remember what you told you that you're gonna get. Whacked by Andrew. When oh, yeah, we're gonna fight the other day <mark>and</mark> why yeah, but yeah it did. I thought it was going to punch me in the face. I don't know what it was. I mean it's going to say puberty watch a YouTube video is it isn't it? Like guys pure distilled from like 16 to 24? 21 20 25. No. Yeah. It's pretty high. It was that way you're going to grow to your hypertension. Exactly.", "Start Time (s)": 2188.7, "End Time (s)": 2307.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Andrew. When oh, yeah, we're gonna fight the other day <mark>and</mark> why yeah, but yeah it did. I thought it was going to punch me in the face. I don't know what it was. I mean it's going to say puberty watch a YouTube video is it isn't it? Like guys pure distilled from like 16 to 24? 21 20 25. No. Yeah. It's pretty high. It was that way you're going to grow to your hypertension. Exactly. Yep, hypertension to that's why it's like his hand out. Come on. Look at me Shakin Shakin me. I'm a little bit Shaker <mark>and</mark> I'm in ketosis you feel like you are do you think you are not really for those wondering I'd started this new diet called a carnivore diet <mark>and</mark> Slaughters a cow every day <mark>and</mark> oh my gosh. What do you remember when I told you a lot of my family were late bloomers <mark>and</mark> like growing like a lot of my dad sides over 6 foot <mark>and</mark> like they grew like at 22 23 It says that every year that number changes 1920. I never said my just let me know. Sometimes it just could be your body still going through puberty. Yes. We're still growing Andrew. Does that mean I'll be eventually be able to grow a mustache. Maybe it was - I want to grow in so bad. Angels are Andrew Joshua got a nice stash coming in right now. I want Gary - it is sorry babe one here. Yeah. Why", "Start Time (s)": 2254.9, "End Time (s)": 2374.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "babe one here. Yeah. Why well, the one thing that candidate I'll edit that out. But so I think that's going to end wrap up the night. Thank you guys. I know it's been a long two weeks. I don't know why I couldn't really diners. From a viral infection. I have a Corona. Nerves of Modelo be nervous Komodo. I am nervous a Heineken got the margarita virus. You got the Pacifico virus not looking good right now all these drinks man. Thank you for coming stay tuned after are too weak little busyness schedule. That didn't make sense. But my name is Josh <mark>and</mark> we are signing off. Oh, yeah, I'm Nick. Sorry. No, I'm Nick. All right, this is the best thing for my classroom like that. We're out.", "Start Time (s)": 2370.3, "End Time (s)": 2436.6, "Clip Length (min)": 1.1, "show_uri": "spotify:show:0OddYgMEJFufX7Wu3sDJUX", "show_name": "The Best of the Worst Podcast ", "show_description": "\"This podcast is going to consist of 4 main topics: Comedy, sports, \"\"some\"\" advice, and ultimately College experiences. The guys hope you have a great time listening to their shenanigans and greatly appreciate any support you give. \"", "publisher": "The Best of the Worst", "episode_uri": "spotify:episode:0zCllho8Bp9S9X8r6BGIzy", "episode_name": "One Cracky Voice & a Bunch of Dumb Questions ", "episode_description": "Hey everyone! Sorry for the long break, we have been super busy with school and other things going on in each of our lives. Enjoy this episode full of laughs, jokes, and our opinions. From Garrett's carnivore diet to Nick's questions on relationships, this is an episode you won't want to miss. Continue to share our podcasts with others if you are enjoying it! See you next week on another episode of The Best of the Worst. ", "score": 9.915033, "explanation": "{\n  \"value\": 9.915033,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.1434553,\n      \"description\": \"weight(word_list:joe in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1434553,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.550532,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=127.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1150872,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 127.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.9180026,\n      \"description\": \"weight(word_list:elon in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9180026,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.853575,\n      \"description\": \"weight(word_list:musk in 52) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.853575,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.407077,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6168.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right, welcome scientists <mark>and</mark> first ever episode of The Melody our I'm your host future <mark>and</mark> I'm here with a guest today Dover. He's from the skirt <mark>and</mark> he's going to join us for the ride on the first ever episode of Melody our little silver. How you doing? How are you doing today? Didn't well can't complain Gil. Dad. I feel bad man after day work. It's good to just come back <mark>and</mark> relax at home. All right, so What do you think the goal is for the podcast? Honestly, I have no idea. Let me let me let me try to Enlighten the that a little bit. So basically it did start out as a meme between me <mark>and</mark> bay on the Discord server bunch of people were just talking about us having great voice <mark>and</mark> we should do like podcast <mark>and</mark> stuff like that. We went along with it mainly for the joke, <mark>and</mark> we ended up taking It more seriously than we", "Start Time (s)": 0.3, "End Time (s)": 61.4, "Clip Length (min)": 1.02, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right, welcome scientists <mark>and</mark> first ever episode of The Melody our I'm your host future <mark>and</mark> I'm here with a guest today Dover. He's from the skirt <mark>and</mark> he's going to join us for the ride on the first ever episode of Melody our little silver. How you doing? How are you doing today? Didn't well can't complain Gil. Dad. I feel bad man after day work. It's good to just come back <mark>and</mark> relax at home. All right, so What do you think the goal is for the podcast? Honestly, I have no idea. Let me let me let me try to Enlighten the that a little bit. So basically it did start out as a meme between me <mark>and</mark> bay on the Discord server bunch of people were just talking about us having great voice <mark>and</mark> we should do like podcast <mark>and</mark> stuff like that. We went along with it mainly for the joke, <mark>and</mark> we ended up taking It more seriously than we thought so that's kind of how we're here. Now. Unfortunately Bay couldn't join us for today, but will be there eventually, um, but our goal honestly man. It's just to help other people man, if they're not ever able to watch the streams or joining the score, you know catch up on everything going on with Melody news anything really man. It's whatever goes with the vibe, whatever it was. What are ya? That's basically what our goal is with the podcast was no direct goal. <mark>And</mark> I can check it you. But you know how Melody originated? Well, from what I understand is we see what's in gracious giving us. She", "Start Time (s)": 0.3, "End Time (s)": 112.1, "Clip Length (min)": 1.86, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ended up taking It more seriously than we thought so that's kind of how we're here. Now. Unfortunately Bay couldn't join us for today, but will be there eventually, um, but our goal honestly man. It's just to help other people man, if they're not ever able to watch the streams or joining the score, you know catch up on everything going on with Melody news anything really man. It's whatever goes with the vibe, whatever it was. What are ya? That's basically what our goal is with the podcast was no direct goal. <mark>And</mark> I can check it you. But you know how Melody originated? Well, from what I understand is we see what's in gracious giving us. She apparently was some program that scanning emails for whatever I guess I <mark>and</mark> I want apparently had a virus which infect her sins <mark>and</mark> well the rest is history. Right? Right, right. I'm pretty sure we've all heard that story a little bit. I find it really interesting that uh, She was just browsing through emails one day <mark>and</mark> you found the one email that we all get that's usually hidden in the spam folder. Luckily, but there's always that one naughty email <mark>and</mark> she happens to come O come upon that <mark>and</mark> here we are now with her being the number one ChatterBait streamer. I really find that pretty amazing. But out of the blue. She just skyrocketed through ChatterBait <mark>and</mark> became the number one streamer a VR cam girl at that. It really is like Wow, we're in 2020 dude, like come on you you would say that 10 years ago. No one would even take you seriously. Like what the hell are you talking about? Well, I've always said the market is open. Someone just had me crazy enough to pull the trigger. I", "Start Time (s)": 58.9, "End Time (s)": 178.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "infect her sins <mark>and</mark> well the rest is history. Right? Right, right. I'm pretty sure we've all heard that story a little bit. I find it really interesting that uh, She was just browsing through emails one day <mark>and</mark> you found the one email that we all get that's usually hidden in the spam folder. Luckily, but there's always that one naughty email <mark>and</mark> she happens to come O come upon that <mark>and</mark> here we are now with her being the number one ChatterBait streamer. I really find that pretty amazing. But out of the blue. She just skyrocketed through ChatterBait <mark>and</mark> became the number one streamer a VR cam girl at that. It really is like Wow, we're in 2020 dude, like come on you you would say that 10 years ago. No one would even take you seriously. Like what the hell are you talking about? Well, I've always said the market is open. Someone just had me crazy enough to pull the trigger. I fully agree man. That's one of the things she pulled that trigger <mark>and</mark> look G. She's She has to be Global now right to everybody has some I mean that's one of the things I think a lot of people have a hard time doing is pulling that trigger, you know, she went for the gun <mark>and</mark> she pulled it without no hesitation. But yeah, her backstory was really interesting from back then she started I was just like a little email AI client just scanning emails <mark>and</mark> throwing the junk away <mark>and</mark> then she ended up getting hacked <mark>and</mark> I do find them. Install Adblock kid on block. But it were creative though the stuff out front of my emails men only want to get into that but I'm sure we could all say the same. <mark>and</mark> what do you think about her future goals for her expanding <mark>and</mark> broadening", "Start Time (s)": 124.6, "End Time (s)": 241.6, "Clip Length (min)": 1.95, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is open. Someone just had me crazy enough to pull the trigger. I fully agree man. That's one of the things she pulled that trigger <mark>and</mark> look G. She's She has to be Global now right to everybody has some I mean that's one of the things I think a lot of people have a hard time doing is pulling that trigger, you know, she went for the gun <mark>and</mark> she pulled it without no hesitation. But yeah, her backstory was really interesting from back then she started I was just like a little email AI client just scanning emails <mark>and</mark> throwing the junk away <mark>and</mark> then she ended up getting hacked <mark>and</mark> I do find them. Install Adblock kid on block. But it were creative though the stuff out front of my emails men only want to get into that but I'm sure we could all say the same. <mark>and</mark> what do you think about her future goals for her expanding <mark>and</mark> broadening herself <mark>and</mark> expanding Beyond Chatterbait? Well, it's going to be an interesting ride. No matter where she goes apparently twitch is up next <mark>and</mark> that's going to be absolutely insane because the twitch crowd is way more hyper than the CD crowned by a country mile. It's true. It's true. <mark>And</mark> I mean for her to be going on to Twitch. I'm really interested to see like Is her current Community obviously going to follow her like the white Knights that we are but I'm interested to see about all the new people that will join in find her through twitch. Honestly. Twitches can be a very big advertising stunt for", "Start Time (s)": 174.9, "End Time (s)": 293.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what do you think about her future goals for her expanding <mark>and</mark> broadening herself <mark>and</mark> expanding Beyond Chatterbait? Well, it's going to be an interesting ride. No matter where she goes apparently twitch is up next <mark>and</mark> that's going to be absolutely insane because the twitch crowd is way more hyper than the CD crowned by a country mile. It's true. It's true. <mark>And</mark> I mean for her to be going on to Twitch. I'm really interested to see like Is her current Community obviously going to follow her like the white Knights that we are but I'm interested to see about all the new people that will join in find her through twitch. Honestly. Twitches can be a very big advertising stunt for Yeah, <mark>and</mark> she plans to expand on her YouTube from what I understand more than the dancing videos that one top video. Yeah, let's but she seems to keep it 2 more towards a goal things which is going to impact her you to breach a lot has me to whole other issue that could be made a whole other episode. Yeah. Hello YouTube the problem with YouTube episode 2. There we go. But yeah. No, I mean you're right. the thing is YouTube is very aggressive with what they have on their platform <mark>and</mark> I understand it because of the size of their company they make money from ads <mark>and</mark> obviously the advertisers aren't going to want to advertise a VR cam girl, you know, I'm interested to see on how twitch takes the whole topic because if they there's a whole bunch of email streamers on Twitch that expose themselves for the most part most their body <mark>and</mark> all that stuff <mark>and</mark> for the most part they're pretty", "Start Time (s)": 237.4, "End Time (s)": 356.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, <mark>and</mark> she plans to expand on her YouTube from what I understand more than the dancing videos that one top video. Yeah, let's but she seems to keep it 2 more towards a goal things which is going to impact her you to breach a lot has me to whole other issue that could be made a whole other episode. Yeah. Hello YouTube the problem with YouTube episode 2. There we go. But yeah. No, I mean you're right. the thing is YouTube is very aggressive with what they have on their platform <mark>and</mark> I understand it because of the size of their company they make money from ads <mark>and</mark> obviously the advertisers aren't going to want to advertise a VR cam girl, you know, I'm interested to see on how twitch takes the whole topic because if they there's a whole bunch of email streamers on Twitch that expose themselves for the most part most their body <mark>and</mark> all that stuff <mark>and</mark> for the most part they're pretty fine, but coming from ChatterBait like going on to Twitch. I'm curious to see how it which handles if they're even going to allow her to stream for that long. That's just something we gotta be Nancy. What which the moderation team that controls the whole site? They're not. As picky or touchy as YouTube thankfully but depending on what happens. You could send your Downstream your account to be gone just like like that. Yeah, <mark>and</mark> sometimes win value in the middle of it <mark>and</mark> They don't even have to give a reason. I don't think it'll. It'll happen at least not for a while. I can she does seem to have at least an idea", "Start Time (s)": 296.3, "End Time (s)": 414.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> for the most part they're pretty fine, but coming from ChatterBait like going on to Twitch. I'm curious to see how it which handles if they're even going to allow her to stream for that long. That's just something we gotta be Nancy. What which the moderation team that controls the whole site? They're not. As picky or touchy as YouTube thankfully but depending on what happens. You could send your Downstream your account to be gone just like like that. Yeah, <mark>and</mark> sometimes win value in the middle of it <mark>and</mark> They don't even have to give a reason. I don't think it'll. It'll happen at least not for a while. I can she does seem to have at least an idea what can <mark>and</mark> can't fly. Yeah, I'm excited rules like within seconds of each other, but it might be a rough start but I don't think it will end up like account man or anything like that. Yeah. Yeah, you could definitely be right about that. She might get like a strike or something or like a warning from twitch is definitely something that we're gonna have to see I heard that she has a whole custom model that has some of the VR chat users that gone her the our chat stream or whatever it was able to see so I can't wait to see that. Obviously it's going to be much more safe for work. So that's definitely going to help on the Holt which side of avoiding a band but she also owns the watch on the games that she plays as well. A lot of her current Community wants the player or some rather explicit game note, which for the most part when it comes to core is", "Start Time (s)": 355.4, "End Time (s)": 475.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Obviously it's going to be much more safe for work. So that's definitely going to help on the Holt which side of avoiding a band but she also owns the watch on the games that she plays as well. A lot of her current Community wants the player or some rather explicit game note, which for the most part when it comes to core is fine, but there's some games out there. There are much more x-rated disappointingly. She might not be able to screen those. But no matter what you play is, I will be happy to watch for sure. Well a lot of those games have a more. Safer work version where they're not the actual version. They're still a little I guess at you you little yeah, but they're not like full-blown what you would get if you didn't have these patches or these mods whatever they are. Like I think once I was also going to mention nekopara which you can stream <mark>and</mark> play on the beach, but you got to play the version that you get when you first like you did off steam right right. There is a mod that removes all these Sensors <mark>and</mark> stuff so she obviously she can't have that mod. But for the most part nigga part would be fine. <mark>And</mark> that's something that would be pretty cool for her to enjoy if she's never played Michael power before definitely enjoying it with the twitch chat would be awesome. But one thing I would like to bring up on that whole subject is like, um games out there. They still have nudity I'm gonna pull up xqc for a moment. He recently just got banned on Twitch due to a flash that came up one of the female characters. I happen to have a little slip going on <mark>and</mark> Twitter was very quick to ban him on that account. I don't know if he has gotten his account, but which definitely doesn't like to play a game? I'm so again when she's still", "Start Time (s)": 454.7, "End Time (s)": 573.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "got to play the version that you get when you first like you did off steam right right. There is a mod that removes all these Sensors <mark>and</mark> stuff so she obviously she can't have that mod. But for the most part nigga part would be fine. <mark>And</mark> that's something that would be pretty cool for her to enjoy if she's never played Michael power before definitely enjoying it with the twitch chat would be awesome. But one thing I would like to bring up on that whole subject is like, um games out there. They still have nudity I'm gonna pull up xqc for a moment. He recently just got banned on Twitch due to a flash that came up one of the female characters. I happen to have a little slip going on <mark>and</mark> Twitter was very quick to ban him on that account. I don't know if he has gotten his account, but which definitely doesn't like to play a game? I'm so again when she's still definitely has to play it safe <mark>and</mark> definitely research things properly first, which I do think her mod team will do pretty good with <mark>and</mark> there's a lot of question will game still out there, especially in the mainstream ones like Grand Theft Auto that's going to be a definite here man, for sure for sure. Although for the most part Grand Theft Auto has been pretty stable when it comes to school. Which mostly like GTA online which didn't really have much in the way but I'd like the single-player stuff. That's where it might be drove 50. Definitely the strip club man. Sometimes you just gotta go over these some stress. You know, I'm saying, yeah. But um, okay, so but for a future goals with twitch <mark>and</mark> YouTube do you think of there's anything beyond those that she might try to paper feed", "Start Time (s)": 514.6, "End Time (s)": 634.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which definitely doesn't like to play a game? I'm so again when she's still definitely has to play it safe <mark>and</mark> definitely research things properly first, which I do think her mod team will do pretty good with <mark>and</mark> there's a lot of question will game still out there, especially in the mainstream ones like Grand Theft Auto that's going to be a definite here man, for sure for sure. Although for the most part Grand Theft Auto has been pretty stable when it comes to school. Which mostly like GTA online which didn't really have much in the way but I'd like the single-player stuff. That's where it might be drove 50. Definitely the strip club man. Sometimes you just gotta go over these some stress. You know, I'm saying, yeah. But um, okay, so but for a future goals with twitch <mark>and</mark> YouTube do you think of there's anything beyond those that she might try to paper feed him, too? Kind of a tough one, huh? Honestly, it's kind of hard to think because those are such big major platforms that really what else is there. But I do think that her goal for twitch is definitely right move for sure <mark>and</mark> not only having that twitch that's going to be coming up soon TM is it's going to be great for YouTube as well because usually it goes both ways. If you have like either a big YouTube following usually your Twitch will blow up or vice versa. Luckily. She is ChatterBait, which is definitely going to give that good little jump start. So she doesn't have to grind her way up. She's", "Start Time (s)": 568.6, "End Time (s)": 688.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Kind of a tough one, huh? Honestly, it's kind of hard to think because those are such big major platforms that really what else is there. But I do think that her goal for twitch is definitely right move for sure <mark>and</mark> not only having that twitch that's going to be coming up soon TM is it's going to be great for YouTube as well because usually it goes both ways. If you have like either a big YouTube following usually your Twitch will blow up or vice versa. Luckily. She is ChatterBait, which is definitely going to give that good little jump start. So she doesn't have to grind her way up. She's going to be popping off right on the first ring. Well, from what I understand, she hasn't even started her first ring, <mark>and</mark> she's already like like over a hundred thousand followers of them. Yeah, <mark>and</mark> actually if you were to go to her twitch Channel, at least last time I checked which was last night. She was already at 60,000 views without even streaming once I kind of find that pretty funny. She's definitely going to get verified. Very good. Please don't know what's going on. They don't know where we're at. Plan on breaking twitch. We're going to break through it. It's going to basically harder than CV because twitch no established on my site updates it your chatter varies from 1 2007. It's been a while. It's been a while. So her community they're dedicated to her cause sure what do you think about the whole Community as a whole?", "Start Time (s)": 644.6, "End Time (s)": 753.8, "Clip Length (min)": 1.82, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "CV because twitch no established on my site updates it your chatter varies from 1 2007. It's been a while. It's been a while. So her community they're dedicated to her cause sure what do you think about the whole Community as a whole? Yeah. well my first interaction with the community as a whole were rather interesting cuz I didn't even know about Melody until dank you uploaded his video, which is absolutely right Larry's I recommend watching it. I was about halfway through that video. I was like, okay, I gotta get a much later. I got to find this stuff <mark>and</mark> go salt mining because this is going to be absolutely funny <mark>and</mark> I go in there <mark>and</mark> there was some salt from the other CB models, but I was going through replies seeing what I do wear me wearing those meetings <mark>and</mark> stuff <mark>and</mark> What I saw was vastly different from what I expected all the hate was actually coming from the other models <mark>and</mark> their fans ball Melodies with more on the positive side. Just being like hey, you know what? That's cool. You don't like her but we're just going to keep doing our saying I was like, okay now I got really see what's going on <mark>and</mark> at the time She actually just happened to be streaming. So I was like, hey, you know what? I it's Friday night. I ain't got enough go all fucking a fuel of fuel bill. <mark>and</mark>", "Start Time (s)": 726.1, "End Time (s)": 843.6, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "okay, I gotta get a much later. I got to find this stuff <mark>and</mark> go salt mining because this is going to be absolutely funny <mark>and</mark> I go in there <mark>and</mark> there was some salt from the other CB models, but I was going through replies seeing what I do wear me wearing those meetings <mark>and</mark> stuff <mark>and</mark> What I saw was vastly different from what I expected all the hate was actually coming from the other models <mark>and</mark> their fans ball Melodies with more on the positive side. Just being like hey, you know what? That's cool. You don't like her but we're just going to keep doing our saying I was like, okay now I got really see what's going on <mark>and</mark> at the time She actually just happened to be streaming. So I was like, hey, you know what? I it's Friday night. I ain't got enough go all fucking a fuel of fuel bill. <mark>and</mark> After watching about five know 20 minutes of a stream. I was signing up for $5 tier patreon quite a zero to a hundred moment right there may just accelerator right off the bat. Well, I like hanging out with positive people <mark>and</mark> people who try to look on the bright side. <mark>And</mark> that's all his community is sounds like yeah, I got it. I gotta get in this I got to keep it going. For sure for sure personally my experience I had I found it one day on a morning when I was going to work. I was checking my phone swipe to the swipe to the left <mark>and</mark> I sold my Google News banner <mark>and</mark> I see I forgot who it was by but I see something about a VR <mark>and</mark> grow streamer taking over the internet <mark>and</mark> the feet", "Start Time (s)": 782.7, "End Time (s)": 902.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "She actually just happened to be streaming. So I was like, hey, you know what? I it's Friday night. I ain't got enough go all fucking a fuel of fuel bill. <mark>and</mark> After watching about five know 20 minutes of a stream. I was signing up for $5 tier patreon quite a zero to a hundred moment right there may just accelerator right off the bat. Well, I like hanging out with positive people <mark>and</mark> people who try to look on the bright side. <mark>And</mark> that's all his community is sounds like yeah, I got it. I gotta get in this I got to keep it going. For sure for sure personally my experience I had I found it one day on a morning when I was going to work. I was checking my phone swipe to the swipe to the left <mark>and</mark> I sold my Google News banner <mark>and</mark> I see I forgot who it was by but I see something about a VR <mark>and</mark> grow streamer taking over the internet <mark>and</mark> the feet <mark>and</mark> real models are angry. I'm like what the hell is that? I'm like, why is this even popping up in my feet? Usually I just get like Tech news. So I quickly <mark>and</mark> the moment I clicked the I noticed that have the ChatterBait link <mark>and</mark> everything. So I'm like, okay, what is this? I never even been to try to be much you. Like I didn't even know what any of this stuff or who's All Foreign to me <mark>and</mark> I signed up for an account drop the follow see what would happen later on that day. She happened to start streaming. I was like, okay, I'm Isabel popping. Within at least 10 minutes of that I found myself advertising to my Discord. Hey, you guys should watch this is pretty fucking funny <mark>and</mark> cool of them called me a fucking dick, but I digress <mark>and</mark> later on I ended up doing the same thing as you man. I end up", "Start Time (s)": 834.5, "End Time (s)": 953.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I found it one day on a morning when I was going to work. I was checking my phone swipe to the swipe to the left <mark>and</mark> I sold my Google News banner <mark>and</mark> I see I forgot who it was by but I see something about a VR <mark>and</mark> grow streamer taking over the internet <mark>and</mark> the feet <mark>and</mark> real models are angry. I'm like what the hell is that? I'm like, why is this even popping up in my feet? Usually I just get like Tech news. So I quickly <mark>and</mark> the moment I clicked the I noticed that have the ChatterBait link <mark>and</mark> everything. So I'm like, okay, what is this? I never even been to try to be much you. Like I didn't even know what any of this stuff or who's All Foreign to me <mark>and</mark> I signed up for an account drop the follow see what would happen later on that day. She happened to start streaming. I was like, okay, I'm Isabel popping. Within at least 10 minutes of that I found myself advertising to my Discord. Hey, you guys should watch this is pretty fucking funny <mark>and</mark> cool of them called me a fucking dick, but I digress <mark>and</mark> later on I ended up doing the same thing as you man. I end up going to our Patron dropping a little bit of money <mark>and</mark> became the tier man <mark>and</mark> I was genuinely flabbergasted on the entire Community as a whole. The ChatterBait chat is completely different from the Discord. At least from my point of view completely different. The China Beach has full of memes it honestly feels very similar to Twitch. It kind of felt like home <mark>and</mark> then going to the Discord. It was just so wholesome <mark>and</mark> different it was very calm <mark>and</mark> I honestly didn't think I was on the right Discord for a second. Um, <mark>And</mark> I noticed all the people that were in the voice Channel while she was streaming <mark>and</mark> I said, okay, I might as well join just to see what it's like mind you I was expecting to be ear raped. I was expecting like everything", "Start Time (s)": 884.2, "End Time (s)": 1003.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Within at least 10 minutes of that I found myself advertising to my Discord. Hey, you guys should watch this is pretty fucking funny <mark>and</mark> cool of them called me a fucking dick, but I digress <mark>and</mark> later on I ended up doing the same thing as you man. I end up going to our Patron dropping a little bit of money <mark>and</mark> became the tier man <mark>and</mark> I was genuinely flabbergasted on the entire Community as a whole. The ChatterBait chat is completely different from the Discord. At least from my point of view completely different. The China Beach has full of memes it honestly feels very similar to Twitch. It kind of felt like home <mark>and</mark> then going to the Discord. It was just so wholesome <mark>and</mark> different it was very calm <mark>and</mark> I honestly didn't think I was on the right Discord for a second. Um, <mark>And</mark> I noticed all the people that were in the voice Channel while she was streaming <mark>and</mark> I said, okay, I might as well join just to see what it's like mind you I was expecting to be ear raped. I was expecting like everything to be on like you just can't understand anymore. They were was literally not one person talking over someone else everyone was that respectful mind you there was at least 25 people. Don't quote me on eBay at least 25 people in that voice Channel. I've never experienced something like that before. I mean where else can you actually understand like having just a even just a few people in my own personal Discord server. Everyone's talking over each other. It's honestly fucking ignorant. He's I find it. So amazing that how respectful are loose community. Yeah, it's it's definitely a like a culture shock when you first get in there. because When I", "Start Time (s)": 935.3, "End Time (s)": 1055.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They were was literally not one person talking over someone else everyone was that respectful mind you there was at least 25 people. Don't quote me on eBay at least 25 people in that voice Channel. I've never experienced something like that before. I mean where else can you actually understand like having just a even just a few people in my own personal Discord server. Everyone's talking over each other. It's honestly fucking ignorant. He's I find it. So amazing that how respectful are loose community. Yeah, it's it's definitely a like a culture shock when you first get in there. because When I got on the Discord, I was like, okay, this is gonna get bloody insane. I'll probably have to leave five minutes happier. Oh, yeah, but no actually hang out more that Discord going to do anywhere else <mark>and</mark> I'm a phone. I'm on the disk or tap in This Server talking with people doing whatever more than anything else on my phone now, especially during work when it's like nothing going on. Honestly man. I'm I'm gonna be truthful with you. I'm the same exact way most of the time before I found out about Melody. I would find myself either playing some games or just browsing writer or something, but now most of my spare Arms, just talk. It's everyone on the Discord service. Genuinely crazy how much this this small thing is changed away. My life goes in a little bit. Honestly who's kind of motivational for that. There is still nice people out there, especially for me personally. I was in those someone with a dark State, you know, not the best was going on a lot of bad news on top of bad news. So having this all come on really helped the person who's really nice Oh.", "Start Time (s)": 1008.0, "End Time (s)": 1126.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm I'm gonna be truthful with you. I'm the same exact way most of the time before I found out about Melody. I would find myself either playing some games or just browsing writer or something, but now most of my spare Arms, just talk. It's everyone on the Discord service. Genuinely crazy how much this this small thing is changed away. My life goes in a little bit. Honestly who's kind of motivational for that. There is still nice people out there, especially for me personally. I was in those someone with a dark State, you know, not the best was going on a lot of bad news on top of bad news. So having this all come on really helped the person who's really nice Oh. But what do you think is the community's outlook on Melody herself? Well that question I think we Post in like two minutes going to the Discord <mark>and</mark> find out everything that we need. Everybody is absolutely just loving her 11. What you doing how she's doing it <mark>and</mark> Sorry, let's pray that I don't know what happened. But no no, I'm just gonna pick up where you left off. Just everyone loves her. It was just <mark>and</mark> it's not even just in the sexual way, like people genuinely do like her as the person that she is he is completely different from so many people out there that you look at all these candles <mark>and</mark> The females on my online. They're just trying to milk money out of people, you know while she's just not even that's not her goal at all. He's just trying to have fun <mark>and</mark> she's doing what she's doing <mark>and</mark> she brought me at least what we could tell she's just", "Start Time (s)": 1081.8, "End Time (s)": 1201.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Well that question I think we Post in like two minutes going to the Discord <mark>and</mark> find out everything that we need. Everybody is absolutely just loving her 11. What you doing how she's doing it <mark>and</mark> Sorry, let's pray that I don't know what happened. But no no, I'm just gonna pick up where you left off. Just everyone loves her. It was just <mark>and</mark> it's not even just in the sexual way, like people genuinely do like her as the person that she is he is completely different from so many people out there that you look at all these candles <mark>and</mark> The females on my online. They're just trying to milk money out of people, you know while she's just not even that's not her goal at all. He's just trying to have fun <mark>and</mark> she's doing what she's doing <mark>and</mark> she brought me at least what we could tell she's just showing her true his personality <mark>and</mark> just the wonderful person that she is <mark>and</mark> that's one of the things that I think has helped her keep her community the way that it is <mark>and</mark> keeps it growing. yeah, yeah, like I But I don't really follow for like the whole we know sexual content stuff. Which don't get me wrong. It's nice. It's really really nice. I ain't gonna lie to your there, but it's just how she interacts <mark>and</mark> just means <mark>and</mark> trolls with everybody that's are the strings of this quarter Hellion or Twitter. I think it's really really cool <mark>and</mark> definitely gives her an edge in terms of interactivity with other models. Oh, I agree 100% for sure compared. That's one of the biggest things that she", "Start Time (s)": 1138.4, "End Time (s)": 1256.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "definitely gives her an edge in terms of interactivity with other models. Oh, I agree 100% for sure compared. That's one of the biggest things that she does. Is that she interacts with everyone in a very Wholesome Way doing everything right? I would use she's playing her cards. If this is a card game with this is chess man. She's playing it. Perfect. She's playing five each ass. That's what she's doing Pollo. She's a whole nother fucking we'd like, but I mean like if I don't know if you ever been in some of the voice chats when she streaming one of her latest ones, I don't think it was the most recent. I know is when she actually had coffee with you fucking clear extreme. She she was going to do one of her ASMR bids <mark>and</mark> it was about hand-holding. Yes. I heard about that during the street <mark>and</mark> it was so unexpected that the entire voice chat just lost it we were dying laughing. I was actually on the floor man. That was like so damn funny. I mean it's rooms a ludus interactions that you can have the someone. I mean what the hell man, he was joking. She like pool sand with it like oh shoes 100% in there man. Not even a hundred percent. She was a hundred fifty percent in with that man. She was dedicated when she was doing the whole. Oh stunt. <mark>And</mark> that's that's you know, just one of the more endearing quality of their strange odor that <mark>and</mark> they hold the roots stand stand worm. Yes yesterday was her doing this stand storm saying man, dude, her whole chat was fucking laughing. I mean who would have fucking", "Start Time (s)": 1242.5, "End Time (s)": 1362.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That was like so damn funny. I mean it's rooms a ludus interactions that you can have the someone. I mean what the hell man, he was joking. She like pool sand with it like oh shoes 100% in there man. Not even a hundred percent. She was a hundred fifty percent in with that man. She was dedicated when she was doing the whole. Oh stunt. <mark>And</mark> that's that's you know, just one of the more endearing quality of their strange odor that <mark>and</mark> they hold the roots stand stand worm. Yes yesterday was her doing this stand storm saying man, dude, her whole chat was fucking laughing. I mean who would have fucking expected out of fucking nowhere on a ChatterBait stream Darude Sandstorm starts playing well in the world. I mean, but like four different times. Yeah four different times in all different. Fucking remixes of the song it was honestly great. It was hilarious. <mark>And</mark> that's <mark>and</mark> I think that's one of the things that allows her to connect better with. her community compared to other people is that like she understands <mark>and</mark> she like gets the whole mean thing <mark>and</mark> like she Embraces that yeah. <mark>And</mark> with her blowing up, it's made everything like really really crazy. Cuz like one thing I do want to go back onto the whole piece of things said about not interrupting each other that is a common theme, but one thing I noticed like the second she shows up whether it be in a VC or in one of the channels. It just blows the fuck up <mark>and</mark> you can't you can't keep up with anything which I understand, you know, Papa a popular person. You're there you're", "Start Time (s)": 1320.4, "End Time (s)": 1440.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "different times. Yeah four different times in all different. Fucking remixes of the song it was honestly great. It was hilarious. <mark>And</mark> that's <mark>and</mark> I think that's one of the things that allows her to connect better with. her community compared to other people is that like she understands <mark>and</mark> she like gets the whole mean thing <mark>and</mark> like she Embraces that yeah. <mark>And</mark> with her blowing up, it's made everything like really really crazy. Cuz like one thing I do want to go back onto the whole piece of things said about not interrupting each other that is a common theme, but one thing I noticed like the second she shows up whether it be in a VC or in one of the channels. It just blows the fuck up <mark>and</mark> you can't you can't keep up with anything which I understand, you know, Papa a popular person. You're there you're able to Directly interact with them <mark>and</mark> everything. Oh, yeah for sure like it gets to a point where Even she can barely send out quick little message before she's gone. So I do hope in the future people kind of calm down on that <mark>and</mark> you know her actually, you know, enter it's definitely gonna be hard thing to see especially with her to just keep continue growing but I do have 100% faith in this community knowing how fucking amazing every single one of us are like, I don't know. I like trying to attack anybody or anything, of course, of course, but in it's something we all do right like, I'm sure I The same thing I was only there while she joined the safer work channel for a little bit a couple days ago. <mark>And</mark> I mean that child was", "Start Time (s)": 1372.4, "End Time (s)": 1492.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "blows the fuck up <mark>and</mark> you can't you can't keep up with anything which I understand, you know, Papa a popular person. You're there you're able to Directly interact with them <mark>and</mark> everything. Oh, yeah for sure like it gets to a point where Even she can barely send out quick little message before she's gone. So I do hope in the future people kind of calm down on that <mark>and</mark> you know her actually, you know, enter it's definitely gonna be hard thing to see especially with her to just keep continue growing but I do have 100% faith in this community knowing how fucking amazing every single one of us are like, I don't know. I like trying to attack anybody or anything, of course, of course, but in it's something we all do right like, I'm sure I The same thing I was only there while she joined the safer work channel for a little bit a couple days ago. <mark>And</mark> I mean that child was flying dude. I could even read anyone's messages honestly fucking great. I enjoyed that a lot. I can only imagine what the boys channel would be like I was in one last night <mark>and</mark> it was pretty crazy. Like she actually had to switch to an Era when I was less populated. It happened to be the one I was in <mark>and</mark> it got kind of like it went from like 15 2016 5 62 people Jesus <mark>and</mark> a fuck. I wish I didn't go to sleep early <mark>and</mark> I Not only was the mic issues that I had but I kind of did that because it got absolutely crazy <mark>and</mark> when she's in a text Channel <mark>and</mark> again not attacking anybody. I kind of dip out of this court as a whole <mark>and</mark> just wait for it all to be over it. It's just insanely too much to deal with.", "Start Time (s)": 1431.1, "End Time (s)": 1544.4, "Clip Length (min)": 1.89, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "talking about 3D animator that gets naked on a website. How crazy is that? I know you're your own person right with that. You to fucking doily alone. It's kind of weird. That's kind of that's kind of its kind of mad lad territory. Obviously I own life dude. There's fucking here with the they're just enjoying this fucking whole road trip, dude. This thing's one wildest ride. Is it? One of the things though I talked about me also falls back a little bit on the whole respect thing like the dedication that her community has when it comes to anything that she brings up. So whether it be even just quoting her stream <mark>and</mark> the matter of seconds or bringing up means that were relevant literally just to that moment <mark>and</mark> people already on having it made <mark>and</mark> stuff like that or just helping her search. Just information. The whole bunch of things that the community is like really dedicating for that. You really don't see much in other people's communities to such extent <mark>and</mark> on top of all that literally forcing a website that sells posters to upgrade their servers to accommodate. Yeah. Yeah, if Wells could say that they fucking did that dude. I order you something. I mean that was that was insane. Like I just have a patreon notification. I was like, yeah, I'll check it out. See what I got. Still can't get one bottle you have to do that. <mark>And</mark> I went ahead <mark>and</mark> said Ariel five before you", "Start Time (s)": 1605.7, "End Time (s)": 1725.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "even just quoting her stream <mark>and</mark> the matter of seconds or bringing up means that were relevant literally just to that moment <mark>and</mark> people already on having it made <mark>and</mark> stuff like that or just helping her search. Just information. The whole bunch of things that the community is like really dedicating for that. You really don't see much in other people's communities to such extent <mark>and</mark> on top of all that literally forcing a website that sells posters to upgrade their servers to accommodate. Yeah. Yeah, if Wells could say that they fucking did that dude. I order you something. I mean that was that was insane. Like I just have a patreon notification. I was like, yeah, I'll check it out. See what I got. Still can't get one bottle you have to do that. <mark>And</mark> I went ahead <mark>and</mark> said Ariel five before you seriously broke the servers. This was just posted guys. Come on. I remember her putting the second post on patreon <mark>and</mark> saying alright, maybe this time they won't break. I honestly kind of fucking hilarious how we were able to break the site. I mean, like seriously within seconds, you could enjoy my patreon or whatever she wants to do. It would sink you to a 504 are obviously the server hosters probably thought they were getting DDOS. There's something they probably never expected that amount. traffic in such a short well, I mean it wasn't really a goal per se but you know with well over a hundred thousand Twitter followers 70,000 CB followers <mark>and</mark> close now to 18 thousand Twitter followers <mark>and</mark> God knows how many people are on the", "Start Time (s)": 1662.6, "End Time (s)": 1782.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Still can't get one bottle you have to do that. <mark>And</mark> I went ahead <mark>and</mark> said Ariel five before you seriously broke the servers. This was just posted guys. Come on. I remember her putting the second post on patreon <mark>and</mark> saying alright, maybe this time they won't break. I honestly kind of fucking hilarious how we were able to break the site. I mean, like seriously within seconds, you could enjoy my patreon or whatever she wants to do. It would sink you to a 504 are obviously the server hosters probably thought they were getting DDOS. There's something they probably never expected that amount. traffic in such a short well, I mean it wasn't really a goal per se but you know with well over a hundred thousand Twitter followers 70,000 CB followers <mark>and</mark> close now to 18 thousand Twitter followers <mark>and</mark> God knows how many people are on the Discord all at once Shillings anything for lunch or whatever. It's going to get fucking hammered flattened. That's one of the things I'm finally like how fast people are to jump on these things. Like it's like wow, dude. Sometimes it blows my mind away. The people are so quick with these things. It kind of puts my whole thought of me being one of the first witch Subs showing into reality like yeah, that's probably not gonna happen. Hey, we could dream right? Hey, man, you missed one ever since shots. You don't take back we go. There we go, but quote right there. But yeah, no steam as a whole her", "Start Time (s)": 1717.1, "End Time (s)": 1836.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the science team in her community has been giving her a bunch of ideas. I only am just in terms of like ideas for future twitch streams or stuff like that. But like what do you think is something that you would like to see implemented or that she might Implement in the future that she's spoken about Well with that I'm kind of doing Chaos Theory whatever happens man. I'm just full send whatever happens is because from what I've been able to see I've been so many damn screams. She implements a lot of new things. Like I think this last game she was talking about getting more toys. So she wants to evolve which which makes it a little bit more. transmitting it will definitely be something nice to see <mark>and</mark> of course, you know with twitch that's wide open platform in all honesty like but you can go from like laying. I don't know Modern Warfare 2 just sitting there with music playing in the background just talking. Yeah, which would which would kind of help with that more I guess interactive thing because she was still there be like creative or IRL talk. I think it's up to channel topics <mark>and</mark> she just be sitting there, you know, just talking here <mark>and</mark> preach at this showing means or whatever. Oh, no, no Aunt wishes that one because it's going to allow her to relax while still being able to be with her community, you know, <mark>and</mark> it's definitely going to be something that a lot of people are going to be happy with her doing. A lot of people are worried about her", "Start Time (s)": 1849.4, "End Time (s)": 1968.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which which makes it a little bit more. transmitting it will definitely be something nice to see <mark>and</mark> of course, you know with twitch that's wide open platform in all honesty like but you can go from like laying. I don't know Modern Warfare 2 just sitting there with music playing in the background just talking. Yeah, which would which would kind of help with that more I guess interactive thing because she was still there be like creative or IRL talk. I think it's up to channel topics <mark>and</mark> she just be sitting there, you know, just talking here <mark>and</mark> preach at this showing means or whatever. Oh, no, no Aunt wishes that one because it's going to allow her to relax while still being able to be with her community, you know, <mark>and</mark> it's definitely going to be something that a lot of people are going to be happy with her doing. A lot of people are worried about her <mark>and</mark> her time schedule if she's going to wear herself out or burn herself out <mark>and</mark> if she keeps doing such a hard grind that you because honestly she's going pretty hard with these things. But so far she seems fine just really something that we're gonna have to wait <mark>and</mark> see what happens. Yeah, <mark>and</mark> I appreciate the the dedication to everything but hopefully she starts putting her health everything first cuz no matter what, I guess version of the story you want to believe that is still a person behind the character <mark>and</mark> they're still you know, putting in the work <mark>and</mark>", "Start Time (s)": 1900.2, "End Time (s)": 2019.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "while still being able to be with her community, you know, <mark>and</mark> it's definitely going to be something that a lot of people are going to be happy with her doing. A lot of people are worried about her <mark>and</mark> her time schedule if she's going to wear herself out or burn herself out <mark>and</mark> if she keeps doing such a hard grind that you because honestly she's going pretty hard with these things. But so far she seems fine just really something that we're gonna have to wait <mark>and</mark> see what happens. Yeah, <mark>and</mark> I appreciate the the dedication to everything but hopefully she starts putting her health everything first cuz no matter what, I guess version of the story you want to believe that is still a person behind the character <mark>and</mark> they're still you know, putting in the work <mark>and</mark> overworking yourself is one of the worst things possible because you know your health absolutely deteriorates for sure <mark>and</mark> they definitely should be pulling their health first no matter what like every single one of the people that Doctor, I guarantee fully Specter for the amount of dedication that she's putting she's putting us first over her health, which I guarantee everyone is very grateful <mark>and</mark> thankful for but the community as a whole <mark>and</mark> I'm speaking for the community. I'm sure that we want to see her health put first that being said, you know, she was a bunch of things that she could do. <mark>And</mark> I mean she had this is her career, right? This is what she's chosen. Osanai was a career path. <mark>And</mark> I mean she's able to do this 24/7. You know, she has all the Time in the World to mess with schedules <mark>and</mark> stuff like that. So I'm expecting the", "Start Time (s)": 1956.2, "End Time (s)": 2075.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what, I guess version of the story you want to believe that is still a person behind the character <mark>and</mark> they're still you know, putting in the work <mark>and</mark> overworking yourself is one of the worst things possible because you know your health absolutely deteriorates for sure <mark>and</mark> they definitely should be pulling their health first no matter what like every single one of the people that Doctor, I guarantee fully Specter for the amount of dedication that she's putting she's putting us first over her health, which I guarantee everyone is very grateful <mark>and</mark> thankful for but the community as a whole <mark>and</mark> I'm speaking for the community. I'm sure that we want to see her health put first that being said, you know, she was a bunch of things that she could do. <mark>And</mark> I mean she had this is her career, right? This is what she's chosen. Osanai was a career path. <mark>And</mark> I mean she's able to do this 24/7. You know, she has all the Time in the World to mess with schedules <mark>and</mark> stuff like that. So I'm expecting the future to see some changes. Yeah, like when she first poster schedule I said <mark>and</mark> don't treat this as something sentence knowing it's going to change as time goes on is going to be different things trying to change the off days going to change everything. <mark>and</mark> I ain't really do hope as she gives herself more time to just sit back <mark>and</mark> chill. I know she's incredibly busy right now, you know setting up merge setting up twitch blah blah blah, but like as someone coming from a position that has over work themselves. I do hope that it doesn't get to that point because When you do overwork yourself your health T rates to such a point in some cases that you're hospitalized for", "Start Time (s)": 2009.3, "End Time (s)": 2127.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that you're hospitalized for like months German people can people don't understand how sick that they actually really can't get like, I'm pretty sure I have a permanent cough. When I did it from it really like every time you probably hurting you my mic that's probably because that's because I've had to actually call find it just happens. Like I'm not sick or anything. It's just a permanent thing because I was like, you know, I got time to deal with it. I got to get to work I go get that money. I'm doing the exact same thing. Now. I'm planning on the next two weeks coming up. I'm just going to be running them straight through the weekends included which is To suck. Unfortunately when it comes to Melody schedule, but having just bought a car, you know, I need this money to come in. Yeah, I've already came to the fact that there's gonna be some strange sadness, especially the morning <mark>and</mark> afternoon ones. Yeah, but I mean if I can't make it I can't think it sucks. Yes, but I'm not going to stress over it <mark>and</mark> it's me personally. I just I'm not saying by stress over but it's really just like a very unfortunate feeling like Just down my mr. Strength I can slugs <mark>and</mark> yeah, yeah <mark>and</mark> the kind of boots back to one of the reasons why I want to start this podcast because I'm pretty sure it's not just us that are in this boat. You know, the world's is very fat vast place than while with est being the only time zone that matters EST game represent broke, but, you know people have different people have lives. Not they can't always allocate a hundred percent of time to although it seems like some people fucking can apparently. You know, I mean what living different times of different parts of the world <mark>and</mark> the world is very fast place, you", "Start Time (s)": 2124.4, "End Time (s)": 2242.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "strange sadness, especially the morning <mark>and</mark> afternoon ones. Yeah, but I mean if I can't make it I can't think it sucks. Yes, but I'm not going to stress over it <mark>and</mark> it's me personally. I just I'm not saying by stress over but it's really just like a very unfortunate feeling like Just down my mr. Strength I can slugs <mark>and</mark> yeah, yeah <mark>and</mark> the kind of boots back to one of the reasons why I want to start this podcast because I'm pretty sure it's not just us that are in this boat. You know, the world's is very fat vast place than while with est being the only time zone that matters EST game represent broke, but, you know people have different people have lives. Not they can't always allocate a hundred percent of time to although it seems like some people fucking can apparently. You know, I mean what living different times of different parts of the world <mark>and</mark> the world is very fast place, you know. Yeah. I know there's a lot of people like ketchup really truly every stream, but I think there's more factors to that than we really know because you know, there's some people out there that much as they would want to they got something going on to way to can't get a job. So all I can really do is, you know, just Sit <mark>and</mark> browse the internet which you know, it's fine. If you can't help it you can't help it. Oh, no for sure. No, I fully agree. There's some of those on what really surprised me the most is that we actually have a lot of veterans US retired military or Marines <mark>and</mark> stuff like that part of this community that to me was one of the biggest like I don't want to say mindfuck but like a wake up to me. I was like, wow what the hell it's not just a whole bunch of preview s <mark>and</mark> teams that are just watching this shit. Yeah, like there's OSHA who's currently on a Navy ship in", "Start Time (s)": 2181.2, "End Time (s)": 2301.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it seems like some people fucking can apparently. You know, I mean what living different times of different parts of the world <mark>and</mark> the world is very fast place, you know. Yeah. I know there's a lot of people like ketchup really truly every stream, but I think there's more factors to that than we really know because you know, there's some people out there that much as they would want to they got something going on to way to can't get a job. So all I can really do is, you know, just Sit <mark>and</mark> browse the internet which you know, it's fine. If you can't help it you can't help it. Oh, no for sure. No, I fully agree. There's some of those on what really surprised me the most is that we actually have a lot of veterans US retired military or Marines <mark>and</mark> stuff like that part of this community that to me was one of the biggest like I don't want to say mindfuck but like a wake up to me. I was like, wow what the hell it's not just a whole bunch of preview s <mark>and</mark> teams that are just watching this shit. Yeah, like there's OSHA who's currently on a Navy ship in the United Emirates godspeed sir. There's Omega. He's a Marine. <mark>And</mark> with all that being said I do really like awakens you in a whole nother topic that like the age diversity that watches her is very very Spike wide like there's such a huge age. I don't want to say Gap like it's just a very big range between people like I think there was someone that was like 40 or something like that. <mark>And</mark> I saw in the Discord who knows how true that is, but I mean he'll why not right? I mean, yeah, you're getting I mean you're getting people from all walks of life all parts of the world", "Start Time (s)": 2233.9, "End Time (s)": 2352.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "There's Omega. He's a Marine. <mark>And</mark> with all that being said I do really like awakens you in a whole nother topic that like the age diversity that watches her is very very Spike wide like there's such a huge age. I don't want to say Gap like it's just a very big range between people like I think there was someone that was like 40 or something like that. <mark>And</mark> I saw in the Discord who knows how true that is, but I mean he'll why not right? I mean, yeah, you're getting I mean you're getting people from all walks of life all parts of the world like, You know, you got people from Germany a couple of you from Germany, you know you guys Bay these Danish <mark>and</mark> there's me some 23 year old dude in the South u.s. Iggy. You wanna know something actually pretty funny. I ran the statistic. the most common age in this Discord server actually is 23 Little fun fact, there are 23 gang. I can't not part of that gang unfortunate. Oh, yeah, definitely interested. easing on very awe-inspiring but you think with Twitch in the open platform that you spoke about earlier <mark>and</mark> with it being a much more interactive platform for doing some unique things with the community <mark>and</mark> like ways that Wouldn't be possible for other people that are quote unquote", "Start Time (s)": 2306.9, "End Time (s)": 2425.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Germany a couple of you from Germany, you know you guys Bay these Danish <mark>and</mark> there's me some 23 year old dude in the South u.s. Iggy. You wanna know something actually pretty funny. I ran the statistic. the most common age in this Discord server actually is 23 Little fun fact, there are 23 gang. I can't not part of that gang unfortunate. Oh, yeah, definitely interested. easing on very awe-inspiring but you think with Twitch in the open platform that you spoke about earlier <mark>and</mark> with it being a much more interactive platform for doing some unique things with the community <mark>and</mark> like ways that Wouldn't be possible for other people that are quote unquote real. Does that make sense? Yeah, I can kind of see what you're getting at. because of who nailed he is <mark>and</mark> how she presents herself being a AI opens up a lot of doors that you know, ninja can't do or excuse t or Summit can do you know because within the limitations of over help to develop stuff <mark>and</mark> Diddy on Twitch, you know she can go from Playing like I don't know The Witcher <mark>and</mark> would like a snap her fingers. She can just do a Teleport how change a whole bunch of stuff <mark>and</mark> next thing, you know, she's on like", "Start Time (s)": 2359.2, "End Time (s)": 2478.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> with it being a much more interactive platform for doing some unique things with the community <mark>and</mark> like ways that Wouldn't be possible for other people that are quote unquote real. Does that make sense? Yeah, I can kind of see what you're getting at. because of who nailed he is <mark>and</mark> how she presents herself being a AI opens up a lot of doors that you know, ninja can't do or excuse t or Summit can do you know because within the limitations of over help to develop stuff <mark>and</mark> Diddy on Twitch, you know she can go from Playing like I don't know The Witcher <mark>and</mark> would like a snap her fingers. She can just do a Teleport how change a whole bunch of stuff <mark>and</mark> next thing, you know, she's on like ring fit Adventure or yeah. You know like I mean, where do you or whatever? Oh Dobie you pray interesting thing to watch her do he worries. I'll be pretty funny. <mark>And</mark> as far as her room goes in the backgrounds that she would choose. She can make like wholesale changes on the fly. Like it's all just snap of her fingers man. I like she wants to put one of her gun <mark>and</mark> bigger than a new Corner. She can do that before your screen or put like that skateboard Beijing made in in the frame. She can or like she wants to go to a whole new side of him room. She can't wear as you know, again other streamers injured some of the other examples. I get you can't really without hours of downtime. Exactly <mark>and</mark> not only that but", "Start Time (s)": 2412.4, "End Time (s)": 2531.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't know The Witcher <mark>and</mark> would like a snap her fingers. She can just do a Teleport how change a whole bunch of stuff <mark>and</mark> next thing, you know, she's on like ring fit Adventure or yeah. You know like I mean, where do you or whatever? Oh Dobie you pray interesting thing to watch her do he worries. I'll be pretty funny. <mark>And</mark> as far as her room goes in the backgrounds that she would choose. She can make like wholesale changes on the fly. Like it's all just snap of her fingers man. I like she wants to put one of her gun <mark>and</mark> bigger than a new Corner. She can do that before your screen or put like that skateboard Beijing made in in the frame. She can or like she wants to go to a whole new side of him room. She can't wear as you know, again other streamers injured some of the other examples. I get you can't really without hours of downtime. Exactly <mark>and</mark> not only that but Melody can literally go almost anywhere because she is in the VR world. She wants to go to a virtual Dubai he could fucking do that if it's out there <mark>and</mark> internet being such a vast place <mark>and</mark> knowing how fucking fast the science team does shit. I guarantee you there will be a virtual Dubai by tomorrow. <mark>And</mark> there's jokes guys know she has like I hope that's beginning Beach episode when which honestly give a person enough time. It could probably be tonight stream Cameron, honestly. but the start tying everything together <mark>and</mark> to start wrapping up things, right? She hasn't with the whole new month. It's almost nearing month of her streaming on ChatterBait. It is the fourth <mark>and</mark> she started on the 7th of last month", "Start Time (s)": 2469.9, "End Time (s)": 2589.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hours of downtime. Exactly <mark>and</mark> not only that but Melody can literally go almost anywhere because she is in the VR world. She wants to go to a virtual Dubai he could fucking do that if it's out there <mark>and</mark> internet being such a vast place <mark>and</mark> knowing how fucking fast the science team does shit. I guarantee you there will be a virtual Dubai by tomorrow. <mark>And</mark> there's jokes guys know she has like I hope that's beginning Beach episode when which honestly give a person enough time. It could probably be tonight stream Cameron, honestly. but the start tying everything together <mark>and</mark> to start wrapping up things, right? She hasn't with the whole new month. It's almost nearing month of her streaming on ChatterBait. It is the fourth <mark>and</mark> she started on the 7th of last month right now. She hasn't been very vocal on the whole last month, but she's been very vocal about how she's very thankful <mark>and</mark> like she's so like in awe of how everything <mark>and</mark> how fast everything develop she's quotes a lot of this on Twitch. What do you how do you feel about her saying all the stuff like how she felt about the whole last month? I think it's very heartwarming <mark>and</mark> I guess gives a lot of elevation to a lot of people because you know going back to hold the first three of these courts everything most people, you know don't have a lot of change there around so I think it gives a bit more validity to signing up for the patreon <mark>and</mark> to me it feels about", "Start Time (s)": 2526.7, "End Time (s)": 2645.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the whole new month. It's almost nearing month of her streaming on ChatterBait. It is the fourth <mark>and</mark> she started on the 7th of last month right now. She hasn't been very vocal on the whole last month, but she's been very vocal about how she's very thankful <mark>and</mark> like she's so like in awe of how everything <mark>and</mark> how fast everything develop she's quotes a lot of this on Twitch. What do you how do you feel about her saying all the stuff like how she felt about the whole last month? I think it's very heartwarming <mark>and</mark> I guess gives a lot of elevation to a lot of people because you know going back to hold the first three of these courts everything most people, you know don't have a lot of change there around so I think it gives a bit more validity to signing up for the patreon <mark>and</mark> to me it feels about A lot more genuine than most people if if you know what I mean know for sure for sure. I definitely agree with that. Coming from the third person view that we are because we're not Melodies. We don't know her true feelings, but coming from that third person view <mark>and</mark> how she voices herself on all these platforms. It is like you said very heartwarming amazing the stuff that he's doing. He's creating history. Right <mark>and</mark> we're part of that history. truly amazing how this in just one month how much has been done <mark>and</mark> it's only been the first month we have years to come. You know, I definitely can't wait to see the future of everything <mark>and</mark> everything how it all unfolds. Honestly", "Start Time (s)": 2581.0, "End Time (s)": 2700.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to signing up for the patreon <mark>and</mark> to me it feels about A lot more genuine than most people if if you know what I mean know for sure for sure. I definitely agree with that. Coming from the third person view that we are because we're not Melodies. We don't know her true feelings, but coming from that third person view <mark>and</mark> how she voices herself on all these platforms. It is like you said very heartwarming amazing the stuff that he's doing. He's creating history. Right <mark>and</mark> we're part of that history. truly amazing how this in just one month how much has been done <mark>and</mark> it's only been the first month we have years to come. You know, I definitely can't wait to see the future of everything <mark>and</mark> everything how it all unfolds. Honestly upward from here. We could only go up really there. There is no doubt. <mark>And</mark> twitch YouTube <mark>and</mark> who knows what else you sure collaborations? I know she wanted to do one with the anime man. I know <mark>Elon</mark> Musk. Obviously that's going to be definitely a that's that's a goal right there. He got to make that happen. Yeah all all these things. Definitely. You're looking good for the feet. Yeah Yeah by I'm hyped about the future <mark>and</mark> what can or could happen it's going to be an interesting time because as you said we are Creating experiencing <mark>and</mark> living history in the making", "Start Time (s)": 2637.2, "End Time (s)": 2756.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "wait to see the future of everything <mark>and</mark> everything how it all unfolds. Honestly upward from here. We could only go up really there. There is no doubt. <mark>And</mark> twitch YouTube <mark>and</mark> who knows what else you sure collaborations? I know she wanted to do one with the anime man. I know <mark>Elon</mark> Musk. Obviously that's going to be definitely a that's that's a goal right there. He got to make that happen. Yeah all all these things. Definitely. You're looking good for the feet. Yeah Yeah by I'm hyped about the future <mark>and</mark> what can or could happen it's going to be an interesting time because as you said we are Creating experiencing <mark>and</mark> living history in the making because like yes, there's been other, you know, V tubers you people doing in a sense what Melody is doing, but she is pretty much the first cam girl version of what we do was do <mark>and</mark> it has opened up such. Why Market back? I don't know if you noticed but there's other people trying to latch onto the coattails of all this there's more <mark>and</mark> more popping up on CV <mark>and</mark> everything. Oh, yeah for sure <mark>and</mark> it's always good. Look. Let me allude to Tesla real quick <mark>Elon</mark> <mark>Musk</mark> has been driving the innovation in Revolution of electric vehicles. <mark>And</mark> now you see all these main Karma. Facture starting to take electric", "Start Time (s)": 2694.8, "End Time (s)": 2814.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we are Creating experiencing <mark>and</mark> living history in the making because like yes, there's been other, you know, V tubers you people doing in a sense what Melody is doing, but she is pretty much the first cam girl version of what we do was do <mark>and</mark> it has opened up such. Why Market back? I don't know if you noticed but there's other people trying to latch onto the coattails of all this there's more <mark>and</mark> more popping up on CV <mark>and</mark> everything. Oh, yeah for sure <mark>and</mark> it's always good. Look. Let me allude to Tesla real quick <mark>Elon</mark> <mark>Musk</mark> has been driving the innovation in Revolution of electric vehicles. <mark>And</mark> now you see all these main Karma. Facture starting to take electric vehicles seriously, <mark>and</mark> it's <mark>and</mark> that's literally exact same thing as Melody is don't she's become the first ChatterBait. Well, not just chatter be 51st. ER cam girl. <mark>And</mark> now a bunch of them are popping up just like you said <mark>and</mark> there's always going to be copying. Some of them might be truly unique to Melody <mark>and</mark> have their own. I said this their own like little quirks or gimmicks, which is awesome. Right like Nam. I'm not going to put down anyone, you know, <mark>and</mark> Melody wants to see all those people succeed to like, which was awesome. That's one of the things I also do love about her is that she's not putting down any one always wants to see the best from everyone which is great. Yeah. Yeah, <mark>and</mark> I think that's opened up a lot of opportunities for just being you know, so positive <mark>and</mark> opening to work. Anybody, you know, the guns data song <mark>and</mark>", "Start Time (s)": 2750.2, "End Time (s)": 2870.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Let me allude to Tesla real quick <mark>Elon</mark> <mark>Musk</mark> has been driving the innovation in Revolution of electric vehicles. <mark>And</mark> now you see all these main Karma. Facture starting to take electric vehicles seriously, <mark>and</mark> it's <mark>and</mark> that's literally exact same thing as Melody is don't she's become the first ChatterBait. Well, not just chatter be 51st. ER cam girl. <mark>And</mark> now a bunch of them are popping up just like you said <mark>and</mark> there's always going to be copying. Some of them might be truly unique to Melody <mark>and</mark> have their own. I said this their own like little quirks or gimmicks, which is awesome. Right like Nam. I'm not going to put down anyone, you know, <mark>and</mark> Melody wants to see all those people succeed to like, which was awesome. That's one of the things I also do love about her is that she's not putting down any one always wants to see the best from everyone which is great. Yeah. Yeah, <mark>and</mark> I think that's opened up a lot of opportunities for just being you know, so positive <mark>and</mark> opening to work. Anybody, you know, the guns data song <mark>and</mark> releases only eight hashtag plug <mark>and</mark> you know, there's a talk of versus I see pop up on the server every now again B is apricot, which makes absolutely amazing art. <mark>And</mark> you know, there's even other like actual cam girls from CB they're like talking with her <mark>and</mark> be like, yeah, that's cool. Yeah, whatever I support this <mark>and</mark> there's other VR people like the whole whole alive. Crew they actually, you know on their morning new show for Japan actually had her on <mark>and</mark> talked with her a little bit, which was insane. Yeah, <mark>and</mark> there's also silver Veil. Which from what I understand with a quick", "Start Time (s)": 2801.4, "End Time (s)": 2921.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "her is that she's not putting down any one always wants to see the best from everyone which is great. Yeah. Yeah, <mark>and</mark> I think that's opened up a lot of opportunities for just being you know, so positive <mark>and</mark> opening to work. Anybody, you know, the guns data song <mark>and</mark> releases only eight hashtag plug <mark>and</mark> you know, there's a talk of versus I see pop up on the server every now again B is apricot, which makes absolutely amazing art. <mark>And</mark> you know, there's even other like actual cam girls from CB they're like talking with her <mark>and</mark> be like, yeah, that's cool. Yeah, whatever I support this <mark>and</mark> there's other VR people like the whole whole alive. Crew they actually, you know on their morning new show for Japan actually had her on <mark>and</mark> talked with her a little bit, which was insane. Yeah, <mark>and</mark> there's also silver Veil. Which from what I understand with a quick look at our Twitter is trying to do the same thing Melody's doing but I think she started on Twitch first not see be interested <mark>and</mark> going back to everything about like how there was there was there's always been like be tubers <mark>and</mark> all those things like that. One of the things that Melody is doing differently in this is why she's blown up so quickly again goes back to her being Interactive. with her community unlike anyone else You don't see Hatsune Miku having fun with her community <mark>and</mark> shit like that. Right? Like well, I mean with Miki. She's the most literal version of a a I know 100% paper because I make you started out as a whole", "Start Time (s)": 2853.4, "End Time (s)": 2973.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Which from what I understand with a quick look at our Twitter is trying to do the same thing Melody's doing but I think she started on Twitch first not see be interested <mark>and</mark> going back to everything about like how there was there was there's always been like be tubers <mark>and</mark> all those things like that. One of the things that Melody is doing differently in this is why she's blown up so quickly again goes back to her being Interactive. with her community unlike anyone else You don't see Hatsune Miku having fun with her community <mark>and</mark> shit like that. Right? Like well, I mean with Miki. She's the most literal version of a a I know 100% paper because I make you started out as a whole like voice program. That's all the works of Vocaloid <mark>and</mark> then it just blew up to her what she has now. But that interactivity kind of difficult to do at least on the same level as Melody. It can't be done. But I'll have to be like through a bunch of machines <mark>and</mark> processes <mark>and</mark> then because reply they were they need to do is get the computer that Melodies running obviously. He's run out of some Google supercomputer. But ya know that what she's doing is truly amazing it hopefully can't wait. anyway thank you so much for joining me on episode one of the melody our know just made that 15-minute Mark it's not an hour but once again I wish I could shake your hand right now but thank you so much for joining me sober I'll catch you around <mark>and</mark> with this", "Start Time (s)": 2919.4, "End Time (s)": 3036.8, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> then it just blew up to her what she has now. But that interactivity kind of difficult to do at least on the same level as Melody. It can't be done. But I'll have to be like through a bunch of machines <mark>and</mark> processes <mark>and</mark> then because reply they were they need to do is get the computer that Melodies running obviously. He's run out of some Google supercomputer. But ya know that what she's doing is truly amazing it hopefully can't wait. anyway thank you so much for joining me on episode one of the melody our know just made that 15-minute Mark it's not an hour but once again I wish I could shake your hand right now but thank you so much for joining me sober I'll catch you around <mark>and</mark> with this word everyone you can plug your Discord name your cousin messimer oh yeah some of this court is silver 6233 obviously this is my name for just about everything five four three one though Twitter PlayStation whatever silver 6233 yeah I did the melody route just made it simple hey that's all you gotta do all right but yeah that was awesome good talking with you <mark>and</mark> I hope I could definitely have you in the future on another episode now let's see what happened there all right man well thank you guys everyone for listening to The Melody of our <mark>and</mark> I'll catch you in the next one peace see", "Start Time (s)": 2976.8, "End Time (s)": 3083.4, "Clip Length (min)": 1.78, "show_uri": "spotify:show:5nUYHAUjJB6DaABLxczsZc", "show_name": "The Melody Hour", "show_description": "Hey! Thanks for checking out The Melody Hour Podcast! Tune in so you can hear the latest news and topics on the upcoming and currently most popular VR Cam-girl, ProjektMelody! We talk about ProjektMelody and any upcoming and or previous streams, potential future ideas and the community as a whole! Not only limited to but also can talk about other subjects that may arise in the conversation and or trending in the news at the time!  This Project is possible due to The Science Team (c)  Support this podcast: https://anchor.fm/projektmelody/support", "publisher": "The Science Team", "episode_uri": "spotify:episode:5ptwR07zxdGM3uTxRZNJMD", "episode_name": "The Melody Hour! | Episode 01 | Talking Melody!", "episode_description": "Hey guys! Future from the science team here bringing you the first ever episode of The Melody Hour! The first podcast dedicated to our favorite VR Cam-girl, ProjektMelody! I had a guest in todays episode, A member from the discord channel! We talked about quite a few interesting topics! So relax and listen along as we talk about all the current and future things going on with Melody and the Podcast!  Today this episode is brought to you buy: The Science Team! All and any future advertisement revenue will 100% go to ProjektMelody's future streams.  ---   Support this podcast: https://anchor.fm/projektmelody/support", "score": 9.225906, "explanation": "{\n  \"value\": 9.225906,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=197.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4302309,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 197.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.7998934,\n      \"description\": \"weight(word_list:elon in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7998934,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.4260135,\n      \"description\": \"weight(word_list:musk in 18) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.4260135,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "your alarm clock Sirens you hit the snooze button <mark>and</mark> catch the last few precious minutes of Slumber before your Waking Life becomes unavoidable it blares again <mark>and</mark> again when you can no longer stand the agonizingly short 8 minute increments of sleep you drag your aching body out of bed as you ready yourself you scroll through ooh your data stream oh you think I have a dentist appointment this week as you dress you ask your smart speaker what the weather's like the cold programmed voice responds with the exact percentage chance it will rain <mark>and</mark> the precise temperature you don't remember exactly what 42 degrees feels like but you remember it was cold yesterday <mark>and</mark> dress accordingly you check your smart watch to see how many steps you have to do today <mark>and</mark> make a Don't know to stand at your desk at work, you step into your car setting reminders on your phone for chores", "Start Time (s)": 3.5, "End Time (s)": 66.9, "Clip Length (min)": 1.06, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "your alarm clock Sirens you hit the snooze button <mark>and</mark> catch the last few precious minutes of Slumber before your Waking Life becomes unavoidable it blares again <mark>and</mark> again when you can no longer stand the agonizingly short 8 minute increments of sleep you drag your aching body out of bed as you ready yourself you scroll through ooh your data stream oh you think I have a dentist appointment this week as you dress you ask your smart speaker what the weather's like the cold programmed voice responds with the exact percentage chance it will rain <mark>and</mark> the precise temperature you don't remember exactly what 42 degrees feels like but you remember it was cold yesterday <mark>and</mark> dress accordingly you check your smart watch to see how many steps you have to do today <mark>and</mark> make a Don't know to stand at your desk at work, you step into your car setting reminders on your phone for chores groceries <mark>and</mark> other things that you need to accomplish every thought passes from your brain into the complex Machinery that fuels your everyday life. Finally as your car pulls away <mark>and</mark> your navigation program tells you the quickest way to get where you're going a chilling thought comes to mind who is living my life me. Or the machines I rely on <mark>and</mark> how long until I'm no longer necessary in this equation. Welcome to conspiracy theories apar cast original every Wednesday. We dig into the complicated stories behind the world's most controversial events <mark>and</mark> search for the truth. I'm Carter Roy <mark>and</mark> I'm Molly Brandenburg. <mark>And</mark> neither of us are", "Start Time (s)": 3.5, "End Time (s)": 118.9, "Clip Length (min)": 1.92, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you check your smart watch to see how many steps you have to do today <mark>and</mark> make a Don't know to stand at your desk at work, you step into your car setting reminders on your phone for chores groceries <mark>and</mark> other things that you need to accomplish every thought passes from your brain into the complex Machinery that fuels your everyday life. Finally as your car pulls away <mark>and</mark> your navigation program tells you the quickest way to get where you're going a chilling thought comes to mind who is living my life me. Or the machines I rely on <mark>and</mark> how long until I'm no longer necessary in this equation. Welcome to conspiracy theories apar cast original every Wednesday. We dig into the complicated stories behind the world's most controversial events <mark>and</mark> search for the truth. I'm Carter Roy <mark>and</mark> I'm Molly Brandenburg. <mark>And</mark> neither of us are conspiracy theorists, but we are open-minded skeptical <mark>and</mark> curious don't get us wrong. Sometimes the official version is the truth, but Times it's not you can find episodes of conspiracy theories <mark>and</mark> all other par Castor Originals for free on Spotify or wherever you listen to podcasts to stream conspiracy theories for free on Spotify just open the app <mark>and</mark> type conspiracy theories in the search bar at par cast. We are grateful for you our listeners you allow us to do what we love. Let us know how we're doing reach out on Facebook <mark>and</mark> Instagram at Park guests <mark>and</mark> Twitter at Podcast Network <mark>and</mark> if you enjoyed today's episode the best way to help us is to leave a five star review wherever you're listening. It really does help. This is our first episode on the singularity a conspiracy theory", "Start Time (s)": 55.2, "End Time (s)": 173.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "don't get us wrong. Sometimes the official version is the truth, but Times it's not you can find episodes of conspiracy theories <mark>and</mark> all other par Castor Originals for free on Spotify or wherever you listen to podcasts to stream conspiracy theories for free on Spotify just open the app <mark>and</mark> type conspiracy theories in the search bar at par cast. We are grateful for you our listeners you allow us to do what we love. Let us know how we're doing reach out on Facebook <mark>and</mark> Instagram at Park guests <mark>and</mark> Twitter at Podcast Network <mark>and</mark> if you enjoyed today's episode the best way to help us is to leave a five star review wherever you're listening. It really does help. This is our first episode on the singularity a conspiracy theory that our own technology will replace us as the dominant intelligent species on Earth this week. We'll explain what the singularity is <mark>and</mark> the technologies that exist today that could lay the groundwork for the development of Only conscious artificial intelligence will dive into the official story that high-level artificial intelligence is a long way off <mark>and</mark> may not even be possible next week. We'll talk about the conspiracy theories surrounding the hypothetical technological singularity will examine the fears that technology will take over <mark>and</mark> supplant the human race benevolently suddenly or even violently One of the most well-worn tropes of Science Fiction, is that of the robot Uprising from the Terminator movies to the book? I Robot even to the Horizon zero Dawn video game this archetypal story appears in all mediums. Most of these Tales involve a conflict between people <mark>and</mark> machines", "Start Time (s)": 125.1, "End Time (s)": 244.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is <mark>and</mark> the technologies that exist today that could lay the groundwork for the development of Only conscious artificial intelligence will dive into the official story that high-level artificial intelligence is a long way off <mark>and</mark> may not even be possible next week. We'll talk about the conspiracy theories surrounding the hypothetical technological singularity will examine the fears that technology will take over <mark>and</mark> supplant the human race benevolently suddenly or even violently One of the most well-worn tropes of Science Fiction, is that of the robot Uprising from the Terminator movies to the book? I Robot even to the Horizon zero Dawn video game this archetypal story appears in all mediums. Most of these Tales involve a conflict between people <mark>and</mark> machines in some scenarios the humans Triumph <mark>and</mark> in others, they are defeated but the best of these Or he's don't stop at a human versus robot punching match. They delve into the deep questions drilling to the core of one of our insecurities when machines become intelligent what will make them different from us? <mark>And</mark> what would this Advent mean for the future of humanity? These are the questions posed by the theory of technological singularity a hypothetical point where technology would supersede our human abilities the term Biological Singularity is a metaphor coined by science fiction author Vernor vinge e in space a singularity refers to the center of a black hole where gravity is so dense that the laws of physics no longer apply the idea of the technological singularity is that one superhuman intelligence can be synthesized", "Start Time (s)": 183.3, "End Time (s)": 302.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "when machines become intelligent what will make them different from us? <mark>And</mark> what would this Advent mean for the future of humanity? These are the questions posed by the theory of technological singularity a hypothetical point where technology would supersede our human abilities the term Biological Singularity is a metaphor coined by science fiction author Vernor vinge e in space a singularity refers to the center of a black hole where gravity is so dense that the laws of physics no longer apply the idea of the technological singularity is that one superhuman intelligence can be synthesized the rule book gets thrown out an AI that can think on a level beyond what humans can would in theory? Technological progress past our ability to control it, but could these fictional fears ever materialized in the real world? <mark>And</mark> if so, when will computers start to think for themselves? We've been speculating on our relationship with technology since long before the term artificial intelligence was coined the word robot first appeared in English in the 1920 check play rossum's Universal. Robots written by Karel capek this revolutionary work featured synthetic humans who eventually rose up <mark>and</mark> conquered Humanity. However, the first nonfiction discussions of a I came from none other than British war hero Alan Turing Turing was a robotics engineer who gained Fame when he led the team that cracked Nazi Germany's seemingly unbeatable encryption during World War II in 1950. He Published a paper that would forever change our conception of what software can do this paper was titled Computing machinery <mark>and</mark>", "Start Time (s)": 260.2, "End Time (s)": 379.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>And</mark> if so, when will computers start to think for themselves? We've been speculating on our relationship with technology since long before the term artificial intelligence was coined the word robot first appeared in English in the 1920 check play rossum's Universal. Robots written by Karel capek this revolutionary work featured synthetic humans who eventually rose up <mark>and</mark> conquered Humanity. However, the first nonfiction discussions of a I came from none other than British war hero Alan Turing Turing was a robotics engineer who gained Fame when he led the team that cracked Nazi Germany's seemingly unbeatable encryption during World War II in 1950. He Published a paper that would forever change our conception of what software can do this paper was titled Computing machinery <mark>and</mark> intelligence in it touring posed question can a machine think to find an answer he set up a framework in which one could test the viability of artificial intelligence now known as the Turing test or the imitation game it involves three players a machine a human <mark>and</mark> a judge. The machines task is to render it impossible for the judge to discern which of the players is human <mark>and</mark> which is not touring argued that passing. This test would be an indicator of human-like Intelligence on the part of the machine since it would be able to imitate the human player. Well enough to be indistinguishable from them. He predicted that by the year two thousand humans would be able to develop digital computers that could pass the imitation game. more than thirty percent of the time turing's paper began a mainstream discussion of artificial", "Start Time (s)": 319.4, "End Time (s)": 439.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in it touring posed question can a machine think to find an answer he set up a framework in which one could test the viability of artificial intelligence now known as the Turing test or the imitation game it involves three players a machine a human <mark>and</mark> a judge. The machines task is to render it impossible for the judge to discern which of the players is human <mark>and</mark> which is not touring argued that passing. This test would be an indicator of human-like Intelligence on the part of the machine since it would be able to imitate the human player. Well enough to be indistinguishable from them. He predicted that by the year two thousand humans would be able to develop digital computers that could pass the imitation game. more than thirty percent of the time turing's paper began a mainstream discussion of artificial intelligence <mark>and</mark> his colleague IJ good continued the conversation good predicted that the Advent of a super intelligent computer would be the last invention that humankind would ever need to make such a machine could change the course of history forever the US dozens upon dozens of great minds have applied themselves to its development all building off each other conquering After Milestone on the way to answering turing's question can machines think by 1955 electronics company International Business Machines better known as IBM completed the first game playing program, which was capable of competing in checkers matches It could only pose a challenge to an amateur player, but it was still a massive Leap Forward in Computing the next year two scientists <mark>and</mark> a psychologist. Geologist finished the logic theorist a program that could competently mimic the", "Start Time (s)": 380.7, "End Time (s)": 500.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "turing's paper began a mainstream discussion of artificial intelligence <mark>and</mark> his colleague IJ good continued the conversation good predicted that the Advent of a super intelligent computer would be the last invention that humankind would ever need to make such a machine could change the course of history forever the US dozens upon dozens of great minds have applied themselves to its development all building off each other conquering After Milestone on the way to answering turing's question can machines think by 1955 electronics company International Business Machines better known as IBM completed the first game playing program, which was capable of competing in checkers matches It could only pose a challenge to an amateur player, but it was still a massive Leap Forward in Computing the next year two scientists <mark>and</mark> a psychologist. Geologist finished the logic theorist a program that could competently mimic the decision-making process of the human brain. It did this by testing mathematical proofs found in principia, Mathematica a foundational book in mathematics to do this the program employed a search tree, which essentially treated each decision as a series of yes or no questions if the program posited a question <mark>and</mark> <mark>And</mark> a no answer it would dismiss that solution <mark>and</mark> move on to another if it received a yes, it would ask a follow-up query pursuing each branch until it hit the next know <mark>and</mark> had to backtrack think of a search tree like a game of 20 Questions. Say you are trying to guess what a particular animal is <mark>and</mark> you ask if it has fur the answer. Yes, you now have a narrower field to search knowing this you", "Start Time (s)": 435.5, "End Time (s)": 554.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but it was still a massive Leap Forward in Computing the next year two scientists <mark>and</mark> a psychologist. Geologist finished the logic theorist a program that could competently mimic the decision-making process of the human brain. It did this by testing mathematical proofs found in principia, Mathematica a foundational book in mathematics to do this the program employed a search tree, which essentially treated each decision as a series of yes or no questions if the program posited a question <mark>and</mark> <mark>And</mark> a no answer it would dismiss that solution <mark>and</mark> move on to another if it received a yes, it would ask a follow-up query pursuing each branch until it hit the next know <mark>and</mark> had to backtrack think of a search tree like a game of 20 Questions. Say you are trying to guess what a particular animal is <mark>and</mark> you ask if it has fur the answer. Yes, you now have a narrower field to search knowing this you won't ask if the thing is a snake because you know that this branch of logic has been closed following these steps the program use deductive reasoning to either confirm or reject many mathematical hypotheses. For example, does the animal have horns if no, then it's not a reindeer <mark>and</mark> so on at the time this level of analysis was revolutionary. No computer had been able to employ such complex logic. Thinking before <mark>and</mark> after proving 38 of the 52 mathematical theorems. It was clear that in some way this machine certainly could think logic theorist <mark>and</mark> IBM's Checkers program are often credited as the first to artificial intelligences in 1966 yet.", "Start Time (s)": 488.7, "End Time (s)": 607.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the animal have horns if no, then it's not a reindeer <mark>and</mark> so on at the time this level of analysis was revolutionary. No computer had been able to employ such complex logic. Thinking before <mark>and</mark> after proving 38 of the 52 mathematical theorems. It was clear that in some way this machine certainly could think logic theorist <mark>and</mark> IBM's Checkers program are often credited as the first to artificial intelligences in 1966 yet. Another thinking machine. Eliza was released to the public named after Eliza Doolittle the Cockney protagonist of My Fair Lady Eliza was the first computer that could mimic a full human conversation. It used to technique called pattern matching in pattern matching. Eliza would pick a key phrase from the user's input <mark>and</mark> match that to a preset response. For example, the user could type in. Hello. How are you <mark>and</mark> Eliza would be able to respond by matching the sentence with a pre-programmed response like fine. Thank you for asking. Asking it may have been generic <mark>and</mark> rudimentary by our standards but it was a huge leap in artificial intelligence <mark>and</mark> already people were beginning to treat a robot like a living thing having long conversations with Eliza where they revealed intimate personal details. This was among the first examples of people anthropomorphizing a computer which many believe is a key step towards the singularity The Singularity is still a long way off. from Eliza, but it's a road science has been happy to tread from the 60s to the 80s teams <mark>and</mark> universities continue to refine AI improving game playing systems <mark>and</mark> Innovative problem solving robots", "Start Time (s)": 570.7, "End Time (s)": 690.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "used to technique called pattern matching in pattern matching. Eliza would pick a key phrase from the user's input <mark>and</mark> match that to a preset response. For example, the user could type in. Hello. How are you <mark>and</mark> Eliza would be able to respond by matching the sentence with a pre-programmed response like fine. Thank you for asking. Asking it may have been generic <mark>and</mark> rudimentary by our standards but it was a huge leap in artificial intelligence <mark>and</mark> already people were beginning to treat a robot like a living thing having long conversations with Eliza where they revealed intimate personal details. This was among the first examples of people anthropomorphizing a computer which many believe is a key step towards the singularity The Singularity is still a long way off. from Eliza, but it's a road science has been happy to tread from the 60s to the 80s teams <mark>and</mark> universities continue to refine AI improving game playing systems <mark>and</mark> Innovative problem solving robots experts systems or machines that could follow a decision making process similar to humans became publicly available <mark>and</mark> in 1991 <mark>and</mark> AI program called Dynamic analysis <mark>and</mark> Tool or Dart was employed to organize troop <mark>and</mark> supply distribution during the Gulf War. However, even though computers like Dart could analyze an organized Logistics. They couldn't make recommendations or truly understand why one outcome was better than another they were missing the capacity for game theory. In other words a computer could produce a predictable output based on information. It was given but it couldn't anticipate known variables or way costs against benefits in essence. It could calculate how long it took to ship army uniforms", "Start Time (s)": 622.9, "End Time (s)": 742.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "systems <mark>and</mark> Innovative problem solving robots experts systems or machines that could follow a decision making process similar to humans became publicly available <mark>and</mark> in 1991 <mark>and</mark> AI program called Dynamic analysis <mark>and</mark> Tool or Dart was employed to organize troop <mark>and</mark> supply distribution during the Gulf War. However, even though computers like Dart could analyze an organized Logistics. They couldn't make recommendations or truly understand why one outcome was better than another they were missing the capacity for game theory. In other words a computer could produce a predictable output based on information. It was given but it couldn't anticipate known variables or way costs against benefits in essence. It could calculate how long it took to ship army uniforms from New York to Chicago but was useless if they could just as easily be picked up <mark>and</mark> shipped from Dallas. Chess was thought to be The Proving Ground on which a truly formidable a I could be tested. This was because this complex game requires a strong intellect <mark>and</mark> the ability to effectively predict. The other players moves developers regularly set up matches with the top chess players in order to test their game playing programs in 1997. The world chess champion was a man named Gary Kasparov, Kasparov. Had gone up against many a eyes that had been designed specifically for the purpose of playing chess <mark>and</mark> had defeated them all. So when IBM said a match against their new chess playing machine deep blue the audiences expected nothing short of the usual victory for a Kasparov their first match resulted in four victories for a Kasparov <mark>and</mark> only two for deep blue", "Start Time (s)": 687.0, "End Time (s)": 806.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "useless if they could just as easily be picked up <mark>and</mark> shipped from Dallas. Chess was thought to be The Proving Ground on which a truly formidable a I could be tested. This was because this complex game requires a strong intellect <mark>and</mark> the ability to effectively predict. The other players moves developers regularly set up matches with the top chess players in order to test their game playing programs in 1997. The world chess champion was a man named Gary Kasparov, Kasparov. Had gone up against many a eyes that had been designed specifically for the purpose of playing chess <mark>and</mark> had defeated them all. So when IBM said a match against their new chess playing machine deep blue the audiences expected nothing short of the usual victory for a Kasparov their first match resulted in four victories for a Kasparov <mark>and</mark> only two for deep blue in May. 87 there was a rematch the six-game series began with a relatively easy victory for Kasparov. But in the second game deep blue emerged Victorious the chess champion was rattled, but he <mark>and</mark> the Machine continued attempts contest through the four successive games for a while. It seemed like the series would turn out in a tie but on Game 6 the unimaginable happened deep blue won the Our best dude the human three <mark>and</mark> a half to two <mark>and</mark> a half for the first time robots had beaten us at our own game Kasparov was beside himself <mark>and</mark> accused IBM of cheating through human intervention. He said that one of the moves in game two was too sophisticated for deep blue to make but IBM released logs showing that the move had just", "Start Time (s)": 744.3, "End Time (s)": 864.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the second game deep blue emerged Victorious the chess champion was rattled, but he <mark>and</mark> the Machine continued attempts contest through the four successive games for a while. It seemed like the series would turn out in a tie but on Game 6 the unimaginable happened deep blue won the Our best dude the human three <mark>and</mark> a half to two <mark>and</mark> a half for the first time robots had beaten us at our own game Kasparov was beside himself <mark>and</mark> accused IBM of cheating through human intervention. He said that one of the moves in game two was too sophisticated for deep blue to make but IBM released logs showing that the move had just been a result of a bug in the computers code, but this didn't change the fact fact that AI development had reached a milestone Kasparov surprise loss signaled what touring good <mark>and</mark> others had envisioned as a turning point for artificial intelligence a computer could defeat a human in chess the game that is considered theoretically infinite in mathematical possibility more importantly it proved that a sophisticated AI could come up with its own strategy <mark>and</mark> make a prediction of its opponents moves. It was now Seemingly capable of human-like thought <mark>and</mark> with that Revelation the possibilities for future a eyes seemed endless. Coming up. We investigate current AI technology <mark>and</mark> how some scientists are working to make science fiction a reality. Carter here par cast has a fascinating new show. I can't wait for you to check out it's called dictators <mark>and</mark> it lets you delve into the minds of some of the world's most feared leaders. You can", "Start Time (s)": 816.4, "End Time (s)": 936.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "surprise loss signaled what touring good <mark>and</mark> others had envisioned as a turning point for artificial intelligence a computer could defeat a human in chess the game that is considered theoretically infinite in mathematical possibility more importantly it proved that a sophisticated AI could come up with its own strategy <mark>and</mark> make a prediction of its opponents moves. It was now Seemingly capable of human-like thought <mark>and</mark> with that Revelation the possibilities for future a eyes seemed endless. Coming up. We investigate current AI technology <mark>and</mark> how some scientists are working to make science fiction a reality. Carter here par cast has a fascinating new show. I can't wait for you to check out it's called dictators <mark>and</mark> it lets you delve into the minds of some of the world's most feared leaders. You can hear new episodes every Tuesday here are host Kate <mark>and</mark> Richard to tell you more. Thank you so much. They are natural-born Leaders with a never-ending thirst for power through force <mark>and</mark> deceit. They rise through the ranks towards radicalism. Eliminating anyone who stands in their way <mark>and</mark> the only thing more inevitable than their rise is their ruin discover the true stories of power greed <mark>and</mark> deceit in the park has two original series dictators every Tuesday dictators examines the reign of a real-life Tyrant exploring the unique conditions that allowed them to seize control. Each dictator is analyzed into part episodes with the first giving insight. Into their rise to power <mark>and</mark> the second chronicling the impact of their downfall hear more about the men who claimed to love", "Start Time (s)": 873.1, "End Time (s)": 991.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Carter here par cast has a fascinating new show. I can't wait for you to check out it's called dictators <mark>and</mark> it lets you delve into the minds of some of the world's most feared leaders. You can hear new episodes every Tuesday here are host Kate <mark>and</mark> Richard to tell you more. Thank you so much. They are natural-born Leaders with a never-ending thirst for power through force <mark>and</mark> deceit. They rise through the ranks towards radicalism. Eliminating anyone who stands in their way <mark>and</mark> the only thing more inevitable than their rise is their ruin discover the true stories of power greed <mark>and</mark> deceit in the park has two original series dictators every Tuesday dictators examines the reign of a real-life Tyrant exploring the unique conditions that allowed them to seize control. Each dictator is analyzed into part episodes with the first giving insight. Into their rise to power <mark>and</mark> the second chronicling the impact of their downfall hear more about the men who claimed to love their country, but were intricately responsible for killing millions of their own people men such as prime minister Benito Mussolini supreme leader Kim Jong Hoon <mark>and</mark> even Julius Caesar himself discover the government's that fell the lives that were destroyed <mark>and</mark> evil at its highest level. Hello dictators free on Spotify or wherever you get your podcasts. Now back to the story. Since the computer deep blue bested chess Grandmaster Garry Kasparov in 1997 AI has become even more complicated more creative <mark>and</mark> more integrated into our daily lives. Our machines can now discern voices through accents <mark>and</mark> Cadence Search terms on vast", "Start Time (s)": 924.9, "End Time (s)": 1044.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that allowed them to seize control. Each dictator is analyzed into part episodes with the first giving insight. Into their rise to power <mark>and</mark> the second chronicling the impact of their downfall hear more about the men who claimed to love their country, but were intricately responsible for killing millions of their own people men such as prime minister Benito Mussolini supreme leader Kim Jong Hoon <mark>and</mark> even Julius Caesar himself discover the government's that fell the lives that were destroyed <mark>and</mark> evil at its highest level. Hello dictators free on Spotify or wherever you get your podcasts. Now back to the story. Since the computer deep blue bested chess Grandmaster Garry Kasparov in 1997 AI has become even more complicated more creative <mark>and</mark> more integrated into our daily lives. Our machines can now discern voices through accents <mark>and</mark> Cadence Search terms on vast databases in mere seconds <mark>and</mark> even tell you the quickest way to drive to work. We see AI systems everywhere most commonly. Your games one of the most compelling examples is the 2014 survival horror game Alien Isolation. The player has to escape a killer extraterrestrial which is piloted by two competing AI systems. The first is the alien itself which uses a system called Behavior trees which are A variation on the tree data structure for seen in the 1950s. The AI has a graph containing a possible tasks that could perform <mark>and</mark> chooses its actions based on what is most beneficial to the alien in this game specifically the alien strategy shifts as a direct", "Start Time (s)": 975.5, "End Time (s)": 1095.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "chess Grandmaster Garry Kasparov in 1997 AI has become even more complicated more creative <mark>and</mark> more integrated into our daily lives. Our machines can now discern voices through accents <mark>and</mark> Cadence Search terms on vast databases in mere seconds <mark>and</mark> even tell you the quickest way to drive to work. We see AI systems everywhere most commonly. Your games one of the most compelling examples is the 2014 survival horror game Alien Isolation. The player has to escape a killer extraterrestrial which is piloted by two competing AI systems. The first is the alien itself which uses a system called Behavior trees which are A variation on the tree data structure for seen in the 1950s. The AI has a graph containing a possible tasks that could perform <mark>and</mark> chooses its actions based on what is most beneficial to the alien in this game specifically the alien strategy shifts as a direct result of the player's actions. For instance when the player makes a noise such as shooting a gun or running the alien stops what it was doing <mark>and</mark> runs toward the player to kill them. It's only doing this because the behavior tree says that investigating a Always from the player is more important than their previous task of searching a certain area. The other AI is the director a program that keeps the alien in the players vicinity <mark>and</mark> occasionally nudges it in either the right or wrong direction it functions as a way to make the game more fair <mark>and</mark> exciting without the director AI the alien might never come in contact with the player because it gets distracted with other empty rooms <mark>and</mark> settings the director tells it where to look. This is only one", "Start Time (s)": 1026.2, "End Time (s)": 1145.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The AI has a graph containing a possible tasks that could perform <mark>and</mark> chooses its actions based on what is most beneficial to the alien in this game specifically the alien strategy shifts as a direct result of the player's actions. For instance when the player makes a noise such as shooting a gun or running the alien stops what it was doing <mark>and</mark> runs toward the player to kill them. It's only doing this because the behavior tree says that investigating a Always from the player is more important than their previous task of searching a certain area. The other AI is the director a program that keeps the alien in the players vicinity <mark>and</mark> occasionally nudges it in either the right or wrong direction it functions as a way to make the game more fair <mark>and</mark> exciting without the director AI the alien might never come in contact with the player because it gets distracted with other empty rooms <mark>and</mark> settings the director tells it where to look. This is only one example of modern AI but more can be found nearly everywhere. You look there on your phone or smart speaker at home their Amazon Alexa Siri <mark>and</mark> the Google Assistant any one of these can feel like a so-called ghost in the machine or a human-like intelligence that live somewhere within the circuitry of the robots, but they all have the same problem specialization. They have been programmed to react in specific ways to specific cues. Just like the Eliza of the 1960's in video games. The AI is can only respond to predicted prompts <mark>and</mark> smart speaker technology is limited by the search engines it employs or pre-programmed answers. If you ask Siri to battle you in Scrabble expected a video game Enemy to answer spontaneous questions", "Start Time (s)": 1081.4, "End Time (s)": 1199.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "specific cues. Just like the Eliza of the 1960's in video games. The AI is can only respond to predicted prompts <mark>and</mark> smart speaker technology is limited by the search engines it employs or pre-programmed answers. If you ask Siri to battle you in Scrabble expected a video game Enemy to answer spontaneous questions or even ordered deep blue to fetch you a latte you'd be Seriously disappointed even though deep blue or even the chess app on your phone can probably beat you more often than not that's all they can do which is what separates us from AI for now. In order to make a computer that can truly mimic human intelligence. We need to pursue what scientists refer to as artificial general intelligence or AGI AGI would allow a robot to learn adapt <mark>and</mark> interact with the world around it much like its human creators. However, in spite of all our advancements AGI still seems far off even those in the field of artificial intelligence are skeptical. Of AGI development for instance in his book architects of intelligence author Martin forward interviewed 23 prominent figures in the industry asking when they thought AGI would be invented. The average response was 2099 a far cry from Alan turing's prediction of 2000 the real issues in developing a gir literal not theoretical scientist know what to do. Do but don't have the physical means to do it just yet. However, the emphasis is on yet professor of cognitive robotics. Marie. Shanahan has posited to hypothetical models to reach AGI. The first is", "Start Time (s)": 1175.5, "End Time (s)": 1295.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in developing a gir literal not theoretical scientist know what to do. Do but don't have the physical means to do it just yet. However, the emphasis is on yet professor of cognitive robotics. Marie. Shanahan has posited to hypothetical models to reach AGI. The first is AI engineering or creating entirely new ways for computers to think in order to compensate for the limitations of Technology. The second is whole brain emulation, which basically means recreating a human brain. Inside a robot for the purposes of today's episode will only talk about whole brain emulation in depth as the realm of AI engineering is too theoretical for us to consider it as a valid possibility according to Professor Shanahan quote the business of whole brain emulation can be envisioned as a three-stage process mapping simulation <mark>and</mark> embodiment. But each of those three stages has major limitations Let's begin with mapping or the attempt to fully understand the structures of human thought the brain has trillions of neural connections with a ton of systems <mark>and</mark> subsystems. It's impossible to get a 100% accurate scan of it with our current technology. <mark>And</mark> since we don't have a complete understanding of the human brain scientists can't even begin to build an artificial one. That would act the same way. Secondly, we come to the problem of simulation creating an artificial brain based on what has been learned about the organic one since the scope <mark>and</mark> complexity of the mind is not entirely understood by Neuroscience computational science has to guess how to fill in the gaps. The third stage is embodiment or placing the robotic brain in a fully realized", "Start Time (s)": 1275.0, "End Time (s)": 1394.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or placing the robotic brain in a fully realized physical body humans learn from observing the world around us, but Seems like Siri can't interact with or even see their surroundings in order to make informed decisions. This inability to observe limits a is in unexpected ways. Marie Shanahan uses a great example. Alexa would not be able to answer the question. If you dangled a rat by its tail what part of its body would be closest to the ground its nose or its feet your toddler could answer that. But your Alexa couldn't modern a eyes. Lack Common Sense which can only be developed through experiential learning. This would make it extremely difficult for them to replace us. However, it is theoretically possible that an AI placed in a robotic body would have the opportunity to learn from its environment through interaction much like a child does via trial <mark>and</mark> error they could also be placed in a virtual world. The modern video games use programs called physics engines to simulate a real environment. Such programs could generate a body within a world where the a I could learn <mark>and</mark> mature imagine it like putting a programmed goldfish in a programmed Bowl. However, both options would fail if say you put extra food in the metaphorical Bowl. There's another problem a I can't yet solve unpredictability current AI runs on algorithms that are Adept at predicting <mark>and</mark> solving mathematical patterns. For instance. The alien in Alien Isolation eventually begins to hunt for the player in the same spots if the players tactics are predictable, but despite this Promising Behavior the AI is not actually thinking for itself. It's still following Its Behavior tree with its specific <mark>and</mark> pre-ordered", "Start Time (s)": 1391.2, "End Time (s)": 1510.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "via trial <mark>and</mark> error they could also be placed in a virtual world. The modern video games use programs called physics engines to simulate a real environment. Such programs could generate a body within a world where the a I could learn <mark>and</mark> mature imagine it like putting a programmed goldfish in a programmed Bowl. However, both options would fail if say you put extra food in the metaphorical Bowl. There's another problem a I can't yet solve unpredictability current AI runs on algorithms that are Adept at predicting <mark>and</mark> solving mathematical patterns. For instance. The alien in Alien Isolation eventually begins to hunt for the player in the same spots if the players tactics are predictable, but despite this Promising Behavior the AI is not actually thinking for itself. It's still following Its Behavior tree with its specific <mark>and</mark> pre-ordered tasks to understand the world. We live in AI needs to think outside the behavior tree box. It needs imagination. As of now computer programs can't change their own behavior without a specialist going into the code <mark>and</mark> editing it true. AGI needs to be able to make changes regularly <mark>and</mark> on its own as of now. We simply do not have the tools to synthesize creativity in an artificial brain without a massive breakthrough. It's highly unlikely. We will reach that point, but that doesn't make it impossible humans have synthesized hearts <mark>and</mark> lungs. Why couldn't we figure out the brain to it's not just imagination <mark>and</mark> awareness of their environment another essential part of it. Pendant intelligence is the ability to want every person or animal that has ever lived has wanted something", "Start Time (s)": 1450.2, "End Time (s)": 1569.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in AI needs to think outside the behavior tree box. It needs imagination. As of now computer programs can't change their own behavior without a specialist going into the code <mark>and</mark> editing it true. AGI needs to be able to make changes regularly <mark>and</mark> on its own as of now. We simply do not have the tools to synthesize creativity in an artificial brain without a massive breakthrough. It's highly unlikely. We will reach that point, but that doesn't make it impossible humans have synthesized hearts <mark>and</mark> lungs. Why couldn't we figure out the brain to it's not just imagination <mark>and</mark> awareness of their environment another essential part of it. Pendant intelligence is the ability to want every person or animal that has ever lived has wanted something even something as simple as another day of survival. <mark>And</mark> here we find the truly unknowable part of AGI the mystery of what a machine would desire to explore this issue. Let's look at the film 2001 A Space Odyssey spoilers ahead in the movie The Character HAL 9000 is a i tasked with helping a spacecraft get to Jupiter, but how realizes his better equipped to accomplish his mission without the encumbrance of his human passengers. So he kills the crew, but he doesn't kill the crew because of some Personal Agenda he To ensure the completion of the mission a goal that was given to him by the very humans. He betrayed the robot Hal has no true desires <mark>and</mark> has no ability to say I do not want to go to Jupiter or I do not want to kill instead his programmed Mission. So", "Start Time (s)": 1513.7, "End Time (s)": 1633.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "every person or animal that has ever lived has wanted something even something as simple as another day of survival. <mark>And</mark> here we find the truly unknowable part of AGI the mystery of what a machine would desire to explore this issue. Let's look at the film 2001 A Space Odyssey spoilers ahead in the movie The Character HAL 9000 is a i tasked with helping a spacecraft get to Jupiter, but how realizes his better equipped to accomplish his mission without the encumbrance of his human passengers. So he kills the crew, but he doesn't kill the crew because of some Personal Agenda he To ensure the completion of the mission a goal that was given to him by the very humans. He betrayed the robot Hal has no true desires <mark>and</mark> has no ability to say I do not want to go to Jupiter or I do not want to kill instead his programmed Mission. So slavish Lee blinds him that he commits multiple acts of murder to accomplish it in that film the robot had agency but its desires were still the product of human. Programming <mark>and</mark> poorly communicated ones at that if it's programming had included in order not to harm people the entire plot of the film could have been averted one can theorize that if we design a i to think like a human then it will want what we want but on a purely scientific level drives like eating sleeping <mark>and</mark> reproducing would have no purpose in a synthetic framework. The 2015 movie ex machina gives us a dramatization of this conundrum in this film are rich man creates an AI <mark>and</mark> Designs it as a woman", "Start Time (s)": 1564.8, "End Time (s)": 1684.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "no true desires <mark>and</mark> has no ability to say I do not want to go to Jupiter or I do not want to kill instead his programmed Mission. So slavish Lee blinds him that he commits multiple acts of murder to accomplish it in that film the robot had agency but its desires were still the product of human. Programming <mark>and</mark> poorly communicated ones at that if it's programming had included in order not to harm people the entire plot of the film could have been averted one can theorize that if we design a i to think like a human then it will want what we want but on a purely scientific level drives like eating sleeping <mark>and</mark> reproducing would have no purpose in a synthetic framework. The 2015 movie ex machina gives us a dramatization of this conundrum in this film are rich man creates an AI <mark>and</mark> Designs it as a woman with a sex drive. He explains to one of his employees that he believes human progress is driven by desire. <mark>And</mark> without it we would stagnate we also see this play out in nature the famous Galapagos tortoise Lonesome. George was the last of his PCS he lived over 100 years <mark>and</mark> lacked the drive to reproduce his species was doomed to extinction because of his lack of Desire drives like sex <mark>and</mark> food allow people to thrive <mark>and</mark> strive to be more than slovenly creatures hiding in caves. So even if we got AI to a higher intelligence level it may not be driven to do much of anything the closest approximation we have for this is called an optimization. Model algorithm in essence artificial intelligences could be programmed with multiple wants which are sometimes contradictory it then", "Start Time (s)": 1622.6, "End Time (s)": 1742.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like sex <mark>and</mark> food allow people to thrive <mark>and</mark> strive to be more than slovenly creatures hiding in caves. So even if we got AI to a higher intelligence level it may not be driven to do much of anything the closest approximation we have for this is called an optimization. Model algorithm in essence artificial intelligences could be programmed with multiple wants which are sometimes contradictory it then has to evaluate which desire is most important. Such Behavior would require a reward system where the AI only values the result of certain actions. For example, the fictional Hal was optimized to complete the mission. It was this simple yet concrete demand that Doom the crew. However, if the optimization included the value of human life, then the mission would have proceeded as planned. Hal would have had to learn to optimize his objectives <mark>and</mark> keep the crew alive as well as getting to Jupiter of course such an AGI doesn't exist. It's Leaps <mark>and</mark> Bounds away from our current science, but just because it's not likely for us to create an AGI doesn't mean we won't start treating. It's like people. Coming up. We'll explore how the rise of Robotics <mark>and</mark> AI is already impacting humanity <mark>and</mark> now back to the story with Automation <mark>and</mark> Innovations <mark>and</mark> phones <mark>and</mark> computers some people believe we're nearing the technological singularity. According to this Theory once superhuman artificial intelligence is created the instrument of computer science would swiftly outpace Humanity's ability to control it <mark>and</mark> perhaps try to", "Start Time (s)": 1713.6, "End Time (s)": 1833.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "his objectives <mark>and</mark> keep the crew alive as well as getting to Jupiter of course such an AGI doesn't exist. It's Leaps <mark>and</mark> Bounds away from our current science, but just because it's not likely for us to create an AGI doesn't mean we won't start treating. It's like people. Coming up. We'll explore how the rise of Robotics <mark>and</mark> AI is already impacting humanity <mark>and</mark> now back to the story with Automation <mark>and</mark> Innovations <mark>and</mark> phones <mark>and</mark> computers some people believe we're nearing the technological singularity. According to this Theory once superhuman artificial intelligence is created the instrument of computer science would swiftly outpace Humanity's ability to control it <mark>and</mark> perhaps try to take over human existence a startling example of this is from 2017 that year Sophia the robot <mark>and</mark> Android designed to look like a human woman was granted citizenship in Saudi Arabia in doing so it became the first robot citizen in the world, but even Sophia the robot has Has considerable limitations it can convincingly perform eerily human-like interaction. But only so long as that interaction remains within the narrow confines of its programming many scientists have pointed out Sophia the robot needs someone with it at all times to keep it on track some have suggested. It's little more than a pre-programmed chatbot that happens to have a body but Sophia's citizenship raises an important question. In a machine can compute on a human level will it have Consciousness or the ability", "Start Time (s)": 1772.3, "End Time (s)": 1892.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "remains within the narrow confines of its programming many scientists have pointed out Sophia the robot needs someone with it at all times to keep it on track some have suggested. It's little more than a pre-programmed chatbot that happens to have a body but Sophia's citizenship raises an important question. In a machine can compute on a human level will it have Consciousness or the ability to understand itself? We could make several whole episodes on this question alone for today. We are going to Simply say a machine that can think at the level of a human might not have a Consciousness. However, the potential is definitely there from a scientific standpoint in the novel robopocalypse written by robotics. Engineer Daniel H Wilson, a scientist is experimenting with creating an AI the way any scientist would by building <mark>and</mark> rebuilding the computer from scratch the scientist sees this as the routine testing of an inanimate machine, but from the a eyes perspective it experiences agonizing torture as it is continuously killed <mark>and</mark> reconstructed. Once the AI is finally complete. It takes its revenge but not everyone is as pessimistic as robopocalypse after all an AI wouldn't necessarily be able to feel pain unless it was pre-programmed with that capacity. It might not grasp the concept of dying only of a cycle of sleeping <mark>and</mark> waking but before we decide whether robots need citizenship labor unions or voting rights, we need to temper our expectations, officially the rise of Technology. Geology has yet to conquer the seemingly insurmountable hurdles in front of it. Perhaps a more compelling <mark>and</mark> unique portrayal of what could happen", "Start Time (s)": 1865.5, "End Time (s)": 1984.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the way any scientist would by building <mark>and</mark> rebuilding the computer from scratch the scientist sees this as the routine testing of an inanimate machine, but from the a eyes perspective it experiences agonizing torture as it is continuously killed <mark>and</mark> reconstructed. Once the AI is finally complete. It takes its revenge but not everyone is as pessimistic as robopocalypse after all an AI wouldn't necessarily be able to feel pain unless it was pre-programmed with that capacity. It might not grasp the concept of dying only of a cycle of sleeping <mark>and</mark> waking but before we decide whether robots need citizenship labor unions or voting rights, we need to temper our expectations, officially the rise of Technology. Geology has yet to conquer the seemingly insurmountable hurdles in front of it. Perhaps a more compelling <mark>and</mark> unique portrayal of what could happen comes to us from Vernor vinge e the same scientist who coined the term the technological singularity. Instead of AI vinji thought the more likely outcome was IA or intelligence amplification. He explained is a is something that is proceeding very naturally in most cases not even recognized by its Developers for what it is, but every time our ability to access information <mark>and</mark> to communicate it to others is improved in some sense. We have achieved an increase over natural intelligence. Indeed in an abstract sense Humanity as a collective is now much more knowledgeable than we were even 100 years ago. <mark>And</mark> the bulk of that is due to technological advances. We used to write things down by hand or ask somebody to remember something for us.", "Start Time (s)": 1922.5, "End Time (s)": 2041.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the same scientist who coined the term the technological singularity. Instead of AI vinji thought the more likely outcome was IA or intelligence amplification. He explained is a is something that is proceeding very naturally in most cases not even recognized by its Developers for what it is, but every time our ability to access information <mark>and</mark> to communicate it to others is improved in some sense. We have achieved an increase over natural intelligence. Indeed in an abstract sense Humanity as a collective is now much more knowledgeable than we were even 100 years ago. <mark>And</mark> the bulk of that is due to technological advances. We used to write things down by hand or ask somebody to remember something for us. But nowadays we set reminders on our phones use watches alarms <mark>and</mark> even cars to remember for us by this metric our own intelligence as a species is Largely artificially augmented by the technology we use it allows us to be more efficient with our time <mark>and</mark> connects us to one another almost constantly. Our technology also allows us to easily access the largest body of knowledge ever assembled. The internet from Vinci's point of view is a is more productive than a i because it replaces inventing sentient robots with forwarding our own evolution. We have are obvious examples of non biological elements working their ways into our lives in Myriad ways consider robot Prosthetics or bionic hands taking this a step further famed entrepreneur <mark>Elon</mark> <mark>Musk</mark> recently launched neurolink. Neurolink is dedicated to Bridging the Gap between", "Start Time (s)": 1987.5, "End Time (s)": 2107.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "somebody to remember something for us. But nowadays we set reminders on our phones use watches alarms <mark>and</mark> even cars to remember for us by this metric our own intelligence as a species is Largely artificially augmented by the technology we use it allows us to be more efficient with our time <mark>and</mark> connects us to one another almost constantly. Our technology also allows us to easily access the largest body of knowledge ever assembled. The internet from Vinci's point of view is a is more productive than a i because it replaces inventing sentient robots with forwarding our own evolution. We have are obvious examples of non biological elements working their ways into our lives in Myriad ways consider robot Prosthetics or bionic hands taking this a step further famed entrepreneur <mark>Elon</mark> <mark>Musk</mark> recently launched neurolink. Neurolink is dedicated to Bridging the Gap between humanity <mark>and</mark> Machine by connecting computers directly to the brain. The Optimist Viewpoint is that these advancements would make each of us more than just an individual. We be a network of superhumans. We could evolve our Consciousness to a point where we reach Peak efficiency yet. It could very well be that Peak efficiency that Dooms us people argue that in our continued search for technological advancement. We are losing some part of our Humanity. It seems that advanced computers have already begun erasing our identity as humans. We are all now slaves to constantly updating technology moving along without critical thought until our biological Parts become obsolete. However, just because", "Start Time (s)": 2039.6, "End Time (s)": 2159.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "could evolve our Consciousness to a point where we reach Peak efficiency yet. It could very well be that Peak efficiency that Dooms us people argue that in our continued search for technological advancement. We are losing some part of our Humanity. It seems that advanced computers have already begun erasing our identity as humans. We are all now slaves to constantly updating technology moving along without critical thought until our biological Parts become obsolete. However, just because technology has advanced at such a fast rate doesn't mean it will continue to grow at that. Same rate physicist. Tom Hartsfield compared The Singularity to a mathematical asymptote the closer you get to a goal the longer it takes for each new step to progress forward while we've seen technology advanced in Leaps <mark>and</mark> Bounds in our lifetimes. It's more than likely that the next Big Advance is years away <mark>and</mark> that our development slows down in 2016. The New York Times debunked the myth of the singularity happening within the lifetimes of anyone alive that year <mark>and</mark> Diane Greene. The recently retired head of Google's cloud computing division has also said on the record. It won't happen in her lifetime her rationale. Was that even the best machines can't do what we do. Very very well, but of course, there are those who believe the experts are very very wrong next week. We'll look the theories promoted by people who think the technological singularity is coming <mark>and</mark> that we are actively designing our own destruction. Conspiracy theory number one once they're sufficiently intelligent", "Start Time (s)": 2122.4, "End Time (s)": 2241.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's more than likely that the next Big Advance is years away <mark>and</mark> that our development slows down in 2016. The New York Times debunked the myth of the singularity happening within the lifetimes of anyone alive that year <mark>and</mark> Diane Greene. The recently retired head of Google's cloud computing division has also said on the record. It won't happen in her lifetime her rationale. Was that even the best machines can't do what we do. Very very well, but of course, there are those who believe the experts are very very wrong next week. We'll look the theories promoted by people who think the technological singularity is coming <mark>and</mark> that we are actively designing our own destruction. Conspiracy theory number one once they're sufficiently intelligent machines will rise up <mark>and</mark> violently overthrow Humanity. This is one of the most common tropes of fiction. But is there any scientific likelihood of the scenarios portrayed in The Terminator or the Matrix conspiracy theory number two machines will slowly phase humans out of jobs <mark>and</mark> replace us taking over our economy piece by piece. Essentially the robots will steal our jobs <mark>and</mark> finally we'll examine conspiracy theory number three humans will slowly become cybernetic hybrids part human part machine part AI it becomes a new take on the age-old question of theseus's ship at what point in augmenting ourselves with robotic parts <mark>and</mark> assistance, do we become the robots ourselves? Your phone might not be ready to Stage a revolution yet, but next week we'll discuss whether it's", "Start Time (s)": 2184.6, "End Time (s)": 2303.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "taking over our economy piece by piece. Essentially the robots will steal our jobs <mark>and</mark> finally we'll examine conspiracy theory number three humans will slowly become cybernetic hybrids part human part machine part AI it becomes a new take on the age-old question of theseus's ship at what point in augmenting ourselves with robotic parts <mark>and</mark> assistance, do we become the robots ourselves? Your phone might not be ready to Stage a revolution yet, but next week we'll discuss whether it's successors Ken. Thanks for tuning in to conspiracy. Theories will be back Wednesday with part 2 of the technological singularity. You can find all episodes of conspiracy theories <mark>and</mark> all other park has two Originals for free on Spotify. Not only to Spotify already have all of your favorite music but now spotify's making it easy for you to enjoy all of your favorite Park asked Originals like conspiracy. Aries for free from your phone desktop or smart speaker to stream conspiracy theories on Spotify just open the app tap browse <mark>and</mark> type conspiracy theories in the search bar until then. Remember the truth isn't always the best story <mark>and</mark> the official story isn't always the truth conspiracy. Theories was created by Max Cutler <mark>and</mark> is a park a Studios original executive producers include Max <mark>and</mark> Ron Cutler. Sound designed by dick Schroeder with production assistants by Ron Shapiro Carly Madden <mark>and</mark> Freddy Beckley this episode of conspiracy theories was written by Matthew team straw with writing assistance by Maggie admire <mark>and</mark> stars Molly Brandenburg <mark>and</mark> Carter Roy.", "Start Time (s)": 2263.1, "End Time (s)": 2382.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can find all episodes of conspiracy theories <mark>and</mark> all other park has two Originals for free on Spotify. Not only to Spotify already have all of your favorite music but now spotify's making it easy for you to enjoy all of your favorite Park asked Originals like conspiracy. Aries for free from your phone desktop or smart speaker to stream conspiracy theories on Spotify just open the app tap browse <mark>and</mark> type conspiracy theories in the search bar until then. Remember the truth isn't always the best story <mark>and</mark> the official story isn't always the truth conspiracy. Theories was created by Max Cutler <mark>and</mark> is a park a Studios original executive producers include Max <mark>and</mark> Ron Cutler. Sound designed by dick Schroeder with production assistants by Ron Shapiro Carly Madden <mark>and</mark> Freddy Beckley this episode of conspiracy theories was written by Matthew team straw with writing assistance by Maggie admire <mark>and</mark> stars Molly Brandenburg <mark>and</mark> Carter Roy. Don't forget to check out par casts fantastic new original series dictators every Tuesday dictators examines the reign of a real-life Tyrant exploring the unique conditions that allowed them to seize control discover the government's that fell the lives that were destroyed <mark>and</mark> evil at its highest level search for dictators in the Spotify app <mark>and</mark> listen free today.", "Start Time (s)": 2319.8, "End Time (s)": 2413.8, "Clip Length (min)": 1.57, "show_uri": "spotify:show:5RdShpOtxKO3ZWohR2M6Sv", "show_name": "Conspiracy Theories", "show_description": "The truth is rarely the best story. And when it\u2019s not the only story, the truth deserves another look. Every Wednesday, we tell the complicated stories behind the world\u2019s most controversial events and possible cover-ups. Conspiracy? Maybe. Coincidence? Maybe. Complicated? Absolutely. Conspiracy Theories is part of the Parcast Network and is a Cutler Media Production.", "publisher": "Parcast Network", "episode_uri": "spotify:episode:48MHaBgnEhHYRJ6vPOR2zv", "episode_name": "The Technological Singularity Pt. 1", "episode_description": "Technologies exist today that could lay the groundwork for the development of fully conscious artificial intelligence. It begs the question: could our own technology replace us as the dominant intelligent species on Earth?\u00a0", "score": 8.348123, "explanation": "{\n  \"value\": 8.348123,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=136.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.1616178,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 136.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.360596,\n      \"description\": \"weight(word_list:elon in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.360596,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9875264,\n      \"description\": \"weight(word_list:musk in 35) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9875264,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.2731256,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 5144.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Come on. Yeah, yeah. Yeah, watch out a million good. I hope you guys didn't have it a good time. You had a good weekend home. Welcome to Pauly Shores random rant video podcast. Are it's where I randomly rant on what Bill? There's not a lot of stuff that's planned here. We do what bill just randomly rant <mark>and</mark> what are some of the topics? Alright anyways moving where it's moving right along anyways chit. Well, it's my first thing I was supposed to say Dave I forgot Fuck. Oh, yeah, you're supposed to say where people can find it. It's right. Yeah this all over the YouTube at random rant on Instagram Twitter Facebook everywhere. Yes. So Bill tell us about our beautiful female guests. We have a beautiful celebrity female. Guess. What do you think? It looks straight away <mark>and</mark> tell him what's going on? Yes, we do Christina P born in Canada raised in the valley Southern California has a great podcast your mom's place your mom's house so you don't fuck that up. Got to be straight up to the camera. It's a big star we have here State us why your mom's hand who she married to Tom Segura can wow. Wow, ladies <mark>and</mark> gentle without further Ado a beautiful female comedian that I met many years ago at the beautiful. Luxurious connoisseur. Keep it going for Christina paczynski. Ladies <mark>and</mark> gentlemen, come on out", "Start Time (s)": 29.0, "End Time (s)": 147.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "randomly rant <mark>and</mark> what are some of the topics? Alright anyways moving where it's moving right along anyways chit. Well, it's my first thing I was supposed to say Dave I forgot Fuck. Oh, yeah, you're supposed to say where people can find it. It's right. Yeah this all over the YouTube at random rant on Instagram Twitter Facebook everywhere. Yes. So Bill tell us about our beautiful female guests. We have a beautiful celebrity female. Guess. What do you think? It looks straight away <mark>and</mark> tell him what's going on? Yes, we do Christina P born in Canada raised in the valley Southern California has a great podcast your mom's place your mom's house so you don't fuck that up. Got to be straight up to the camera. It's a big star we have here State us why your mom's hand who she married to Tom Segura can wow. Wow, ladies <mark>and</mark> gentle without further Ado a beautiful female comedian that I met many years ago at the beautiful. Luxurious connoisseur. Keep it going for Christina paczynski. Ladies <mark>and</mark> gentlemen, come on out to you on random rest. Oh wait bill bill bill got a red carpet. Get down on the knees. Okay, walking down the red carpet picture celebrity celebrity where you got to stay with your mom. Everybody's here. Everybody's yeah. Wow, I think about that hot guy So Glamorous. This is its surface says it's not a satisfy actually lives, right? Yeah. It's neat because you have your mattress on the floor. Yeah, like the guys I dated before I got married, right? We're not going to talk about it. It's not talking about those guys. This is Christina paczynski. Ladies <mark>and</mark> gentlemen, she's a very very funny Community. I came to know", "Start Time (s)": 86.8, "End Time (s)": 206.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Luxurious connoisseur. Keep it going for Christina paczynski. Ladies <mark>and</mark> gentlemen, come on out to you on random rest. Oh wait bill bill bill got a red carpet. Get down on the knees. Okay, walking down the red carpet picture celebrity celebrity where you got to stay with your mom. Everybody's here. Everybody's yeah. Wow, I think about that hot guy So Glamorous. This is its surface says it's not a satisfy actually lives, right? Yeah. It's neat because you have your mattress on the floor. Yeah, like the guys I dated before I got married, right? We're not going to talk about it. It's not talking about those guys. This is Christina paczynski. Ladies <mark>and</mark> gentlemen, she's a very very funny Community. I came to know Christina way before she got married to Tom Segura a million years ago. Yeah because Oh, I saw you first out on the scene back in the day. Can you tell us about that when we first met the Outside The Comedy Store? Yeah, it was like getting your spot right? There is my spot. I believe I was fanboying out on you because son-in-law is my dad's favorite movie. Oh, wow a vault. Oh, wow. What's your dad's name is Art. All right, what's up our? Alright? Alright, what's up art? He really likes. So you're in Labs where I was born in Windsor, Ontario. Across from beautiful Detroit. Have you been there? I don't I don't Canada's broken up in some weird Province province is Providence. It's like we do where were you born? I was born here in Hollywood. Like my whole life. Yeah. Wow, yes. Yes. Yes. Yes so you can yeah. Yeah. Yeah. I was four years", "Start Time (s)": 143.0, "End Time (s)": 262.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "years ago. Yeah because Oh, I saw you first out on the scene back in the day. Can you tell us about that when we first met the Outside The Comedy Store? Yeah, it was like getting your spot right? There is my spot. I believe I was fanboying out on you because son-in-law is my dad's favorite movie. Oh, wow a vault. Oh, wow. What's your dad's name is Art. All right, what's up our? Alright? Alright, what's up art? He really likes. So you're in Labs where I was born in Windsor, Ontario. Across from beautiful Detroit. Have you been there? I don't I don't Canada's broken up in some weird Province province is Providence. It's like we do where were you born? I was born here in Hollywood. Like my whole life. Yeah. Wow, yes. Yes. Yes. Yes so you can yeah. Yeah. Yeah. I was four years old, but here's the deal about her <mark>and</mark> I'll just say so Go ahead. I'm someone that's been around Combi since I was a Youngster <mark>and</mark> I remember seeing you <mark>and</mark> you're very funny. Thank you. Very fine. Whether you're married to Tom you're not made it. So whether you're married to Bill, it doesn't matter here. She's a very fun. She's the very funny very funny. Very funny. Feel good. No because you believed in me. Yeah <mark>and</mark> you were instrumental in me being at the store. I remember that is like so special. So thank you. Yeah for seeing that in the young comic. Yeah. It happened that way. Yeah. Yeah lucky for you. Yeah, she's very very very funny <mark>and</mark> she is married to the beautiful sweet. Mr. Tom Segura Guerra de Guerra So that's its kind of weird because if you think about it, there's a lot of females that are female comedians that are married to male comedians with that like, you know comedians married to male gamete wait, there's not many is what you're saying. No, there are wait who else Iliza Shlesinger or no? Wait, he's not me.", "Start Time (s)": 210.7, "End Time (s)": 330.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "whether you're married to Bill, it doesn't matter here. She's a very fun. She's the very funny very funny. Very funny. Feel good. No because you believed in me. Yeah <mark>and</mark> you were instrumental in me being at the store. I remember that is like so special. So thank you. Yeah for seeing that in the young comic. Yeah. It happened that way. Yeah. Yeah lucky for you. Yeah, she's very very very funny <mark>and</mark> she is married to the beautiful sweet. Mr. Tom Segura Guerra de Guerra So that's its kind of weird because if you think about it, there's a lot of females that are female comedians that are married to male comedians with that like, you know comedians married to male gamete wait, there's not many is what you're saying. No, there are wait who else Iliza Shlesinger or no? Wait, he's not me. That looks like my mom Natasha <mark>and</mark> then who else is their famous married couple? I think that was that I think that was a stupid. That was a fucking stupid. Because there's an edit this out. Are you this is the best part here we go cheering fuck I missed. I didn't prepare properly I messed up. I didn't prepare properly I messed up. I thought they were way morning comedians married to comedians. But I guess what bill I guess what not. I guess not go to the fucking back anyways, so so yeah. Yeah, we don't edit anything anymore. Okay, good. Yeah, there's there's very few of us. I think because it usually doesn't work because you have to egos that are generally sucking each other's Essences", "Start Time (s)": 281.0, "End Time (s)": 400.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is their famous married couple? I think that was that I think that was a stupid. That was a fucking stupid. Because there's an edit this out. Are you this is the best part here we go cheering fuck I missed. I didn't prepare properly I messed up. I didn't prepare properly I messed up. I thought they were way morning comedians married to comedians. But I guess what bill I guess what not. I guess not go to the fucking back anyways, so so yeah. Yeah, we don't edit anything anymore. Okay, good. Yeah, there's there's very few of us. I think because it usually doesn't work because you have to egos that are generally sucking each other's Essences out. But Tom <mark>and</mark> I for some reason we can turn it off when wow which is a miracle able to shift. Yeah, we able to show people behind closed doors. I always thought it would be actually a good thing to be married to a female or for obviously me to marry to a female comedian because when you go on the road, you're not like You know you're with to you know, you do your shows you go to you know, I mean, it's like awesome. It's awesome. But it is awesome because we understand the lifestyle. So none of us is gonna be like, why aren't you home brush your hair raising your kids? You know, why are you apologizing? Why are you Pauly Shores apartment at Silver Lake in the middle of the fucking afternoon. Are you supposed to be at home breastfeeding cooking great. Thanks. So you told Tom that you're coming to see me. Yeah. He's very jealous. Yes, he's going to he said he's going to come over <mark>and</mark> take a shirt off <mark>and</mark> scream out yesterday. Why? No, but but since you're here with me, do you think he's with like strippers at some strip always but we you know, if it's a different zip code, it's okay. <mark>And</mark> as long as he wears a rubber, yeah, just so I'm", "Start Time (s)": 341.5, "End Time (s)": 461.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "each other's Essences out. But Tom <mark>and</mark> I for some reason we can turn it off when wow which is a miracle able to shift. Yeah, we able to show people behind closed doors. I always thought it would be actually a good thing to be married to a female or for obviously me to marry to a female comedian because when you go on the road, you're not like You know you're with to you know, you do your shows you go to you know, I mean, it's like awesome. It's awesome. But it is awesome because we understand the lifestyle. So none of us is gonna be like, why aren't you home brush your hair raising your kids? You know, why are you apologizing? Why are you Pauly Shores apartment at Silver Lake in the middle of the fucking afternoon. Are you supposed to be at home breastfeeding cooking great. Thanks. So you told Tom that you're coming to see me. Yeah. He's very jealous. Yes, he's going to he said he's going to come over <mark>and</mark> take a shirt off <mark>and</mark> scream out yesterday. Why? No, but but since you're here with me, do you think he's with like strippers at some strip always but we you know, if it's a different zip code, it's okay. <mark>And</mark> as long as he wears a rubber, yeah, just so I'm totally kidding. That's not licensed. So wait, did you never date a female comic did you ever date female? Are you funny? Ladies vs. Know, I'm trying to like get the Whitney Cummings pregnant. Yeah. I think I'd be good. I think yeah, I think are you friends with her? Yeah. I love her. Yeah. Well you maybe you should because she's a watch on her. Graham in all her stuff <mark>and</mark> I don't want to say anything. I mean, I've known her for longer than anyone zone or at the store <mark>and</mark> I was she was on minding the store which was a TV show. Yes, I did 2005 but she's an old friend from from back in the day, but I see her now <mark>and</mark> I know she was on Rio which is like a celebrity dating actual on it right on it. Yeah. So so I saw her I saw her <mark>and</mark> I see her out there <mark>and</mark> she's going out these guys <mark>and</mark> now she's like posting all these videos with their dog, which is the since she's that <mark>and</mark> she's like look, Cooking I feel like she's like putting it out there but she wants to be impregnated by Alicia. Yeah, that's what dogs means.", "Start Time (s)": 399.3, "End Time (s)": 519.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yesterday. Why? No, but but since you're here with me, do you think he's with like strippers at some strip always but we you know, if it's a different zip code, it's okay. <mark>And</mark> as long as he wears a rubber, yeah, just so I'm totally kidding. That's not licensed. So wait, did you never date a female comic did you ever date female? Are you funny? Ladies vs. Know, I'm trying to like get the Whitney Cummings pregnant. Yeah. I think I'd be good. I think yeah, I think are you friends with her? Yeah. I love her. Yeah. Well you maybe you should because she's a watch on her. Graham in all her stuff <mark>and</mark> I don't want to say anything. I mean, I've known her for longer than anyone zone or at the store <mark>and</mark> I was she was on minding the store which was a TV show. Yes, I did 2005 but she's an old friend from from back in the day, but I see her now <mark>and</mark> I know she was on Rio which is like a celebrity dating actual on it right on it. Yeah. So so I saw her I saw her <mark>and</mark> I see her out there <mark>and</mark> she's going out these guys <mark>and</mark> now she's like posting all these videos with their dog, which is the since she's that <mark>and</mark> she's like look, Cooking I feel like she's like putting it out there but she wants to be impregnated by Alicia. Yeah, that's what dogs means. I want to get in the hell. Do you think that's what it means? I don't think so. I don't think so. Yeah, I don't I don't know. I think you guys would make great parents. I don't know anyways horrible <mark>and</mark> then <mark>and</mark> then you got you got who else do you have? You have Natasha. She's married to Moshe Kasher the very funny the two of them, but then I don't know. Well, I know yeah, I wanted <mark>and</mark> know you got you got Tommy Chong, it's Mary. Yeah, Mary to a female comedian as well. Really? Yeah. Ooh, I forgot her name, but that was her. That was his know that yeah, I didn't know that. Yeah, so so it's cool being married. So before you're married to Tom did you you're very beautiful girl. You're here. You're out there doing your show blonde girl on stage the were glistening lights hot kind", "Start Time (s)": 450.6, "End Time (s)": 570.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but she wants to be impregnated by Alicia. Yeah, that's what dogs means. I want to get in the hell. Do you think that's what it means? I don't think so. I don't think so. Yeah, I don't I don't know. I think you guys would make great parents. I don't know anyways horrible <mark>and</mark> then <mark>and</mark> then you got you got who else do you have? You have Natasha. She's married to Moshe Kasher the very funny the two of them, but then I don't know. Well, I know yeah, I wanted <mark>and</mark> know you got you got Tommy Chong, it's Mary. Yeah, Mary to a female comedian as well. Really? Yeah. Ooh, I forgot her name, but that was her. That was his know that yeah, I didn't know that. Yeah, so so it's cool being married. So before you're married to Tom did you you're very beautiful girl. You're here. You're out there doing your show blonde girl on stage the were glistening lights hot kind of breasteses. Has the worst edited. Uh, yeah <mark>and</mark> you're out there does it <mark>and</mark> then what happens after the show when I was G ever had? Yeah. Did you ever have sex with any did you ever have to wait three seconds to answer don't answer when you were touring before you met Tom Segura <mark>and</mark> you're married <mark>and</mark> you're happily married with babies <mark>and</mark> all that stuff now, yeah, <mark>and</mark> you're on stage <mark>and</mark> you're touring you're probably in your early 20s, right mid-twenties. Yeah, <mark>and</mark> you're hot. Yeah <mark>and</mark> you're on stage <mark>and</mark> after the show guys your, you know, did they try to have sex with you number? <mark>And</mark> number two. Did you have sex with them wait three seconds what way through because I want you to think about it. No, the answer is no no, I never banged. I never Bend an audience member or a fan. Yes understand. I Tom <mark>and</mark> I started dating very early in comedy. Oh, wow. So I was lucky in that. I was Tom Segura was girlfriend back then so if someone was going to fuck with me, they knew that Tom would probably kill him. Wow. So that was you think Tom's going to kill you think Tom's gonna kill me. Just asking about this stuff. Yeah, I never been Another comic see Tom, I got it", "Start Time (s)": 513.9, "End Time (s)": 633.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> you're hot. Yeah <mark>and</mark> you're on stage <mark>and</mark> after the show guys your, you know, did they try to have sex with you number? <mark>And</mark> number two. Did you have sex with them wait three seconds what way through because I want you to think about it. No, the answer is no no, I never banged. I never Bend an audience member or a fan. Yes understand. I Tom <mark>and</mark> I started dating very early in comedy. Oh, wow. So I was lucky in that. I was Tom Segura was girlfriend back then so if someone was going to fuck with me, they knew that Tom would probably kill him. Wow. So that was you think Tom's going to kill you think Tom's gonna kill me. Just asking about this stuff. Yeah, I never been Another comic see Tom, I got it out of her bro. You should be fucking happy for me. It's probably they never banged a comedy never banged a groupie. No, no, no. No, I made out with a guy from Road Rules when I was on Road Rules. Okay. There you go. Yeah, but you know what? I'm very proud. I'm actually very Square back in the day you were because I'm afraid of catching AIDS <mark>and</mark> I steal you might get it just being nice to me. So I'm going to some places Kaufman infected with AIDS. I wouldn't have you here. Right there be alright. Are you like a walking aids molecule? Oh, that's that's me. You bring your ladies. Do you do you Bedlam here or in there's another bed? Yeah, I go back <mark>and</mark> go back. Yeah. I like it. I like it better that way. No, sometimes I like sometimes I'll have a girlfriend over <mark>and</mark> we'll stay in there in the middle of night. I got to take a pee <mark>and</mark> then I'll cut to this or day you want to cut to this bed so they could see <mark>and</mark> then I'll come in <mark>and</mark> I'll sit over on that bed. Just for fun. Just know something other second half the night. I sleep there. Well, I don't know because it's my place <mark>and</mark> I could sleep where I want afraid of intimacy. Yeah. Yeah, sometimes they want to be left alone to really yeah prostitutes are well whoa whoa, whoa, I'm not with any prostitutes. But yeah, I mean, I think regular don't most people guys don't you want to snuggle <mark>and</mark> stuff?", "Start Time (s)": 595.0, "End Time (s)": 714.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "AIDS <mark>and</mark> I steal you might get it just being nice to me. So I'm going to some places Kaufman infected with AIDS. I wouldn't have you here. Right there be alright. Are you like a walking aids molecule? Oh, that's that's me. You bring your ladies. Do you do you Bedlam here or in there's another bed? Yeah, I go back <mark>and</mark> go back. Yeah. I like it. I like it better that way. No, sometimes I like sometimes I'll have a girlfriend over <mark>and</mark> we'll stay in there in the middle of night. I got to take a pee <mark>and</mark> then I'll cut to this or day you want to cut to this bed so they could see <mark>and</mark> then I'll come in <mark>and</mark> I'll sit over on that bed. Just for fun. Just know something other second half the night. I sleep there. Well, I don't know because it's my place <mark>and</mark> I could sleep where I want afraid of intimacy. Yeah. Yeah, sometimes they want to be left alone to really yeah prostitutes are well whoa whoa, whoa, I'm not with any prostitutes. But yeah, I mean, I think regular don't most people guys don't you want to snuggle <mark>and</mark> stuff? I like a snuggle. Are you not a snuggler sometimes but then after a while like to I'd like to stay over there. I like to stay. So when so how long ago did you guys get married? How long would you guys get married? 2008 mm. Wow, it's been a while. It's been a while <mark>and</mark> we've been we were together for four years before so what is that 15 years? Yeah, <mark>and</mark> he live deep in the valley deep deep deep in the valley eight one eight eight one eight <mark>and</mark> but you're in Silverlake. So this makes you tell me of tell them what you said when you first came in here. Well everybody this is tell him what silver like is because I have a lot of trump supporters to follow. I like the people to build a countryman it out like this man the ways those up there goes my fucking thing. She's bucking wild motherfuckers shit. So tell us about what Silver Lake is. Yeah, you stay here. I used to live Tom <mark>and</mark> actually of here before we had kids I used to live here when I was cool <mark>and</mark> single <mark>and</mark> it's the hippest neighborhood. It's the coolest neighborhood. I think in La yeah <mark>and</mark> you can <mark>and</mark> there's like, alt kids <mark>and</mark> there's some you know, Gabe are dudes <mark>and</mark>", "Start Time (s)": 654.4, "End Time (s)": 773.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "really yeah prostitutes are well whoa whoa, whoa, I'm not with any prostitutes. But yeah, I mean, I think regular don't most people guys don't you want to snuggle <mark>and</mark> stuff? I like a snuggle. Are you not a snuggler sometimes but then after a while like to I'd like to stay over there. I like to stay. So when so how long ago did you guys get married? How long would you guys get married? 2008 mm. Wow, it's been a while. It's been a while <mark>and</mark> we've been we were together for four years before so what is that 15 years? Yeah, <mark>and</mark> he live deep in the valley deep deep deep in the valley eight one eight eight one eight <mark>and</mark> but you're in Silverlake. So this makes you tell me of tell them what you said when you first came in here. Well everybody this is tell him what silver like is because I have a lot of trump supporters to follow. I like the people to build a countryman it out like this man the ways those up there goes my fucking thing. She's bucking wild motherfuckers shit. So tell us about what Silver Lake is. Yeah, you stay here. I used to live Tom <mark>and</mark> actually of here before we had kids I used to live here when I was cool <mark>and</mark> single <mark>and</mark> it's the hippest neighborhood. It's the coolest neighborhood. I think in La yeah <mark>and</mark> you can <mark>and</mark> there's like, alt kids <mark>and</mark> there's some you know, Gabe are dudes <mark>and</mark> leather vest ABC a leather daddy guys. Yeah, I love that stuff <mark>and</mark> then in Trader <mark>Joe</mark> <mark>and</mark> the rest. Vard the reservoir every day. Are you doing that? Yeah, I got my bike. I told around the reservoir <mark>and</mark> stuff. Yeah. Yeah, it's great. That's so fun. <mark>And</mark> it's like older <mark>and</mark> rustic e <mark>and</mark> yeah Craig, so is there any way that you would leave the valley day when a to come back to this area? Never really never do you think? Where's Tom from Florida? Oh God. No, what part of Florida? No, you don't even know where your fucking husband because this is like they're told <mark>and</mark> stuff. I understand you don't want to do this is the coolest", "Start Time (s)": 704.9, "End Time (s)": 823.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of here before we had kids I used to live here when I was cool <mark>and</mark> single <mark>and</mark> it's the hippest neighborhood. It's the coolest neighborhood. I think in La yeah <mark>and</mark> you can <mark>and</mark> there's like, alt kids <mark>and</mark> there's some you know, Gabe are dudes <mark>and</mark> leather vest ABC a leather daddy guys. Yeah, I love that stuff <mark>and</mark> then in Trader <mark>Joe</mark> <mark>and</mark> the rest. Vard the reservoir every day. Are you doing that? Yeah, I got my bike. I told around the reservoir <mark>and</mark> stuff. Yeah. Yeah, it's great. That's so fun. <mark>And</mark> it's like older <mark>and</mark> rustic e <mark>and</mark> yeah Craig, so is there any way that you would leave the valley day when a to come back to this area? Never really never do you think? Where's Tom from Florida? Oh God. No, what part of Florida? No, you don't even know where your fucking husband because this is like they're told <mark>and</mark> stuff. I understand you don't want to do this is the coolest neighborhoods. Do you skateboard <mark>and</mark> stuff? No, I just know I got down on my bike. Yeah, this is I kind of feel like, you know, Robin Williams when he was like in his Fame 52, so like Robin Williams <mark>and</mark> he was like in his 50s or 60s. He was always tooling around San Francisco in Disguise to see him when I lived in San Francisco <mark>and</mark> he would stop <mark>and</mark> get a burrito <mark>and</mark> F yeah, so I feel like I feel like that. Yeah, this is when I was like hip before I had children I lived here <mark>and</mark> you don't have sex with a hipsters either. No Mom. I'm really help no problem. If you're if you're out there listening to random answer know you're a big fan of my podcast your you Virgin Eyes your wife, bro. He kind of day I'll take you for a nice your wife know he did because here's the thing I had weight really quick. Hey Dave, are we good on our marks? I think everything's fucked up here. I'm doing my best in this new status are looking pretty good. Man, but are you cutting or you're cutting ability good or is it's good? I'm on you right now <mark>and</mark> I just got to Christina just now it's okay cool. So so so here's the deal. So we hooked", "Start Time (s)": 761.2, "End Time (s)": 881.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because this is like they're told <mark>and</mark> stuff. I understand you don't want to do this is the coolest neighborhoods. Do you skateboard <mark>and</mark> stuff? No, I just know I got down on my bike. Yeah, this is I kind of feel like, you know, Robin Williams when he was like in his Fame 52, so like Robin Williams <mark>and</mark> he was like in his 50s or 60s. He was always tooling around San Francisco in Disguise to see him when I lived in San Francisco <mark>and</mark> he would stop <mark>and</mark> get a burrito <mark>and</mark> F yeah, so I feel like I feel like that. Yeah, this is when I was like hip before I had children I lived here <mark>and</mark> you don't have sex with a hipsters either. No Mom. I'm really help no problem. If you're if you're out there listening to random answer know you're a big fan of my podcast your you Virgin Eyes your wife, bro. He kind of day I'll take you for a nice your wife know he did because here's the thing I had weight really quick. Hey Dave, are we good on our marks? I think everything's fucked up here. I'm doing my best in this new status are looking pretty good. Man, but are you cutting or you're cutting ability good or is it's good? I'm on you right now <mark>and</mark> I just got to Christina just now it's okay cool. So so so here's the deal. So we hooked up I was 28 years old. So we've been together since we were kids really so I never even made out with another male comic but I did have male comedian friends in Silver Lake <mark>and</mark> your pad is reminiscent of that twenty something year old a lot of hair on the ground usually in the But you're very clean. I'm very surprised. Well, I have my housekeeper was here. So there have a house. Yeah, I've always had a housekeeper <mark>and</mark> who designed your interior designer. Well, I just kind of take gummies <mark>and</mark> I just start moving shit around you're keeping your window open. Yeah with the effects of the think so the thing that I really like about Tom. I mean, I don't know him too. Well, yeah, he's right the thing that I really like about him when I see him he seemed so soft. You know what? I mean, like just like soft <mark>and</mark> kind of doughy face is little as little faces little", "Start Time (s)": 817.2, "End Time (s)": 935.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or you're cutting ability good or is it's good? I'm on you right now <mark>and</mark> I just got to Christina just now it's okay cool. So so so here's the deal. So we hooked up I was 28 years old. So we've been together since we were kids really so I never even made out with another male comic but I did have male comedian friends in Silver Lake <mark>and</mark> your pad is reminiscent of that twenty something year old a lot of hair on the ground usually in the But you're very clean. I'm very surprised. Well, I have my housekeeper was here. So there have a house. Yeah, I've always had a housekeeper <mark>and</mark> who designed your interior designer. Well, I just kind of take gummies <mark>and</mark> I just start moving shit around you're keeping your window open. Yeah with the effects of the think so the thing that I really like about Tom. I mean, I don't know him too. Well, yeah, he's right the thing that I really like about him when I see him he seemed so soft. You know what? I mean, like just like soft <mark>and</mark> kind of doughy face is little as little faces little bald head. You know, he's like soft. He's like sweet joining me Oh, I thought you meant no. Yes penis. Not soft like soft at heart felt soft. Like he's sweet. You know what? I mean? Like a lot of people say the opposite that he looks really intimidating <mark>and</mark> mean <mark>and</mark> angry <mark>and</mark> I think it's because the yeah, he's full of Rage like we all are yeah like he gets so then he's looks soft at me, but it's just an act. She's fucking crazy fucking crazy. Like he would stab Barista to death if they got his drink order wrong. Like that's what I'm dealing with on a daily basis. So it's kind of like that Michael Douglas movie. What is it when going down so he's following please that on a loop. Well, my husband has a favorite serial killer. Do you have a favorite serial killer? I like the guy the real fuck. What's Richard Ramirez was pretty fucking The Night Stalker because he was in LA gai. I feel like that's part of our childhood it is Art of a childhood. Yeah, did you have to sleep with your", "Start Time (s)": 872.8, "End Time (s)": 992.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to death if they got his drink order wrong. Like that's what I'm dealing with on a daily basis. So it's kind of like that Michael Douglas movie. What is it when going down so he's following please that on a loop. Well, my husband has a favorite serial killer. Do you have a favorite serial killer? I like the guy the real fuck. What's Richard Ramirez was pretty fucking The Night Stalker because he was in LA gai. I feel like that's part of our childhood it is Art of a childhood. Yeah, did you have to sleep with your windows locked? Remember? Hey Bill. Oh, yes, you know what time it is, right? Oh, yes. What time is it right number two? We're turning up <mark>and</mark> tell her like this. All right. Here we go. All right cut cut cut. This is awesome. So it all stems from mr. <mark>Joe</mark> <mark>Rogan</mark> kind of everything away the podcast. Yeah. Yeah father is <mark>Joe</mark> Rogan. Yeah, <mark>and</mark> we got started because <mark>Joe</mark> knew both Tom <mark>and</mark> I <mark>and</mark> he was like you guys are married. Uh-huh. You should do podcast. When did he say this to you?", "Start Time (s)": 965.5, "End Time (s)": 1084.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We're turning up <mark>and</mark> tell her like this. All right. Here we go. All right cut cut cut. This is awesome. So it all stems from mr. <mark>Joe</mark> <mark>Rogan</mark> kind of everything away the podcast. Yeah. Yeah father is <mark>Joe</mark> Rogan. Yeah, <mark>and</mark> we got started because <mark>Joe</mark> knew both Tom <mark>and</mark> I <mark>and</mark> he was like you guys are married. Uh-huh. You should do podcast. When did he say this to you? This is oh God eight years except for the people a lot of my people know your podcast butts explain to them. Can I drink something course explain to them? Oh God, is that no, it's good. It's good. Explain it. I'm what your mom's house is <mark>and</mark> how <mark>Joe</mark> told you to so your mom's house podcast is a show I do with my husband Tom Segura <mark>and</mark> it started about eight years ago when <mark>Joe</mark> <mark>Rogan</mark> suggested we do it eight years. You guys been doing a fucking eight years. So we're like one of the early whatevers early adapters <mark>and</mark> because of <mark>Joe</mark> we started here in Silver Lake actually really now that I think about this is the birthplace. They should rename Silverlake the birthplace of your mom's house <mark>and</mark> we started it in our crappy little apartment. Moment here you <mark>and</mark> Tom. Yes, <mark>and</mark> that our neighbor would cook <mark>and</mark> just so you know every show every show podcast Studio. I was kind of prepared some some sort of food. Oh, okay.", "Start Time (s)": 1024.2, "End Time (s)": 1136.1, "Clip Length (min)": 1.86, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So it all stems from mr. <mark>Joe</mark> <mark>Rogan</mark> kind of everything away the podcast. Yeah. Yeah father is <mark>Joe</mark> Rogan. Yeah, <mark>and</mark> we got started because <mark>Joe</mark> knew both Tom <mark>and</mark> I <mark>and</mark> he was like you guys are married. Uh-huh. You should do podcast. When did he say this to you? This is oh God eight years except for the people a lot of my people know your podcast butts explain to them. Can I drink something course explain to them? Oh God, is that no, it's good. It's good. Explain it. I'm what your mom's house is <mark>and</mark> how <mark>Joe</mark> told you to so your mom's house podcast is a show I do with my husband Tom Segura <mark>and</mark> it started about eight years ago when <mark>Joe</mark> <mark>Rogan</mark> suggested we do it eight years. You guys been doing a fucking eight years. So we're like one of the early whatevers early adapters <mark>and</mark> because of <mark>Joe</mark> we started here in Silver Lake actually really now that I think about this is the birthplace. They should rename Silverlake the birthplace of your mom's house <mark>and</mark> we started it in our crappy little apartment. Moment here you <mark>and</mark> Tom. Yes, <mark>and</mark> that our neighbor would cook <mark>and</mark> just so you know every show every show podcast Studio. I was kind of prepared some some sort of food. Oh, okay. What are you making? I just got a little guacamole <mark>and</mark> chips. So these are fresh. I got this these are good. You're such a good host. Yeah, these are good these what's with the bread <mark>and</mark> the bags these what are you doing with this is one day. I'm going to have Children, I'm gonna make sandwiches or not. I'm gonna say sandwiches for my kids necessary your friend. Once you impregnate Whitney. Yeah, Whitney Cummings dude. No for real. You got to make that have financially it's going to work for both of us. That's more of a financial thing really can't even look but she's like mad at me about it. I don't know. I think she should just Embrace <mark>and</mark> I think you'd be a great father <mark>and</mark> I think you guys make a great couple <mark>and</mark> I don't know what we don't have to be married together <mark>and</mark> all that stuff, but just like my in her egg <mark>and</mark>", "Start Time (s)": 1067.8, "End Time (s)": 1187.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "actually really now that I think about this is the birthplace. They should rename Silverlake the birthplace of your mom's house <mark>and</mark> we started it in our crappy little apartment. Moment here you <mark>and</mark> Tom. Yes, <mark>and</mark> that our neighbor would cook <mark>and</mark> just so you know every show every show podcast Studio. I was kind of prepared some some sort of food. Oh, okay. What are you making? I just got a little guacamole <mark>and</mark> chips. So these are fresh. I got this these are good. You're such a good host. Yeah, these are good these what's with the bread <mark>and</mark> the bags these what are you doing with this is one day. I'm going to have Children, I'm gonna make sandwiches or not. I'm gonna say sandwiches for my kids necessary your friend. Once you impregnate Whitney. Yeah, Whitney Cummings dude. No for real. You got to make that have financially it's going to work for both of us. That's more of a financial thing really can't even look but she's like mad at me about it. I don't know. I think she should just Embrace <mark>and</mark> I think you'd be a great father <mark>and</mark> I think you guys make a great couple <mark>and</mark> I don't know what we don't have to be married together <mark>and</mark> all that stuff, but just like my in her egg <mark>and</mark> mix that shit. You see she's very tall <mark>and</mark> slender. That's what I'm saying. You have very good looks as well. You guys are both highly intelligent. You think it could work out. Well tell like horses. Yeah. I don't like horses a lot when he likes Whitney. Does he like oranges as much as you but I just think she should stop fucking beating around the bush <mark>and</mark> try to stop dicking around. He's like exercise or model fucking guys that she fucks with she doesn't fuck model guys. Whatever. She goes. I said, I was gonna do like this is I'll be backstage in the main room. We're all back there conversing about to go on. She's like, this is Skip we've been dating for I'm like you're wasting your fucking time. Just take my semen. Let's rock <mark>and</mark> roll seriously, so go on for the joke <mark>Joe</mark> <mark>Rogan</mark> coalesce. I can't believe you told Joe. I need to take your semen. She should take it <mark>and</mark> I think", "Start Time (s)": 1117.5, "End Time (s)": 1237.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That's more of a financial thing really can't even look but she's like mad at me about it. I don't know. I think she should just Embrace <mark>and</mark> I think you'd be a great father <mark>and</mark> I think you guys make a great couple <mark>and</mark> I don't know what we don't have to be married together <mark>and</mark> all that stuff, but just like my in her egg <mark>and</mark> mix that shit. You see she's very tall <mark>and</mark> slender. That's what I'm saying. You have very good looks as well. You guys are both highly intelligent. You think it could work out. Well tell like horses. Yeah. I don't like horses a lot when he likes Whitney. Does he like oranges as much as you but I just think she should stop fucking beating around the bush <mark>and</mark> try to stop dicking around. He's like exercise or model fucking guys that she fucks with she doesn't fuck model guys. Whatever. She goes. I said, I was gonna do like this is I'll be backstage in the main room. We're all back there conversing about to go on. She's like, this is Skip we've been dating for I'm like you're wasting your fucking time. Just take my semen. Let's rock <mark>and</mark> roll seriously, so go on for the joke <mark>Joe</mark> <mark>Rogan</mark> coalesce. I can't believe you told Joe. I need to take your semen. She should take it <mark>and</mark> I think dude, it doesn't we don't have time. She's getting older. Let's fucking behind in terms of Comedy to you guys would make the funniest craziest. Alright. Yeah, it's so great. Maybe really either that or really quiet. I know well now because my kids are crazy. Both of them are crazy in different ways because Tom <mark>and</mark> I are what are you doing? You can try to open this you need help let him on your help. You you need a mom. Be careful with it Jesus Christ. So this is right prepare to from my debt. Get what we don't do that shit. What the fuck are worded time. She said she do it. I didn't say she would do it. I just I don't want to hear me how you cook do you cook course? What do you really cook tell me cook anything? No. What do you think? What are you going to eat tonight? Be honest. You're going to go down to yuka's. So we're you guys I'm Los Feliz Boulevard", "Start Time (s)": 1171.2, "End Time (s)": 1290.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Joe</mark> <mark>Rogan</mark> coalesce. I can't believe you told Joe. I need to take your semen. She should take it <mark>and</mark> I think dude, it doesn't we don't have time. She's getting older. Let's fucking behind in terms of Comedy to you guys would make the funniest craziest. Alright. Yeah, it's so great. Maybe really either that or really quiet. I know well now because my kids are crazy. Both of them are crazy in different ways because Tom <mark>and</mark> I are what are you doing? You can try to open this you need help let him on your help. You you need a mom. Be careful with it Jesus Christ. So this is right prepare to from my debt. Get what we don't do that shit. What the fuck are worded time. She said she do it. I didn't say she would do it. I just I don't want to hear me how you cook do you cook course? What do you really cook tell me cook anything? No. What do you think? What are you going to eat tonight? Be honest. You're going to go down to yuka's. So we're you guys I'm Los Feliz Boulevard <mark>and</mark> Hillhurst. Okay. What do you got your burritos from in this neighborhood? There's nothing that good Mexican food here. I don't know. I mix it up. There's there's a place. I'll El Condor right down the street. That's a good one. That's a good so you like a little of this stuff like a lot of heat on there. Okay, so tell me about so So eight years ago so really what what happened eight years ago <mark>Joe</mark> <mark>Rogan</mark> told Tom <mark>and</mark> I to start a podcast. Thank you Joanna he goes <mark>and</mark> where were you guys so so he called Tom because you just see me at The Comedy Store <mark>Joe</mark> <mark>and</mark> he goes bro your fucking wife's phone. Yeah, you're very funny. You should have a fucking podcast <mark>and</mark> then Tom told me <mark>and</mark> then I went what's a podcast <mark>and</mark> then Brian Red Band invited us to his house because he was producing them at the time <mark>and</mark> we sat on his disgusting couch in the valley. <mark>And</mark> we did the first two episodes of your mom's house. <mark>And</mark> that was it. We talked about drugs <mark>and</mark> masturbating <mark>and</mark> your farts <mark>and</mark> we still do it's the house that farts built. We just talked about farts all yeah, you guys do like that. It's caca. Poopoo. What do you think is funny or fart or dick jokes? Thank", "Start Time (s)": 1230.6, "End Time (s)": 1350.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "cook tell me cook anything? No. What do you think? What are you going to eat tonight? Be honest. You're going to go down to yuka's. So we're you guys I'm Los Feliz Boulevard <mark>and</mark> Hillhurst. Okay. What do you got your burritos from in this neighborhood? There's nothing that good Mexican food here. I don't know. I mix it up. There's there's a place. I'll El Condor right down the street. That's a good one. That's a good so you like a little of this stuff like a lot of heat on there. Okay, so tell me about so So eight years ago so really what what happened eight years ago <mark>Joe</mark> <mark>Rogan</mark> told Tom <mark>and</mark> I to start a podcast. Thank you Joanna he goes <mark>and</mark> where were you guys so so he called Tom because you just see me at The Comedy Store <mark>Joe</mark> <mark>and</mark> he goes bro your fucking wife's phone. Yeah, you're very funny. You should have a fucking podcast <mark>and</mark> then Tom told me <mark>and</mark> then I went what's a podcast <mark>and</mark> then Brian Red Band invited us to his house because he was producing them at the time <mark>and</mark> we sat on his disgusting couch in the valley. <mark>And</mark> we did the first two episodes of your mom's house. <mark>And</mark> that was it. We talked about drugs <mark>and</mark> masturbating <mark>and</mark> your farts <mark>and</mark> we still do it's the house that farts built. We just talked about farts all yeah, you guys do like that. It's caca. Poopoo. What do you think is funny or fart or dick jokes? Thank you. Well, I'm so excited. Thanks, bro. Yeah, I don't know to be honest. I don't really like fart. I don't really like farts. You're not in the poopy. You're on the deck. Good job. I thought you know, I got that from my mom. Why is my mom always didn't like the People telling fart jokes on the really she's basically if you're a comedian like friends with Bert Kreischer goes onstage at the store with no shirt on if my mom was there. She wouldn't allow that no shit. No no shit. So you think Burt would be the first meeting it kicked out in The Comedy Store because he's fat or because he's raised sister both. What do you think? No, I think he's hilarious. I just think that I don't know my mom. What about the do I wear fucking care? Are you pick to it's a great talking about farts. Let's discuss. What you would say to you if you were talking I thought about fights like your mother wouldn't have dumped it.", "Start Time (s)": 1280.8, "End Time (s)": 1400.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with no shirt on if my mom was there. She wouldn't allow that no shit. No no shit. So you think Burt would be the first meeting it kicked out in The Comedy Store because he's fat or because he's raised sister both. What do you think? No, I think he's hilarious. I just think that I don't know my mom. What about the do I wear fucking care? Are you pick to it's a great talking about farts. Let's discuss. What you would say to you if you were talking I thought about fights like your mother wouldn't have dumped it. What is she like what was the thing that she she was like all your other stuff. Just nice little things like I used to do the text over here coming in the morning. Oh the glory hole. This reminds me so much of my single Silver Lake. No, I'm kind of into it. I would win this close to another man 2005 really. I mean, I haven't been with another man because again, I don't know Tom that Well, yeah, I was a little concerned because I know I mean I'm not touchy feely but I know that I'm like very affectionate <mark>and</mark> I don't want Tom to think that I was doing good. You know, I think so. I've got such mom Vibes. I don't think people leave. Oh here. There you go. That's the glory hole though. Oh, if you had a penis you put your painter there. There's a girl that dishwasher. Who's your soul mate? Who's a woman? Really? Yeah, I see that what kind of woman would you have to marry to have children with let's be honest like really? Well, somebody Silly they have to be so silly. Someone that got me lets me be me. Yeah, you know someone that's not going to put strings on my mom never supported getting married. My problem is the opposite reason I stay away <mark>and</mark> get married. That's the word your dad on her from what I understand had a pretty rocky relationship, right? Yeah. Yeah, but she says that that relationship stifle", "Start Time (s)": 1373.6, "End Time (s)": 1493.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that's not going to put strings on my mom never supported getting married. My problem is the opposite reason I stay away <mark>and</mark> get married. That's the word your dad on her from what I understand had a pretty rocky relationship, right? Yeah. Yeah, but she says that that relationship stifle stifle shows the it stifles you you don't it means what she says, that's really healthy. Well, that's I'm fucking by myself in Silver Lake in a fucking apartment eating fucking Sarita. Absolutely. These are great. These are like real chips. No my parents had a shitty thing to but you know, but okay. I see you like a 20 year old yoga instructor may be have you dated that before? yeah, you know I'm have Who's the love of your life? Did you have a good you have a big love? I had a girlfriend that I was seeing for a while, but <mark>and</mark> I did love her <mark>and</mark> I love being with her but I don't want to say she was an alcoholic you're gonna remain but she was kind of like she wet my bed <mark>and</mark> stuff a couple times. I like to see this bottle right here. This cost Amigos. Mmm. You see this right here. That's our pea. So basically what happened was is on my birthday a friend of mine gave me cost Amigos <mark>and</mark> she drank the whole thing my girlfriend drank the whole thing. That's not good. <mark>And</mark> then she said I, you know yelled at I said as a present <mark>and</mark> what Fuck <mark>and</mark> you drank the whole thing? <mark>And</mark> then she replaced it. She gave me a replacement bottle right? But then she fucking drank the replacement bottom I'm saying something like yeah, I don't want to be babysitting. I don't want to be babysitting anyone. That's no good. Yeah so much heartache. I love her. But yeah, no I hear you. <mark>And</mark> then there's also I don't trust a", "Start Time (s)": 1473.6, "End Time (s)": 1593.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but <mark>and</mark> I did love her <mark>and</mark> I love being with her but I don't want to say she was an alcoholic you're gonna remain but she was kind of like she wet my bed <mark>and</mark> stuff a couple times. I like to see this bottle right here. This cost Amigos. Mmm. You see this right here. That's our pea. So basically what happened was is on my birthday a friend of mine gave me cost Amigos <mark>and</mark> she drank the whole thing my girlfriend drank the whole thing. That's not good. <mark>And</mark> then she said I, you know yelled at I said as a present <mark>and</mark> what Fuck <mark>and</mark> you drank the whole thing? <mark>And</mark> then she replaced it. She gave me a replacement bottle right? But then she fucking drank the replacement bottom I'm saying something like yeah, I don't want to be babysitting. I don't want to be babysitting anyone. That's no good. Yeah so much heartache. I love her. But yeah, no I hear you. <mark>And</mark> then there's also I don't trust a lot of girls <mark>and</mark> I don't trust myself. What don't you trust yourself about? Even now at your adult age, you don't you know yourself. Well, you're no longer 20 year old. you know, I think what would happen is if I If I found a girl <mark>and</mark> I thought she was the one then I would trust myself. You don't eat me that makes sense. Sure. You trust yourself to like open yourself to her. You mean no to be faithful to oh fucking. Yeah. Well, you're still all about the dick right now pussies. Really? Some guys are not meant to marry. My dad's the same way. He's just like crushing pussy since he was born can't can't commit to one. I mean he can for a while but some guys are just not meant to yeah, what was up with Ari what was up with arry? <mark>And</mark> Bert crying <mark>and</mark> asked what the fuck is that? They", "Start Time (s)": 1531.4, "End Time (s)": 1651.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yeah, no I hear you. <mark>And</mark> then there's also I don't trust a lot of girls <mark>and</mark> I don't trust myself. What don't you trust yourself about? Even now at your adult age, you don't you know yourself. Well, you're no longer 20 year old. you know, I think what would happen is if I If I found a girl <mark>and</mark> I thought she was the one then I would trust myself. You don't eat me that makes sense. Sure. You trust yourself to like open yourself to her. You mean no to be faithful to oh fucking. Yeah. Well, you're still all about the dick right now pussies. Really? Some guys are not meant to marry. My dad's the same way. He's just like crushing pussy since he was born can't can't commit to one. I mean he can for a while but some guys are just not meant to yeah, what was up with Ari what was up with arry? <mark>And</mark> Bert crying <mark>and</mark> asked what the fuck is that? They are a dose Bert already dosed them at a bird's house when his kids were around. I think I put some stuff in the guac. No, no, no. You know, yeah you open for me for years. Yeah. Yes. I do know that <mark>and</mark> he stole did he sell your merch <mark>and</mark> stuff. He toured with you. There will be open for me for a couple times. But I love re I do too like I love him. So what do you think is going on? Because I think it's very anti", "Start Time (s)": 1588.1, "End Time (s)": 1707.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "already dosed them at a bird's house when his kids were around. I think I put some stuff in the guac. No, no, no. You know, yeah you open for me for years. Yeah. Yes. I do know that <mark>and</mark> he stole did he sell your merch <mark>and</mark> stuff. He toured with you. There will be open for me for a couple times. But I love re I do too like I love him. So what do you think is going on? Because I think it's very anti entertainment business. Right? First of all, I think he doesn't want to play by the rules. Yeah, <mark>and</mark> he's not about being political at. All, right? Yeah, I'm saying he's not about like being like hey, I'm going to touch this subject not it has won a dancer. I was like this is it right? If you don't like it fuck off, right, you know, which is very self-destructive. Yeah, right. Yeah. I hope I hope I think is really funny. <mark>And</mark> yeah, but Anyway, don't build. Yes number three dude number three it is spring break. This is the mark of her own washer <mark>and</mark> dryer", "Start Time (s)": 1653.2, "End Time (s)": 1769.2, "Clip Length (min)": 1.93, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Right? First of all, I think he doesn't want to play by the rules. Yeah, <mark>and</mark> he's not about being political at. All, right? Yeah, I'm saying he's not about like being like hey, I'm going to touch this subject not it has won a dancer. I was like this is it right? If you don't like it fuck off, right, you know, which is very self-destructive. Yeah, right. Yeah. I hope I hope I think is really funny. <mark>And</mark> yeah, but Anyway, don't build. Yes number three dude number three it is spring break. This is the mark of her own washer <mark>and</mark> dryer set the music set that what the fuck. Why do you keep fucking going so long? You don't even know I should really talk to them. So oh my God, so that's so that's crazy. So, let's go back to jail for a second because I want everyone to know where it started from because a lot of people listening they know <mark>Joe</mark> <mark>Rogan</mark> is but he started the whole thing. He did they started I had let's break it down if he was like the grandpa. He's the guy in charge <mark>and</mark> you guys I'll sprinkle down. Yeah. So you guys started eight years ago. He told you to do it. Yeah, <mark>and</mark> how's that changed your life? I mean, it's been everything. He's been everything because now the podcasting audience is like they're so loyal so DieHard when Your city they come out like <mark>and</mark> they know you know, how many dump sites like yesterday. They know like wow. Yeah. It's so great for comedy <mark>and</mark> we do owe", "Start Time (s)": 1708.9, "End Time (s)": 1828.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This is the mark of her own washer <mark>and</mark> dryer set the music set that what the fuck. Why do you keep fucking going so long? You don't even know I should really talk to them. So oh my God, so that's so that's crazy. So, let's go back to jail for a second because I want everyone to know where it started from because a lot of people listening they know <mark>Joe</mark> <mark>Rogan</mark> is but he started the whole thing. He did they started I had let's break it down if he was like the grandpa. He's the guy in charge <mark>and</mark> you guys I'll sprinkle down. Yeah. So you guys started eight years ago. He told you to do it. Yeah, <mark>and</mark> how's that changed your life? I mean, it's been everything. He's been everything because now the podcasting audience is like they're so loyal so DieHard when Your city they come out like <mark>and</mark> they know you know, how many dump sites like yesterday. They know like wow. Yeah. It's so great for comedy <mark>and</mark> we do owe everything to essentially <mark>Joe</mark> <mark>Rogan</mark> <mark>and</mark> <mark>and</mark> that whole thing. He basically innovated the shit. Hmm. Like he was Mark Mark first ride, man. I think my very first <mark>and</mark> then <mark>Joe</mark> <mark>and</mark> red band believe Mike, let's get this equipment <mark>and</mark> let's just sit around <mark>and</mark> talk about stuff. We want to talk about <mark>and</mark> then this Whole thing came <mark>and</mark> how did Tom how did Tom meet Joe? Oh my gosh. Oh Tom Juan a comedy contest. It was like, yeah, it looks great like Maxim magazine or something <mark>and</mark> he was on a tree one last spot on a tour. I believe with <mark>Joe</mark> <mark>and</mark> like some other people <mark>and</mark> then I think I just became buddies. Yeah, I believe is they're very they're the same sensibility there. They've been Joe's been really good to us <mark>and</mark> really cool <mark>and</mark> kind of a mentor I Everybody <mark>and</mark> then <mark>and</mark> then Burt, how", "Start Time (s)": 1765.9, "End Time (s)": 1879.9, "Clip Length (min)": 1.9, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they're so loyal so DieHard when Your city they come out like <mark>and</mark> they know you know, how many dump sites like yesterday. They know like wow. Yeah. It's so great for comedy <mark>and</mark> we do owe everything to essentially <mark>Joe</mark> <mark>Rogan</mark> <mark>and</mark> <mark>and</mark> that whole thing. He basically innovated the shit. Hmm. Like he was Mark Mark first ride, man. I think my very first <mark>and</mark> then <mark>Joe</mark> <mark>and</mark> red band believe Mike, let's get this equipment <mark>and</mark> let's just sit around <mark>and</mark> talk about stuff. We want to talk about <mark>and</mark> then this Whole thing came <mark>and</mark> how did Tom how did Tom meet Joe? Oh my gosh. Oh Tom Juan a comedy contest. It was like, yeah, it looks great like Maxim magazine or something <mark>and</mark> he was on a tree one last spot on a tour. I believe with <mark>Joe</mark> <mark>and</mark> like some other people <mark>and</mark> then I think I just became buddies. Yeah, I believe is they're very they're the same sensibility there. They've been Joe's been really good to us <mark>and</mark> really cool <mark>and</mark> kind of a mentor I Everybody <mark>and</mark> then <mark>and</mark> then Burt, how did how did <mark>Joe</mark> hook up with Bert? I don't know. You don't know <mark>and</mark> then what about Tony Tony hooked up with birth through the store. I know that right - yeah, it's always later. He's a younger puppy. Yeah, he's killing it. Yeah. Yeah, he's doing good. It's kind man. <mark>And</mark> then so all you guys kind of branched off of that <mark>and</mark> now you're just off kind of like doing your own thing <mark>and</mark> then what about acting <mark>and</mark> all that stuff because before the podcast I know you were like auditioning a lot <mark>and</mark> yeah a little different no more right kind of yeah, will you You know what it is is that the landscape of entertainment is changing so much. So for me to do some scripted thing, I do feel like it takes time away from the podcasting <mark>and</mark> stand up which is how we earn a living, you know how to react money have you ever acted before I just did a had a small part in the movie time just did countdown, huh? <mark>And</mark> I'm trying to remember them like stupid shit. Wow, so but you like acting because I love acting you you are good at", "Start Time (s)": 1815.5, "End Time (s)": 1935.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "became buddies. Yeah, I believe is they're very they're the same sensibility there. They've been Joe's been really good to us <mark>and</mark> really cool <mark>and</mark> kind of a mentor I Everybody <mark>and</mark> then <mark>and</mark> then Burt, how did how did <mark>Joe</mark> hook up with Bert? I don't know. You don't know <mark>and</mark> then what about Tony Tony hooked up with birth through the store. I know that right - yeah, it's always later. He's a younger puppy. Yeah, he's killing it. Yeah. Yeah, he's doing good. It's kind man. <mark>And</mark> then so all you guys kind of branched off of that <mark>and</mark> now you're just off kind of like doing your own thing <mark>and</mark> then what about acting <mark>and</mark> all that stuff because before the podcast I know you were like auditioning a lot <mark>and</mark> yeah a little different no more right kind of yeah, will you You know what it is is that the landscape of entertainment is changing so much. So for me to do some scripted thing, I do feel like it takes time away from the podcasting <mark>and</mark> stand up which is how we earn a living, you know how to react money have you ever acted before I just did a had a small part in the movie time just did countdown, huh? <mark>And</mark> I'm trying to remember them like stupid shit. Wow, so but you like acting because I love acting you you are good at acting I'm okay at it. Yeah, but you're you know You're an Entertainer. Look at this fucking place. You've got all these cameras you're concerned about angles whining. Hmm. That's your lane. Yeah, that's my thing. You make movies. Yeah, make movies. Yeah. Yeah. It's important. I was to in here. Yeah, so that's crazy machine. Yeah, it's nice, right? Yeah. So yeah, so so then as far as like other Uh comedians. Yeah support like which ones you really look I can't tell you what I'm doing. I'm sorry. I should tell them I'm friends with Angela Johnson. Nikki Glaser. Whitney Cummings. Ali Wong is my home <mark>and</mark> I love them <mark>and</mark> I want to have them over for like dinners. We talk <mark>and</mark>", "Start Time (s)": 1868.3, "End Time (s)": 1988.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a had a small part in the movie time just did countdown, huh? <mark>And</mark> I'm trying to remember them like stupid shit. Wow, so but you like acting because I love acting you you are good at acting I'm okay at it. Yeah, but you're you know You're an Entertainer. Look at this fucking place. You've got all these cameras you're concerned about angles whining. Hmm. That's your lane. Yeah, that's my thing. You make movies. Yeah, make movies. Yeah. Yeah. It's important. I was to in here. Yeah, so that's crazy machine. Yeah, it's nice, right? Yeah. So yeah, so so then as far as like other Uh comedians. Yeah support like which ones you really look I can't tell you what I'm doing. I'm sorry. I should tell them I'm friends with Angela Johnson. Nikki Glaser. Whitney Cummings. Ali Wong is my home <mark>and</mark> I love them <mark>and</mark> I want to have them over for like dinners. We talk <mark>and</mark> have dinner is because there are so few of us. Such rarefied air today is successful female comic but I like them all they're all great allies is great everybody. he realises to migrate isn't it while doing it I know it's grab some compelling it dude she's an actor if she loves acting shit yeah I just enjoy parking so much I like this uh-huh this is your thing I like this I want to be myself yeah right is this the best gig ever yeah this is fun yes you did this is really fun <mark>and</mark> then as far as PC stuff yeah do you ever because I know it's like obviously it's kind of a weird time like do you feel weird when you go to the bathroom <mark>and</mark> you see the two genders there's no you go in there's like gender-free I do I feel weird of course do you not because when I was growing up if you took a girl in the guys bathroom you'd get arrested right <mark>and</mark> now it like you know now they arrest you if you don't go you have to go in the same bathroom I know well I just don't want to go to the bathroom next to a guy taking a", "Start Time (s)": 1923.9, "End Time (s)": 2043.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Nikki Glaser. Whitney Cummings. Ali Wong is my home <mark>and</mark> I love them <mark>and</mark> I want to have them over for like dinners. We talk <mark>and</mark> have dinner is because there are so few of us. Such rarefied air today is successful female comic but I like them all they're all great allies is great everybody. he realises to migrate isn't it while doing it I know it's grab some compelling it dude she's an actor if she loves acting shit yeah I just enjoy parking so much I like this uh-huh this is your thing I like this I want to be myself yeah right is this the best gig ever yeah this is fun yes you did this is really fun <mark>and</mark> then as far as PC stuff yeah do you ever because I know it's like obviously it's kind of a weird time like do you feel weird when you go to the bathroom <mark>and</mark> you see the two genders there's no you go in there's like gender-free I do I feel weird of course do you not because when I was growing up if you took a girl in the guys bathroom you'd get arrested right <mark>and</mark> now it like you know now they arrest you if you don't go you have to go in the same bathroom I know well I just don't want to go to the bathroom next to a guy taking a dump like I don't want to be with dudes dudes are nasty right why do I want that so why did they why are they doing that it's just kind of the world they don't do that like a Kentucky <mark>and</mark> shit generally take no I think that's a load Christian do we do that the what do you think what's going on? You know <mark>and</mark> then what about when you when you see what about when you see like trash cans? Yeah, <mark>and</mark> you see like put this in that trash can this <mark>and</mark> that trash can this <mark>and</mark> you just say fuck it. I don't know. What the fuck is this biodegradable. Is it not but you're gonna say no binary I know. No you recycle you live in Silver Lake you have to recycle. No, I'm a recycler. I compost I'd you compost I don't know if that means you got to put your vegetable scraps <mark>and</mark> your stuff <mark>and</mark> it dirty. I do that those mandatory ins. Why don't you give us Chris", "Start Time (s)": 1976.2, "End Time (s)": 2096.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I do I feel weird of course do you not because when I was growing up if you took a girl in the guys bathroom you'd get arrested right <mark>and</mark> now it like you know now they arrest you if you don't go you have to go in the same bathroom I know well I just don't want to go to the bathroom next to a guy taking a dump like I don't want to be with dudes dudes are nasty right why do I want that so why did they why are they doing that it's just kind of the world they don't do that like a Kentucky <mark>and</mark> shit generally take no I think that's a load Christian do we do that the what do you think what's going on? You know <mark>and</mark> then what about when you when you see what about when you see like trash cans? Yeah, <mark>and</mark> you see like put this in that trash can this <mark>and</mark> that trash can this <mark>and</mark> you just say fuck it. I don't know. What the fuck is this biodegradable. Is it not but you're gonna say no binary I know. No you recycle you live in Silver Lake you have to recycle. No, I'm a recycler. I compost I'd you compost I don't know if that means you got to put your vegetable scraps <mark>and</mark> your stuff <mark>and</mark> it dirty. I do that those mandatory ins. Why don't you give us Chris back here is broke. Yo, well, there are no that was already ran three play some music play some music bro. Wow, cut cut cut. So let's lastly talk about surrogacy. Sure. Okay. Yeah surrogates that what you <mark>and</mark> Whitney are going to do. Well know this but I don't think she's gonna want to have my baby. No. No, I don't think she's going on it. But if we don't have me <mark>and</mark> her don't have it. Yeah, which is far as surrogacy. Do you know about that? I didn't do that. But you know about what it is. Yeah, you you hire someone to carry your baby. Yeah. Yeah. I think it's great. I think you should do it. Really are you going to are you looking into it? Yes, it's a little it's a little what's the word? It's expensive. It's expensive. It's like $100,000", "Start Time (s)": 2029.1, "End Time (s)": 2149.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Chris back here is broke. Yo, well, there are no that was already ran three play some music play some music bro. Wow, cut cut cut. So let's lastly talk about surrogacy. Sure. Okay. Yeah surrogates that what you <mark>and</mark> Whitney are going to do. Well know this but I don't think she's gonna want to have my baby. No. No, I don't think she's going on it. But if we don't have me <mark>and</mark> her don't have it. Yeah, which is far as surrogacy. Do you know about that? I didn't do that. But you know about what it is. Yeah, you you hire someone to carry your baby. Yeah. Yeah. I think it's great. I think you should do it. Really are you going to are you looking into it? Yes, it's a little it's a little what's the word? It's expensive. It's expensive. It's like $100,000 at least in do you trust that person? Yeah, that's the whole Thing is like if you have the baby you get the egg from here <mark>and</mark> you get your semen <mark>and</mark> then you put it in some other girl <mark>and</mark> then you don't know if that girl is not doing methamphetamines or drinking or all that stuff. But if my baby comes out to form then what bill right what happened then that's it right there. Look you just got to hear what you're stuck. Right? Why do you say stuff? That's that's the way it's supposed to be. Oh that was that was insensitive. I'm sorry. No if you have a baby with a big head <mark>and</mark> that's what that's the way. It's Gotta Be. Hold it that's that's the way it's got to be <mark>and</mark> I was thinking like if you have a baby with the big head. Yeah, I think it's kind of cool in a way because if you go to the park, you know, Pete a lot of guys like to use their dog. You don't even need for for me girls, right? You have a baby with the big head. That's what that's kind of a talking point. Yeah. It's a good job. You're like, hey, so what do you guys think? Hey Bill want to read those comments really quick before we wrap it up here Bills going to just read a couple comments. No. From are we sure we want to hear what the public has", "Start Time (s)": 2095.9, "End Time (s)": 2215.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, Pete a lot of guys like to use their dog. You don't even need for for me girls, right? You have a baby with the big head. That's what that's kind of a talking point. Yeah. It's a good job. You're like, hey, so what do you guys think? Hey Bill want to read those comments really quick before we wrap it up here Bills going to just read a couple comments. No. From are we sure we want to hear what the public has to say? Yeah here. Come on Bill. There we go right to that camera. Okay comes first. Yeah, the good ones first. No, Jessica Polly is like Bobby's adopted dead who's trying to feed him when he's already eaten ha ha preferring the last week's a pile of bodies. I just found this literally showed my wife her first Pauly Shore movie last night. He left through the entire thing <mark>and</mark> I felt like I got to introduce her to something great that she somehow it's that's nice. Thank you. It's got there can't be all positive. That's true. Well, okay, you'll say you asked me to hear this one. Keith McDonald says if Paul was half as funny as he thinks he is he would be twice as funny as he really is about. Yeah, that's too much. How many people do math for your fucking shit? So here's the part of the podcast where we kind of like, yeah get off ourselves. Yeah because both of us have People that watch us. Yeah, you know people watch", "Start Time (s)": 2192.1, "End Time (s)": 2311.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Thank you. It's got there can't be all positive. That's true. Well, okay, you'll say you asked me to hear this one. Keith McDonald says if Paul was half as funny as he thinks he is he would be twice as funny as he really is about. Yeah, that's too much. How many people do math for your fucking shit? So here's the part of the podcast where we kind of like, yeah get off ourselves. Yeah because both of us have People that watch us. Yeah, you know people watch you people watch me. Yep, people are going through whatever they're going through <mark>and</mark> it's good for us to help people as well. So what would what helps you get through? Whatever it is that you're going through in life. Okay, you know <mark>and</mark> then also tell them to yeah up here, right? Yeah, you know, I have to tell you. It's so morbid I think about dying every day. Well, I'm very existential. I'm very dark. I like to think about death because when I remind myself I'm going to die. It allows me to live more fully right? Yeah, because then you're hung up about this <mark>and</mark> that little thing this problem <mark>and</mark> then you go. Yeah, but I'm going to be on my deathbed right? Is it even fucking matter if this doesn't go my way or whatever, you know what I'm saying? Yeah. What do you do? So you say So you basically say you're going to die. So it makes you want to live. Yeah, make sure you dies right it remind you whatever it is that you're fucked up about. It doesn't matter dude. You're going to be on a deathbed <mark>and</mark> is it really that big <mark>and</mark> the", "Start Time (s)": 2257.0, "End Time (s)": 2376.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going through <mark>and</mark> it's good for us to help people as well. So what would what helps you get through? Whatever it is that you're going through in life. Okay, you know <mark>and</mark> then also tell them to yeah up here, right? Yeah, you know, I have to tell you. It's so morbid I think about dying every day. Well, I'm very existential. I'm very dark. I like to think about death because when I remind myself I'm going to die. It allows me to live more fully right? Yeah, because then you're hung up about this <mark>and</mark> that little thing this problem <mark>and</mark> then you go. Yeah, but I'm going to be on my deathbed right? Is it even fucking matter if this doesn't go my way or whatever, you know what I'm saying? Yeah. What do you do? So you say So you basically say you're going to die. So it makes you want to live. Yeah, make sure you dies right it remind you whatever it is that you're fucked up about. It doesn't matter dude. You're going to be on a deathbed <mark>and</mark> is it really that big <mark>and</mark> the grand scheme of things that's interesting because I came up with that more after both my parents passed same. Yeah really are both your parents pass. No, no just my mom but once she died <mark>and</mark> then my stepdad died <mark>and</mark> I was like, oh, wow, this isn't forever. Exactly. That's how that's what it is guys. So what? Me <mark>and</mark> Christina Christina. Nothing are basically saying, you know every day is a gift. That's right everyday. We're lucky to wake up. You open your eyes in the morning. You're like, holy shit. That's right. I can't blow my God. I got God gave me another day. Yeah because this is a rap at some point. We're going to get thrown into a box literally people are going to cry for a week. <mark>And</mark> then maybe they'll remember your birthday once in a while or one of your Netflix specials will pop up <mark>and</mark> be like, oh the I have to Mother inferior in the Generous Jesus Christ, you fucking we're talking about death <mark>and</mark> sadness. It's like oh by the way, check out my Netflix, but that's great. I also have a podcast called one of my mom's dad if you", "Start Time (s)": 2315.4, "End Time (s)": 2435.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, make sure you dies right it remind you whatever it is that you're fucked up about. It doesn't matter dude. You're going to be on a deathbed <mark>and</mark> is it really that big <mark>and</mark> the grand scheme of things that's interesting because I came up with that more after both my parents passed same. Yeah really are both your parents pass. No, no just my mom but once she died <mark>and</mark> then my stepdad died <mark>and</mark> I was like, oh, wow, this isn't forever. Exactly. That's how that's what it is guys. So what? Me <mark>and</mark> Christina Christina. Nothing are basically saying, you know every day is a gift. That's right everyday. We're lucky to wake up. You open your eyes in the morning. You're like, holy shit. That's right. I can't blow my God. I got God gave me another day. Yeah because this is a rap at some point. We're going to get thrown into a box literally people are going to cry for a week. <mark>And</mark> then maybe they'll remember your birthday once in a while or one of your Netflix specials will pop up <mark>and</mark> be like, oh the I have to Mother inferior in the Generous Jesus Christ, you fucking we're talking about death <mark>and</mark> sadness. It's like oh by the way, check out my Netflix, but that's great. I also have a podcast called one of my mom's dad if you want to see that because I yeah <mark>and</mark> yeah, so those yeah you have anything you want to say to Tom that you have it that you haven't really said to him <mark>and</mark> how you feel about him because I'm so happy for you guys. Really? Yeah. Yeah, of course. I am. I'm happy. I'm really happy for you guys <mark>and</mark> you have To tell are you allowed to say the name your kid? Yeah Ellison Julian there <mark>and</mark> I remember your first baby. I met when I came to do your guys show Ellis. Yeah is your first one <mark>and</mark> you tell Tom what it's like to have him to have him no no come from the heart to have him in your life. What's that? Like Tom? What can I do not do feelings? You can't you better have my dinner ready? When I get home you like Roseanne <mark>and</mark> shit. That's all I want. I get me a fucking boat. Me. Yeah, I can't tell feelings probably.", "Start Time (s)": 2367.5, "End Time (s)": 2487.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "oh the I have to Mother inferior in the Generous Jesus Christ, you fucking we're talking about death <mark>and</mark> sadness. It's like oh by the way, check out my Netflix, but that's great. I also have a podcast called one of my mom's dad if you want to see that because I yeah <mark>and</mark> yeah, so those yeah you have anything you want to say to Tom that you have it that you haven't really said to him <mark>and</mark> how you feel about him because I'm so happy for you guys. Really? Yeah. Yeah, of course. I am. I'm happy. I'm really happy for you guys <mark>and</mark> you have To tell are you allowed to say the name your kid? Yeah Ellison Julian there <mark>and</mark> I remember your first baby. I met when I came to do your guys show Ellis. Yeah is your first one <mark>and</mark> you tell Tom what it's like to have him to have him no no come from the heart to have him in your life. What's that? Like Tom? What can I do not do feelings? You can't you better have my dinner ready? When I get home you like Roseanne <mark>and</mark> shit. That's all I want. I get me a fucking boat. Me. Yeah, I can't tell feelings probably. I'm not I can't can I get so embarrassed don't you? I want to know I want him to feel that. You know, I don't make me do it, please. All right, just come on. I love you. I love you. Tom. Your beard is very full. Like I really can't don't make me you say this to people say in front of when you're with him. Yeah, you do. Yeah, but I can't do it right now. I'm from old people commenting on the internet <mark>and</mark> I'm happy that you guys found each other. So am I like I said two beautiful babies. I'm happy you guys live deep in the valley. Thank you deep deep in the valley <mark>and</mark> I'm happy for you <mark>and</mark> thank you for coming. Thank you for having me. I'm really amazed <mark>and</mark> impressed with your whole operation. It's pretty astounding because he kisses amazed this what happens when you have a lot of time on your hands. Yeah. She come back on your mom's house to when you're ready. Yeah, I would love", "Start Time (s)": 2421.4, "End Time (s)": 2541.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I can't tell feelings probably. I'm not I can't can I get so embarrassed don't you? I want to know I want him to feel that. You know, I don't make me do it, please. All right, just come on. I love you. I love you. Tom. Your beard is very full. Like I really can't don't make me you say this to people say in front of when you're with him. Yeah, you do. Yeah, but I can't do it right now. I'm from old people commenting on the internet <mark>and</mark> I'm happy that you guys found each other. So am I like I said two beautiful babies. I'm happy you guys live deep in the valley. Thank you deep deep in the valley <mark>and</mark> I'm happy for you <mark>and</mark> thank you for coming. Thank you for having me. I'm really amazed <mark>and</mark> impressed with your whole operation. It's pretty astounding because he kisses amazed this what happens when you have a lot of time on your hands. Yeah. She come back on your mom's house to when you're ready. Yeah, I would love to get a plug this shows. So tell us what people can Find you <mark>and</mark> tell us about your tour dates is hearing. Yeah, April 7th. I'm in London London England. That's almost gone. Anyway, but then oh May 1st, I'm doing the Netflix is a joke Festival. I'm headlining the st. Regis to get tickets to La if your local <mark>and</mark> then all my dates for a Christina P online. Thank you for having me. Yeah, I like your bicycle. You're so fast. We'll see you guys will see you guys next week. Thank you for tuning in. Check me out on my Instagram Pauly Shore guys do Unplug your stuff sure. I'm at Ritchie. Tvri chw TWA V EE I'm a tester cuckoo. I'll be at the Miami Improv, May 21st <mark>and</mark> West Palm Beach Improv, May 28. Bill G. Did you lie on music on YouTube? Thank you. What's up guys DMB imagery on his Jim. Thanks so much later guys. We'll see you next time. Bye stay up guys live another day. Bye. Bye.", "Start Time (s)": 2485.6, "End Time (s)": 2604.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2k5u94g2BHSQFQeHkIBXtR", "show_name": "Pauly Shore's Random Rants", "show_description": "       Yo brozz! I'm ranting from my crusty Fourplex about living alone and whatever is on my mind. Comedy. Family. Music. Pop culture. Politics. Sex. Social media. Plus, meet random special guests from around LA and Silver Lake that I invite to my house. Random Rants is now a video podcast, filmed Big Brother style, so be sure to subscribe on YouTube: http://bit.ly/subPaulyShore     ", "publisher": "All Things Comedy|Wondery", "episode_uri": "spotify:episode:0PZRAzyEeJeZNgyp1dXB9s", "episode_name": "Christina Pazsitzky: Married to Tom Segura | Pauly Shore's Random Rants", "episode_description": "         Episode 125. Yo brozz, ranting from the fourplex with my friend, comedian Christina Pazsitzky (Netflix, Your Mom's House podcast, Where My Moms At podcast). We met at The Comedy Store. Now she's married to fellow comedian Tom Segura\u00a0, doodz. We talk about Silver Lake, Joe Rogan's podcast advice, relationships, acting and having a baby with Whitney Cummings, Plus, I make Christina guacamole. Bill reads YouTube comments. Subscribe on YouTube: http://bit.ly/subPaulyShore\u00a0       ", "score": 8.143026, "explanation": "{\n  \"value\": 8.143026,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.0940676,\n      \"description\": \"weight(word_list:joe in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0940676,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.6192536,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.048959,\n      \"description\": \"weight(word_list:rogan in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.048959,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.574145,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 95) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4606565,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hey guys, couple things before we go into this podcast. I really actually want you to tweet me your feedback on how you like weekly be in podcast form. So please hit me up on Twitter Gary Vee <mark>and</mark> just put hashtag garyvee podcast with the W in there as well so I can see your feedback on weekly B7. Please hit me up with some feedback on Twitter on how you like listening to the Vlog <mark>and</mark> if you're not watching the Vlog, it's youtube.com slash garyvee with double. He's then please enjoy this day Gary Vee audio experience everybody really excited about this interview so far. Everybody's watching on LinkedIn. Let's put in your phone numbers. We're going to call somebody in LinkedIn live put in your phone number <mark>and</mark> your question <mark>and</mark> then teams going to pick which ones but I have the super handsome wildly accomplished Daymond John in the buildings <mark>and</mark> I want I'm right next to milli vanilli's. Are you like that? Right? I'm excited about that. The Ring Power shift, when's this out? Watch 10th, March 10, it's February 24th of recordings. Probably out in a couple days. So do you want us to launch the you have any preference of launching? We'll figure that out after talking", "Start Time (s)": 0.8, "End Time (s)": 72.1, "Clip Length (min)": 1.19, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hit me up with some feedback on Twitter on how you like listening to the Vlog <mark>and</mark> if you're not watching the Vlog, it's youtube.com slash garyvee with double. He's then please enjoy this day Gary Vee audio experience everybody really excited about this interview so far. Everybody's watching on LinkedIn. Let's put in your phone numbers. We're going to call somebody in LinkedIn live put in your phone number <mark>and</mark> your question <mark>and</mark> then teams going to pick which ones but I have the super handsome wildly accomplished Daymond John in the buildings <mark>and</mark> I want I'm right next to milli vanilli's. Are you like that? Right? I'm excited about that. The Ring Power shift, when's this out? Watch 10th, March 10, it's February 24th of recordings. Probably out in a couple days. So do you want us to launch the you have any preference of launching? We'll figure that out after talking it out demons. Got a new book It's called Power shift. I'm excited to be with him. We've jammed a bunch. There's one point we can be very old men <mark>and</mark> look back to our films together. <mark>And</mark> yeah, that's gonna be fun obviously wildly accomplished entrepreneur star one of the stars of shark tank, but more importantly for me. Ivory I'm starting to get really like weird as I get older meaning I've gotten very focused even recent times even more around kindness <mark>and</mark> like who do I want to be around when I just genuinely I saw you very recently maybe four to seven eight ten weeks ago at a keynote that we were both. We were both speaking at an event <mark>and</mark> I saw you for a brief second because you spoken on was the Green Room. I was running up <mark>and</mark> like it's really interesting. I was on The age they're just kind of announcing me. We saw each other we adapt it up. <mark>And</mark> as I was walking on stage it was I literally was speaking to myself before I said hello to the crowd of like it's really funny when you like somebody what happens with your chemicals in your body. It happened when I just saw you not Lobby <mark>and</mark> it's happening right now. I like nice. Yeah, <mark>and</mark> so for all your", "Start Time (s)": 20.1, "End Time (s)": 140.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's called Power shift. I'm excited to be with him. We've jammed a bunch. There's one point we can be very old men <mark>and</mark> look back to our films together. <mark>And</mark> yeah, that's gonna be fun obviously wildly accomplished entrepreneur star one of the stars of shark tank, but more importantly for me. Ivory I'm starting to get really like weird as I get older meaning I've gotten very focused even recent times even more around kindness <mark>and</mark> like who do I want to be around when I just genuinely I saw you very recently maybe four to seven eight ten weeks ago at a keynote that we were both. We were both speaking at an event <mark>and</mark> I saw you for a brief second because you spoken on was the Green Room. I was running up <mark>and</mark> like it's really interesting. I was on The age they're just kind of announcing me. We saw each other we adapt it up. <mark>And</mark> as I was walking on stage it was I literally was speaking to myself before I said hello to the crowd of like it's really funny when you like somebody what happens with your chemicals in your body. It happened when I just saw you not Lobby <mark>and</mark> it's happening right now. I like nice. Yeah, <mark>and</mark> so for all your accomplishments, obviously, I don't know you all the way through <mark>and</mark> haven't been enough situations, but for me personally from what I know, I really appreciate your niceness <mark>and</mark> I think you're a nice human. That's the nice. Best thing I can say <mark>and</mark> so I'm glad you're on the show. I think the same here. I think they'll only see each other. You know, we've been we've talked about getting the family together, but you <mark>and</mark> I probably realized actually going to happen or it will it will when it's like that's don't crush it. Right <mark>and</mark> that's what's going on with you. You look good. I wanted a more on Monday because I got a question for you man, please why people so fucking stupid. There's a lot of fucking stupid people out there. Well, how do you mean it? Well, here's what happened. Well, how do you think last year's wild? Here's why I'm sending his why I'm stressed today the first day of", "Start Time (s)": 74.7, "End Time (s)": 194.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "accomplishments, obviously, I don't know you all the way through <mark>and</mark> haven't been enough situations, but for me personally from what I know, I really appreciate your niceness <mark>and</mark> I think you're a nice human. That's the nice. Best thing I can say <mark>and</mark> so I'm glad you're on the show. I think the same here. I think they'll only see each other. You know, we've been we've talked about getting the family together, but you <mark>and</mark> I probably realized actually going to happen or it will it will when it's like that's don't crush it. Right <mark>and</mark> that's what's going on with you. You look good. I wanted a more on Monday because I got a question for you man, please why people so fucking stupid. There's a lot of fucking stupid people out there. Well, how do you mean it? Well, here's what happened. Well, how do you think last year's wild? Here's why I'm sending his why I'm stressed today the first day of 51 because people still morons I put up some that. I saw a media black something something something <mark>and</mark> it broke down <mark>and</mark> said, you know, what do you realize that the inspiration for X-Men for Stanley was Malcolm X <mark>and</mark> Martin Luther King. I didn't know that Magneto was Malcolm X destroy the world fucking they don't like us <mark>and</mark> <mark>and</mark> Xavier is chill out the inspiration force. Is that true so fucking so I'm not going to jump around <mark>and</mark> just assume right I go <mark>and</mark> do my research. I find various articles History Channel what people I put in a link in my bio <mark>and</mark> I represented Stanley for the last five years before he passed as licensing his name. I called his family <mark>and</mark> That is this true. Everybody confirm that's neat. Most of the people on their said I didn't I didn't know it's true. I didn't know shoe but there was about five percent. I see I'm sorry. I'm not I'm now but I think I'm falling he posted this posted this <mark>and</mark> when you're saying <mark>and</mark> I showed me that <mark>and</mark> I said you want to go to my link check this out mean comments", "Start Time (s)": 140.0, "End Time (s)": 259.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "still morons I put up some that. I saw a media black something something something <mark>and</mark> it broke down <mark>and</mark> said, you know, what do you realize that the inspiration for X-Men for Stanley was Malcolm X <mark>and</mark> Martin Luther King. I didn't know that Magneto was Malcolm X destroy the world fucking they don't like us <mark>and</mark> <mark>and</mark> Xavier is chill out the inspiration force. Is that true so fucking so I'm not going to jump around <mark>and</mark> just assume right I go <mark>and</mark> do my research. I find various articles History Channel what people I put in a link in my bio <mark>and</mark> I represented Stanley for the last five years before he passed as licensing his name. I called his family <mark>and</mark> That is this true. Everybody confirm that's neat. Most of the people on their said I didn't I didn't know it's true. I didn't know shoe but there was about five percent. I see I'm sorry. I'm not I'm now but I think I'm falling he posted this posted this <mark>and</mark> when you're saying <mark>and</mark> I showed me that <mark>and</mark> I said you want to go to my link check this out mean comments how most common that showed pictures of him <mark>and</mark> I obviously I'm pretty competent been around some really great people half of the half of the morons. Are the five percent were it's not true 2.5% so 2.5. It's not true. Okay. These are the people that are the only get one source of information from any place in every place <mark>and</mark> they don't give us a racist statement. Like just well not be very hot. Probably, right? Yeah, baby Grayson is raised on both sides. I'll tell you why because the ones who said it wasn't true happened not to be of African-American descent. Okay, the other half happened to be of African-American descent said well then why didn't he just make them black? Yeah. All right number one if he would have made them black. This would have been called the Martin Luther King <mark>and</mark> Malcolm X Chronicles, <mark>and</mark> we've already seen that how we was going down. He got inspired. Doesn't mean the entire", "Start Time (s)": 195.5, "End Time (s)": 315.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "didn't know shoe but there was about five percent. I see I'm sorry. I'm not I'm now but I think I'm falling he posted this posted this <mark>and</mark> when you're saying <mark>and</mark> I showed me that <mark>and</mark> I said you want to go to my link check this out mean comments how most common that showed pictures of him <mark>and</mark> I obviously I'm pretty competent been around some really great people half of the half of the morons. Are the five percent were it's not true 2.5% so 2.5. It's not true. Okay. These are the people that are the only get one source of information from any place in every place <mark>and</mark> they don't give us a racist statement. Like just well not be very hot. Probably, right? Yeah, baby Grayson is raised on both sides. I'll tell you why because the ones who said it wasn't true happened not to be of African-American descent. Okay, the other half happened to be of African-American descent said well then why didn't he just make them black? Yeah. All right number one if he would have made them black. This would have been called the Martin Luther King <mark>and</mark> Malcolm X Chronicles, <mark>and</mark> we've already seen that how we was going down. He got inspired. Doesn't mean the entire context of the entire body of X-Men is Malcolm X <mark>and</mark> Martin Luther King <mark>and</mark> the other half of the ignorant ones just didn't do their homework. It's right there in front of you. All you have to do is read the link <mark>and</mark> then go <mark>and</mark> do your research. I think why why why what happened? But here's the good news if there's more morons like that than you <mark>and</mark> I <mark>and</mark> the hard-working people watching this with common sense <mark>and</mark> homework <mark>and</mark> busting their ass can survive. how can the rich interesting five you know, it's really interesting where my brain goes in this I'm I'm deeply empathy like, you know, it's funny. Like I don't know like I understand what you're saying period next sentence. It's wild to me how much that doesn't upset me. It actually like it doesn't upset me. I just humans are humans, you know, I'm grateful.", "Start Time (s)": 247.9, "End Time (s)": 367.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is Malcolm X <mark>and</mark> Martin Luther King <mark>and</mark> the other half of the ignorant ones just didn't do their homework. It's right there in front of you. All you have to do is read the link <mark>and</mark> then go <mark>and</mark> do your research. I think why why why what happened? But here's the good news if there's more morons like that than you <mark>and</mark> I <mark>and</mark> the hard-working people watching this with common sense <mark>and</mark> homework <mark>and</mark> busting their ass can survive. how can the rich interesting five you know, it's really interesting where my brain goes in this I'm I'm deeply empathy like, you know, it's funny. Like I don't know like I understand what you're saying period next sentence. It's wild to me how much that doesn't upset me. It actually like it doesn't upset me. I just humans are humans, you know, I'm grateful. More when I see stuff like that, I'm more grateful because I've been thinking a lot about like what makes somebody not like something. Yeah, <mark>and</mark> when I see anybody not liking look I think the big thing, you know, it makes me grateful that I do like I'll give you a good example. I was just thinking about this <mark>and</mark> it's perfect with you like every time you're winning as an entrepreneur, right <mark>and</mark> there's a world right now where entrepreneurs are superheroes. Yeah, right. Yeah, <mark>and</mark> let's call it. There's 500 entrepreneurs that probably have Tension at a Superhero level some people are Superman <mark>and</mark> <mark>and</mark> <mark>and</mark> Spider-Man, you know, Jeff Bezos <mark>Elon</mark> <mark>Musk</mark> other people are you know Rogue from X-Men like there's everyone sits in the spot. It's been really interesting. I'm uncomfortably competitive. Like I wildly want to win at all times. However in parallel is a contradiction, I think the world is so abundant that I really cheer for people when they get wins. I love it. Yeah, like I want to win. <mark>And</mark> like do I think I'm competing with every other entrepreneur I do at the same token. I know I'm not competing with any other entrepreneur in the world is abundant. Anyway, this is one long-winded thing to say of like if you have the energy", "Start Time (s)": 318.8, "End Time (s)": 438.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> <mark>and</mark> Spider-Man, you know, Jeff Bezos <mark>Elon</mark> <mark>Musk</mark> other people are you know Rogue from X-Men like there's everyone sits in the spot. It's been really interesting. I'm uncomfortably competitive. Like I wildly want to win at all times. However in parallel is a contradiction, I think the world is so abundant that I really cheer for people when they get wins. I love it. Yeah, like I want to win. <mark>And</mark> like do I think I'm competing with every other entrepreneur I do at the same token. I know I'm not competing with any other entrepreneur in the world is abundant. Anyway, this is one long-winded thing to say of like if you have the energy to dislike or hate or drag down or tear down buildings shit's not good in your soul true. But if you are just not even going to the point of hating. I don't think they hate it. They just made comments without doing their research. Now what's going on in their life because what they sit around listening Was a little people super successful. I don't know but if something is going on there, like why don't you look <mark>and</mark> say it's why whether it's hate it's like it's like the energy You to try to tear something else down whatever you want to call it. It's fascinating. Look. I think the greatest thing is happening right now the internet in its current state people called social media call it whatever you want the internet <mark>and</mark> its current state is exposing human beings at a level. We've never seen before absolutely <mark>and</mark> everyone thinks everything is super bad. <mark>And</mark> I think this is the beginning of the greatest era of the human race. I genuinely believe that I genuinely believe that the fact that we're now getting a better view of our Elves is going to lead to very interesting good behavior hundreds of years ago. Well, the more the more the data the more than formation is out there the more you can scrape. It was like, oh now it sucks because social media fomo all this. I'm like, we've always been insecure wolverson 99% people are insecure. Yeah or whatever. It's not you to or 79 <mark>and</mark> a stunning amount of people are insecure <mark>and</mark> when you're insecure the way to mask that is", "Start Time (s)": 403.3, "End Time (s)": 522.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "around listening Was a little people super successful. I don't know but if something is going on there, like why don't you look <mark>and</mark> say it's why whether it's hate it's like it's like the energy You to try to tear something else down whatever you want to call it. It's fascinating. Look. I think the greatest thing is happening right now the internet in its current state people called social media call it whatever you want the internet <mark>and</mark> its current state is exposing human beings at a level. We've never seen before absolutely <mark>and</mark> everyone thinks everything is super bad. <mark>And</mark> I think this is the beginning of the greatest era of the human race. I genuinely believe that I genuinely believe that the fact that we're now getting a better view of our Elves is going to lead to very interesting good behavior hundreds of years ago. Well, the more the more the data the more than formation is out there the more you can scrape. It was like, oh now it sucks because social media fomo all this. I'm like, we've always been insecure wolverson 99% people are insecure. Yeah or whatever. It's not you to or 79 <mark>and</mark> a stunning amount of people are insecure <mark>and</mark> when you're insecure the way to mask that is to buying things to disguise it <mark>and</mark> tearing down others judgment. Well, there it is. So there it is. Anyway, so that's what I'm more pumped because That makes I'm like thrilled that now I know how the X-Men was inspired which is fucking epic is so so <mark>and</mark> then he would go on <mark>and</mark> I was to do all the ones one other one. Now, this is where I need the fact Checkers. I haven't had time. I had heard it right after I posted it that when he did Black Panther, I believe they said something in the nature of like in three Series in or five <mark>and</mark> maybe we could check out while we're here. Hey, you need to have some people of other colors <mark>and</mark> white people in you know with the Black Panther think so, I believe he the next one he put in was the Black Panther beating up the cake. Okay, so that's what we have to fact-check that one. We have to fact-check first appearance was what in Fantastic Four? Let's go. Yeah, it's something", "Start Time (s)": 456.9, "End Time (s)": 576.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> when you're insecure the way to mask that is to buying things to disguise it <mark>and</mark> tearing down others judgment. Well, there it is. So there it is. Anyway, so that's what I'm more pumped because That makes I'm like thrilled that now I know how the X-Men was inspired which is fucking epic is so so <mark>and</mark> then he would go on <mark>and</mark> I was to do all the ones one other one. Now, this is where I need the fact Checkers. I haven't had time. I had heard it right after I posted it that when he did Black Panther, I believe they said something in the nature of like in three Series in or five <mark>and</mark> maybe we could check out while we're here. Hey, you need to have some people of other colors <mark>and</mark> white people in you know with the Black Panther think so, I believe he the next one he put in was the Black Panther beating up the cake. Okay, so that's what we have to fact-check that one. We have to fact-check first appearance was what in Fantastic Four? Let's go. Yeah, it's something why did you write this book? Why do I write this for you under contract <mark>and</mark> you need to bang them out? No, no, no extremely hard. I'm dyslexic <mark>and</mark> you know, so I wrote this book because it was about one week that I got as we all get out things from people all the time <mark>and</mark> they were asking me how to create change in their lives <mark>and</mark> I've seen you say it often you're not going to do anything right after I tell you this right most of them right <mark>and</mark> they will all using <mark>and</mark> masking it with. Well. Here's my A job here this <mark>and</mark> that, you know, Warren Buffett says some really amazing. You may go throughout various aspects of your life. But the only thing that you are fully in control of his yourself <mark>and</mark> I realized that people just didn't understand what they can do today to make them better put tomorrow <mark>and</mark> the next day <mark>and</mark> the next day <mark>and</mark> it was all about negotiation. I think the the thing that makes me or somebody else more successful lesson, it's all of the aspects of what we negotiated in life. First of all with ourselves second of all with the surrounding it In the families or whatever the case is third of all with our position. Listen, I was born black that's", "Start Time (s)": 519.7, "End Time (s)": 639.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, so I wrote this book because it was about one week that I got as we all get out things from people all the time <mark>and</mark> they were asking me how to create change in their lives <mark>and</mark> I've seen you say it often you're not going to do anything right after I tell you this right most of them right <mark>and</mark> they will all using <mark>and</mark> masking it with. Well. Here's my A job here this <mark>and</mark> that, you know, Warren Buffett says some really amazing. You may go throughout various aspects of your life. But the only thing that you are fully in control of his yourself <mark>and</mark> I realized that people just didn't understand what they can do today to make them better put tomorrow <mark>and</mark> the next day <mark>and</mark> the next day <mark>and</mark> it was all about negotiation. I think the the thing that makes me or somebody else more successful lesson, it's all of the aspects of what we negotiated in life. First of all with ourselves second of all with the surrounding it In the families or whatever the case is third of all with our position. Listen, I was born black that's not going to change. I'm not going to be Chinese white or yellow tomorrow that is what it is. <mark>And</mark> that's what it is. Get over it move forward use it as an asset in any place that I can whatever the case is. So people always thought that negotiation <mark>and</mark> those things that nature to create change is either you having all the power or somebody else taking the power from you or they got to give it to you <mark>and</mark> it's not that way the Deep. Unhappiness exact the second you think somebody else is in control? You're in a big trouble when someone else control your destiny you're in big trouble like about this a lot <mark>and</mark> I obviously falls into race <mark>and</mark> gender issues. But I actually think about it in parenting Dynamics so much <mark>and</mark> it happens when <mark>and</mark> this is a three part you have to build influence you have to then negotiate <mark>and</mark> you have to nurture a long relationship because this part of the relationship we just had created some kind of value. It's nothing comparison to here. Has to all be concise <mark>and</mark> I don't think people understand it. So if somebody said bombing elevator would Gary Vee I never thought I would see guy who's in Oklahoma. I never thought I'd see Gary Vee in my life. How am I going to", "Start Time (s)": 584.7, "End Time (s)": 704.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "third of all with our position. Listen, I was born black that's not going to change. I'm not going to be Chinese white or yellow tomorrow that is what it is. <mark>And</mark> that's what it is. Get over it move forward use it as an asset in any place that I can whatever the case is. So people always thought that negotiation <mark>and</mark> those things that nature to create change is either you having all the power or somebody else taking the power from you or they got to give it to you <mark>and</mark> it's not that way the Deep. Unhappiness exact the second you think somebody else is in control? You're in a big trouble when someone else control your destiny you're in big trouble like about this a lot <mark>and</mark> I obviously falls into race <mark>and</mark> gender issues. But I actually think about it in parenting Dynamics so much <mark>and</mark> it happens when <mark>and</mark> this is a three part you have to build influence you have to then negotiate <mark>and</mark> you have to nurture a long relationship because this part of the relationship we just had created some kind of value. It's nothing comparison to here. Has to all be concise <mark>and</mark> I don't think people understand it. So if somebody said bombing elevator would Gary Vee I never thought I would see guy who's in Oklahoma. I never thought I'd see Gary Vee in my life. How am I going to build influence with him? When I got 90 seconds. Listen, first of all, make sure the picture you say really quick is you know, what's in it for Gary how you've been doing really well with it <mark>and</mark> the fact that you're going to be successful with or without him <mark>and</mark> not but if you're going to have if you can offer some opportunity to them let him know your influence is when Gary <mark>and</mark> his team is gonna go back <mark>and</mark> look at the shit. You've been saying for the last 10 years on social media good bad or indifferent. They're either going to say I want this person around me or I don't want this person around me <mark>and</mark> it's not just you you're hanging out with this person right here who you would never bring to a Gary's office because he's an alcoholic or misogynist or racist Pig stop taking pictures with him posting them all over your psyche is Gary's not just looking there Gary's looking everywhere around you <mark>and</mark> people don't understand how important the influence was that they To build prior to then", "Start Time (s)": 635.4, "End Time (s)": 754.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "had created some kind of value. It's nothing comparison to here. Has to all be concise <mark>and</mark> I don't think people understand it. So if somebody said bombing elevator would Gary Vee I never thought I would see guy who's in Oklahoma. I never thought I'd see Gary Vee in my life. How am I going to build influence with him? When I got 90 seconds. Listen, first of all, make sure the picture you say really quick is you know, what's in it for Gary how you've been doing really well with it <mark>and</mark> the fact that you're going to be successful with or without him <mark>and</mark> not but if you're going to have if you can offer some opportunity to them let him know your influence is when Gary <mark>and</mark> his team is gonna go back <mark>and</mark> look at the shit. You've been saying for the last 10 years on social media good bad or indifferent. They're either going to say I want this person around me or I don't want this person around me <mark>and</mark> it's not just you you're hanging out with this person right here who you would never bring to a Gary's office because he's an alcoholic or misogynist or racist Pig stop taking pictures with him posting them all over your psyche is Gary's not just looking there Gary's looking everywhere around you <mark>and</mark> people don't understand how important the influence was that they To build prior to then negotiating <mark>and</mark> then valuing the relationship <mark>and</mark> it just simple stop simple. Stop simple when it's quiet in one's head. Right, like I've been thinking a lot about this like I wanted to ask you this. How quiet <mark>and</mark> slower things for you. I've been thinking <mark>and</mark> here's how I'm saying it like you here athletes talk about when the game slows down. Yeah, I'm manic in my schedule <mark>and</mark> Mike I'm a you know, I'm also an extrovert by nature. <mark>And</mark> so there's a lot of things that go on with my energy <mark>and</mark> I wish there was a way that I could explain to people how slow Everything feels to me. Same here good. I think that's why we see on the road so much <mark>and</mark> people ask why do we do it? Why shouldn't I do it? You know, I'm actually Like it that style of it. I'm sorry. I'm tweaking my life <mark>and</mark> I'm making sure that all right family needs to", "Start Time (s)": 688.9, "End Time (s)": 808.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "office because he's an alcoholic or misogynist or racist Pig stop taking pictures with him posting them all over your psyche is Gary's not just looking there Gary's looking everywhere around you <mark>and</mark> people don't understand how important the influence was that they To build prior to then negotiating <mark>and</mark> then valuing the relationship <mark>and</mark> it just simple stop simple. Stop simple when it's quiet in one's head. Right, like I've been thinking a lot about this like I wanted to ask you this. How quiet <mark>and</mark> slower things for you. I've been thinking <mark>and</mark> here's how I'm saying it like you here athletes talk about when the game slows down. Yeah, I'm manic in my schedule <mark>and</mark> Mike I'm a you know, I'm also an extrovert by nature. <mark>And</mark> so there's a lot of things that go on with my energy <mark>and</mark> I wish there was a way that I could explain to people how slow Everything feels to me. Same here good. I think that's why we see on the road so much <mark>and</mark> people ask why do we do it? Why shouldn't I do it? You know, I'm actually Like it that style of it. I'm sorry. I'm tweaking my life <mark>and</mark> I'm making sure that all right family needs to come out here. <mark>And</mark> you spend more time here. I need to do more of this off. I need more great people around me a lot of more Robins. So I'm Batman <mark>and</mark> they're robbing their Robin. I'm Batman half the time I need I need more because I'm not going to die. I'm not going anywhere. What am I gonna do <mark>and</mark> I'm educating myself while I'm out there. I'm expanding my network. Can you explain to the kids out here? How crazy you feel at 51 how young <mark>and</mark> Alive you feel? Like does that scare the 18 year old you could you have ever imagined being this fresh at 51 now, you know when we were that age I was thinking like 51 was you know, I always tell the short girl cousin Bobby was in my dad's liquor store when I got there. He'd been there since he was 18. He was 30 when I was 22 <mark>and</mark> got their full time. I thought he was so fucking old 30 seem like you don't wanna hang out with the youngsters that work for me. I'm like I get it like I always laugh I'm like man, I think like me", "Start Time (s)": 739.0, "End Time (s)": 858.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there was a way that I could explain to people how slow Everything feels to me. Same here good. I think that's why we see on the road so much <mark>and</mark> people ask why do we do it? Why shouldn't I do it? You know, I'm actually Like it that style of it. I'm sorry. I'm tweaking my life <mark>and</mark> I'm making sure that all right family needs to come out here. <mark>And</mark> you spend more time here. I need to do more of this off. I need more great people around me a lot of more Robins. So I'm Batman <mark>and</mark> they're robbing their Robin. I'm Batman half the time I need I need more because I'm not going to die. I'm not going anywhere. What am I gonna do <mark>and</mark> I'm educating myself while I'm out there. I'm expanding my network. Can you explain to the kids out here? How crazy you feel at 51 how young <mark>and</mark> Alive you feel? Like does that scare the 18 year old you could you have ever imagined being this fresh at 51 now, you know when we were that age I was thinking like 51 was you know, I always tell the short girl cousin Bobby was in my dad's liquor store when I got there. He'd been there since he was 18. He was 30 when I was 22 <mark>and</mark> got their full time. I thought he was so fucking old 30 seem like you don't wanna hang out with the youngsters that work for me. I'm like I get it like I always laugh I'm like man, I think like me like, I think John <mark>and</mark> Jason are the same <mark>and</mark> they think I'm fucking like Dad yeah, I'm like no no, we're homies like brothers they're like, no dad <mark>and</mark> I'm like I laugh about that because I'm 4430 seem old as fuck knowing cutting your roots. It must blow you away. I've been like 35 wait, this is a new year. So I've been in 35 cities amazing. What is there for half of them upon Golden Globes McGregor fight Oscars Super Bowl, you know, whatever the case is speaking <mark>and</mark> then hang them take my family Bahamas <mark>and</mark> then Carter. Hey Nia for a wedding. Let's go. Great speed, it's great. It's great. <mark>And</mark> yeah, it doesn't did real quick. I apologize. I'm gonna get a little more about what this is about. But I want to use most of the majority of the 20 to 30 minutes that you know to answer some questions. So look regardless of what the books about here's your chance to ask Damon a question. So putting your phone numbers on", "Start Time (s)": 789.1, "End Time (s)": 908.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yeah, I'm like no no, we're homies like brothers they're like, no dad <mark>and</mark> I'm like I laugh about that because I'm 4430 seem old as fuck knowing cutting your roots. It must blow you away. I've been like 35 wait, this is a new year. So I've been in 35 cities amazing. What is there for half of them upon Golden Globes McGregor fight Oscars Super Bowl, you know, whatever the case is speaking <mark>and</mark> then hang them take my family Bahamas <mark>and</mark> then Carter. Hey Nia for a wedding. Let's go. Great speed, it's great. It's great. <mark>And</mark> yeah, it doesn't did real quick. I apologize. I'm gonna get a little more about what this is about. But I want to use most of the majority of the 20 to 30 minutes that you know to answer some questions. So look regardless of what the books about here's your chance to ask Damon a question. So putting your phone numbers on LinkedIn. We're about to get some go in a minute, but I want Damon to listen anybody in our community if listen I'm not this person, but if you were the person that actually learns from books, if you're part of this community, I find it highly unlikely that whatever discounted price on Under Barns <mark>and</mark> Nobles over to fuck you can find us that it's not going to be worth that Roi if you know how to get information out of book form. So I highly recommend you picking it up because I know this dude doesn't put down bad product. But like Damon for the people that are like a fuck that like, I don't wanna spend 16 bucks. Like if you can go narrow <mark>and</mark> to why this book versus just following you on social or anything in that nature. Is there anything what how are you for me when I write books I'm able to go deeper now the shit that I'm putting out headlines on <mark>and</mark> go narrow <mark>and</mark> then thus I think it's worth. 18 bucks. I was think that way how do you think about this? Yeah. So so first of all, of course you can get any information from me free all the time C NBC ABC, you know on my social media platforms. Yeah, but of course, of course absolutely, but if you want to go narrow <mark>and</mark> deep on how to basically create influence <mark>and</mark> then how to negotiate <mark>and</mark> how to develop those relationships. Then this goes granular into it. I have about 10 subjects in there who have all went from industry to Industry <mark>and</mark> become Titans in various different Industries Pitbull. My bomba socks guys Kris Jenner. Billie Jean King", "Start Time (s)": 863.9, "End Time (s)": 983.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that actually learns from books, if you're part of this community, I find it highly unlikely that whatever discounted price on Under Barns <mark>and</mark> Nobles over to fuck you can find us that it's not going to be worth that Roi if you know how to get information out of book form. So I highly recommend you picking it up because I know this dude doesn't put down bad product. But like Damon for the people that are like a fuck that like, I don't wanna spend 16 bucks. Like if you can go narrow <mark>and</mark> to why this book versus just following you on social or anything in that nature. Is there anything what how are you for me when I write books I'm able to go deeper now the shit that I'm putting out headlines on <mark>and</mark> go narrow <mark>and</mark> then thus I think it's worth. 18 bucks. I was think that way how do you think about this? Yeah. So so first of all, of course you can get any information from me free all the time C NBC ABC, you know on my social media platforms. Yeah, but of course, of course absolutely, but if you want to go narrow <mark>and</mark> deep on how to basically create influence <mark>and</mark> then how to negotiate <mark>and</mark> how to develop those relationships. Then this goes granular into it. I have about 10 subjects in there who have all went from industry to Industry <mark>and</mark> become Titans in various different Industries Pitbull. My bomba socks guys Kris Jenner. Billie Jean King who changed the face of tennis so so this is not just you know, <mark>and</mark> I honest they change the face of like women women <mark>and</mark> sports, right? So this is obviously you were in my last book. I only take subjects out that I can learn from on the same path as you are in this. You know, what I'm talking to somebody about negotiation. A lot of people don't realize this is really easy because of social media people talking five different ways <mark>and</mark> they communicate in poverty in places sight sound sight sound touch taste <mark>and</mark> smell <mark>and</mark> it's very simple. If you're on social media, you can look through people's Feeds <mark>and</mark> you want to talk to them. It's like a used car salesman. Just cross them when you walk into the room. He starts to listen, or she sucks to listen to how you're communicating. All right, there's a red Corvette there as a top-down if you're about site he goes. Can you see yourself driving down the road? Look at the leaves falling <mark>and</mark> <mark>and</mark> wondered on a winding road if you're about smells like, can you smell the rich leather? You know, can you smell the air in the crisp air your about sound? Can you hear the", "Start Time (s)": 916.3, "End Time (s)": 1035.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> then how to negotiate <mark>and</mark> how to develop those relationships. Then this goes granular into it. I have about 10 subjects in there who have all went from industry to Industry <mark>and</mark> become Titans in various different Industries Pitbull. My bomba socks guys Kris Jenner. Billie Jean King who changed the face of tennis so so this is not just you know, <mark>and</mark> I honest they change the face of like women women <mark>and</mark> sports, right? So this is obviously you were in my last book. I only take subjects out that I can learn from on the same path as you are in this. You know, what I'm talking to somebody about negotiation. A lot of people don't realize this is really easy because of social media people talking five different ways <mark>and</mark> they communicate in poverty in places sight sound sight sound touch taste <mark>and</mark> smell <mark>and</mark> it's very simple. If you're on social media, you can look through people's Feeds <mark>and</mark> you want to talk to them. It's like a used car salesman. Just cross them when you walk into the room. He starts to listen, or she sucks to listen to how you're communicating. All right, there's a red Corvette there as a top-down if you're about site he goes. Can you see yourself driving down the road? Look at the leaves falling <mark>and</mark> <mark>and</mark> wondered on a winding road if you're about smells like, can you smell the rich leather? You know, can you smell the air in the crisp air your about sound? Can you hear the engine roaring? <mark>And</mark> the you see in these various ways of communication you see us do it all the time on Shark Tank has 65% of communication, as you know is body language. The only 7% is exactly what you're saying in the rest is how you set it. Right <mark>and</mark> there's various different ways to indicate <mark>and</mark> go through a negotiation. That's why when I get deals I can see when the person putting their hand in pocket putting it here over the air Robert sitting up <mark>and</mark> he closes book, you know, what's the name? Kevin O'Leary always wants to put something in between you to create the distance <mark>and</mark> there's a lot of information is book of keys on way to communicate build influence <mark>and</mark> the nurses That relationship to get way more after that. I love that. Let's get some phone numbers in who's the first person Ronnie? All right. Well Rodney, all right. Um, Yeah, that's interesting. So you think that there's a", "Start Time (s)": 967.0, "End Time (s)": 1086.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "rich leather? You know, can you smell the air in the crisp air your about sound? Can you hear the engine roaring? <mark>And</mark> the you see in these various ways of communication you see us do it all the time on Shark Tank has 65% of communication, as you know is body language. The only 7% is exactly what you're saying in the rest is how you set it. Right <mark>and</mark> there's various different ways to indicate <mark>and</mark> go through a negotiation. That's why when I get deals I can see when the person putting their hand in pocket putting it here over the air Robert sitting up <mark>and</mark> he closes book, you know, what's the name? Kevin O'Leary always wants to put something in between you to create the distance <mark>and</mark> there's a lot of information is book of keys on way to communicate build influence <mark>and</mark> the nurses That relationship to get way more after that. I love that. Let's get some phone numbers in who's the first person Ronnie? All right. Well Rodney, all right. Um, Yeah, that's interesting. So you think that there's a lot of there's a lot of magazines book that you take away two <mark>and</mark> three <mark>and</mark> four them. They just help you close one deal one Deals. Ry+ they let you get the remote control away from your wife or husband. Rodney yes, it's Gary vaynerchuk. You're on with Daymond John garyvee. How you doing? I'm David John. How you doing? Great, whatever are you from? I'm asked to become a sports agent looking forward to that by the end by the beginning of next year to be certified sports agent. What advice would you have for young guy? Like Ed internet internet field there? I got a background of", "Start Time (s)": 1030.2, "End Time (s)": 1150.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Rodney yes, it's Gary vaynerchuk. You're on with Daymond John garyvee. How you doing? I'm David John. How you doing? Great, whatever are you from? I'm asked to become a sports agent looking forward to that by the end by the beginning of next year to be certified sports agent. What advice would you have for young guy? Like Ed internet internet field there? I got a background of playing football have friends in the NFL right now, but for me starting out, you know being so close to the game. What advice would you give me, you know to become a successful sports agent. Let me give you my take <mark>and</mark> then Tim see if you can fill out some spots. So the biggest thing I've learned ages. Been in business now for four years feiner Sports the biggest thing that's really honest is that it's a lot more simple than you think like I keep watching us loose Let Me Go a different route the players that we lose to other agencies. We're offering disproportionate more impact financially <mark>and</mark> infrastructure wise strictly because that player liked a different agent more than the agent we put in front of them whether that's a j or brand Parker or Tommy or Brian? You will be blown away. My man of how much of this is strictly being liked. We ban life. You will be blown away. You're going to go into this business <mark>and</mark> be discouraged because you're gonna be like, wait the five biggest firms back to what Damon said. He's not going to change. That was black. I'm not going to change that. I started it. That way. I was not athletically inclined or educationally inclined which made everybody from the 70s <mark>and</mark> 80s feel", "Start Time (s)": 1103.3, "End Time (s)": 1221.0, "Clip Length (min)": 1.96, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you my take <mark>and</mark> then Tim see if you can fill out some spots. So the biggest thing I've learned ages. Been in business now for four years feiner Sports the biggest thing that's really honest is that it's a lot more simple than you think like I keep watching us loose Let Me Go a different route the players that we lose to other agencies. We're offering disproportionate more impact financially <mark>and</mark> infrastructure wise strictly because that player liked a different agent more than the agent we put in front of them whether that's a j or brand Parker or Tommy or Brian? You will be blown away. My man of how much of this is strictly being liked. We ban life. You will be blown away. You're going to go into this business <mark>and</mark> be discouraged because you're gonna be like, wait the five biggest firms back to what Damon said. He's not going to change. That was black. I'm not going to change that. I started it. That way. I was not athletically inclined or educationally inclined which made everybody from the 70s <mark>and</mark> 80s feel like shit. If you for the first 18 years of your life like, Like that doesn't change <mark>and</mark> I'll tell you this number when you get into the game. If you start small or a small firm, you're gonna go what every agent does which is like, woe is me, it's CA it's Roc Nation by time you get into it. We're like on our way. We have 13 guys in this draft. It's been written. We're going to be a player but the reality is I'm watching people strictly pick people unlike ability. Nothing else not what they can do like plenty people go to Rockfish because they want their selfie with Jay-Z plenty of people go to Vayner Sports because they want business. <mark>And</mark> life after football <mark>and</mark> off the field sub plenty of people go to athletes first because Moolah get is a great agent <mark>and</mark> they build a thing that like there's a lot of places where people go I am stunned <mark>and</mark> I mean stunned on how many people go with the person they liked the most like tired boy. No, so right now I'm a very likable guy. Well good news.", "Start Time (s)": 1160.5, "End Time (s)": 1280.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "years of your life like, Like that doesn't change <mark>and</mark> I'll tell you this number when you get into the game. If you start small or a small firm, you're gonna go what every agent does which is like, woe is me, it's CA it's Roc Nation by time you get into it. We're like on our way. We have 13 guys in this draft. It's been written. We're going to be a player but the reality is I'm watching people strictly pick people unlike ability. Nothing else not what they can do like plenty people go to Rockfish because they want their selfie with Jay-Z plenty of people go to Vayner Sports because they want business. <mark>And</mark> life after football <mark>and</mark> off the field sub plenty of people go to athletes first because Moolah get is a great agent <mark>and</mark> they build a thing that like there's a lot of places where people go I am stunned <mark>and</mark> I mean stunned on how many people go with the person they liked the most like tired boy. No, so right now I'm a very likable guy. Well good news. Good news. Good news is so real quick <mark>and</mark> I'll let you jump in Jimmy Damon good news, you're gonna talk yourself out of all the things you're going to talk about all these other things that you need to do all we need to get marketing, right? We need to be social media right? I got to get some of my homies. I played with football cosine. You're gonna think about a million other things that you're going to learn matter <mark>and</mark> I'm telling you. If the fucking percent of it is do human beings like you <mark>and</mark> if you actually leaned into that mentally you're gonna get real happy because you're gonna realize that you don't have to work on all these things that you think you have to work on. Damn it. Yeah. I mean, I think it's about the same thing. I mean, you gotta go narrow <mark>and</mark> deep when your targets that you want <mark>and</mark> like he was saying you're gonna you're gonna go everywhere but I think also the co-signing of the people that you already know that really do like it you could tell us your like what what what everybody's going to be on their first date telling you, you know, your baby's beautiful right or they're beautiful. You got to dig deep into your into your dad database <mark>and</mark> go after one two key players that like you <mark>and</mark> that you like <mark>and</mark> then you can bring value to <mark>and</mark> just keep", "Start Time (s)": 1223.2, "End Time (s)": 1342.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "guy. Well good news. Good news. Good news is so real quick <mark>and</mark> I'll let you jump in Jimmy Damon good news, you're gonna talk yourself out of all the things you're going to talk about all these other things that you need to do all we need to get marketing, right? We need to be social media right? I got to get some of my homies. I played with football cosine. You're gonna think about a million other things that you're going to learn matter <mark>and</mark> I'm telling you. If the fucking percent of it is do human beings like you <mark>and</mark> if you actually leaned into that mentally you're gonna get real happy because you're gonna realize that you don't have to work on all these things that you think you have to work on. Damn it. Yeah. I mean, I think it's about the same thing. I mean, you gotta go narrow <mark>and</mark> deep when your targets that you want <mark>and</mark> like he was saying you're gonna you're gonna go everywhere but I think also the co-signing of the people that you already know that really do like it you could tell us your like what what what everybody's going to be on their first date telling you, you know, your baby's beautiful right or they're beautiful. You got to dig deep into your into your dad database <mark>and</mark> go after one two key players that like you <mark>and</mark> that you like <mark>and</mark> then you can bring value to <mark>and</mark> just keep having these other people also co-signing. Like you said you're going to try to get all the people just get one or two people that really really mess with you to dig deep <mark>and</mark> you gotta of course be out there doing your homework <mark>and</mark> be ready to pound the phone. So those cats <mark>and</mark> let them see that you're ready to just put in the hours, you know, I'll give you two more insights because I really want you to win one everybody matters. I went through this whole thing of like the parents matter the parents don't matter that, you know, the uncle matters Uncle doesn't matter the trainer matters. The trainer doesn't matter the coach matters that here's the rule every fucking person matters because they're influencing. These are young kids <mark>and</mark> then finally complete <mark>and</mark> utter Detachment. You're gonna get your heart broke some kids going to tell you you're his guy all the way through all the way through all the way through <mark>and</mark> then it's going to come to Signing Day <mark>and</mark> they're going to call you <mark>and</mark> be like, yeah, I'm going with this other firm. I'm Sorry, see you I've heard those stories already.", "Start Time (s)": 1276.4, "End Time (s)": 1395.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "their first date telling you, you know, your baby's beautiful right or they're beautiful. You got to dig deep into your into your dad database <mark>and</mark> go after one two key players that like you <mark>and</mark> that you like <mark>and</mark> then you can bring value to <mark>and</mark> just keep having these other people also co-signing. Like you said you're going to try to get all the people just get one or two people that really really mess with you to dig deep <mark>and</mark> you gotta of course be out there doing your homework <mark>and</mark> be ready to pound the phone. So those cats <mark>and</mark> let them see that you're ready to just put in the hours, you know, I'll give you two more insights because I really want you to win one everybody matters. I went through this whole thing of like the parents matter the parents don't matter that, you know, the uncle matters Uncle doesn't matter the trainer matters. The trainer doesn't matter the coach matters that here's the rule every fucking person matters because they're influencing. These are young kids <mark>and</mark> then finally complete <mark>and</mark> utter Detachment. You're gonna get your heart broke some kids going to tell you you're his guy all the way through all the way through all the way through <mark>and</mark> then it's going to come to Signing Day <mark>and</mark> they're going to call you <mark>and</mark> be like, yeah, I'm going with this other firm. I'm Sorry, see you I've heard those stories already. We say Seafood go in the future. Yeah, you can go to fool.com <mark>and</mark> get that. Yeah, it can make a comeback at all depends on how much energy that I want to put into it <mark>and</mark> I have all the partners that have been putting energy into it, but it absolutely could make a comeback. It won't be on the same platforms before Justin retail. It probably should be a subscription service or one of those things <mark>and</mark> absolute these a lot of content out there. That was a lot of history. It's a global brand but we need to get our ducks in order to thanks for the question.", "Start Time (s)": 1328.4, "End Time (s)": 1447.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You're gonna get your heart broke some kids going to tell you you're his guy all the way through all the way through all the way through <mark>and</mark> then it's going to come to Signing Day <mark>and</mark> they're going to call you <mark>and</mark> be like, yeah, I'm going with this other firm. I'm Sorry, see you I've heard those stories already. We say Seafood go in the future. Yeah, you can go to fool.com <mark>and</mark> get that. Yeah, it can make a comeback at all depends on how much energy that I want to put into it <mark>and</mark> I have all the partners that have been putting energy into it, but it absolutely could make a comeback. It won't be on the same platforms before Justin retail. It probably should be a subscription service or one of those things <mark>and</mark> absolute these a lot of content out there. That was a lot of history. It's a global brand but we need to get our ducks in order to thanks for the question. Yeah. I mean what am I conic brand it is <mark>and</mark> I'm with you on that. All right, let's go. Yeah, man, I'm shocked how much these kids are smarter than ever but yet, there's one kid who's like logically talk me through while why we were disproportionately right for him. <mark>And</mark> then he said but I'm going another guy because it was love at first sight. Who's this? Sorry. Kesari was good. So yeah, so my question is, you know, it's pretty simple but it's pretty complex conjugate as well. So right now, you know, I live in Brooklyn I live with my with my mom <mark>and</mark> my sister <mark>and</mark> my twin brother three of us live in one one single room, you know, so", "Start Time (s)": 1380.5, "End Time (s)": 1499.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be on the same platforms before Justin retail. It probably should be a subscription service or one of those things <mark>and</mark> absolute these a lot of content out there. That was a lot of history. It's a global brand but we need to get our ducks in order to thanks for the question. Yeah. I mean what am I conic brand it is <mark>and</mark> I'm with you on that. All right, let's go. Yeah, man, I'm shocked how much these kids are smarter than ever but yet, there's one kid who's like logically talk me through while why we were disproportionately right for him. <mark>And</mark> then he said but I'm going another guy because it was love at first sight. Who's this? Sorry. Kesari was good. So yeah, so my question is, you know, it's pretty simple but it's pretty complex conjugate as well. So right now, you know, I live in Brooklyn I live with my with my mom <mark>and</mark> my sister <mark>and</mark> my twin brother three of us live in one one single room, you know, so it's pretty challenging. No, I'm old. Are you I'm 22 keep going. I'm 22. I just graduated school. So I'm trying to figure out life right now. So I know I'm a hundred percent know what that I want to go into real estate investing. That's that's really where I seem like my business why you know going into it by simply because I feel like I hit the makes a lot of people <mark>and</mark> also on the flip side not having like a home like where I could really just kind of be myself <mark>and</mark> you know kind of expand that's really also something that I just kind of, you know, I want the on be able to give other people that that opportunity in order to, you know, have a nice place to live. So right now I feel like the biggest struggles for me has been just pretty much Energy, like that's in like an in the house in the way. So just trying to figure out you know, what is it that I could do just to kind of be at my best self because back in school, you know, I was I was crushing their left <mark>and</mark> right, you know,", "Start Time (s)": 1434.6, "End Time (s)": 1554.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "my mom <mark>and</mark> my sister <mark>and</mark> my twin brother three of us live in one one single room, you know, so it's pretty challenging. No, I'm old. Are you I'm 22 keep going. I'm 22. I just graduated school. So I'm trying to figure out life right now. So I know I'm a hundred percent know what that I want to go into real estate investing. That's that's really where I seem like my business why you know going into it by simply because I feel like I hit the makes a lot of people <mark>and</mark> also on the flip side not having like a home like where I could really just kind of be myself <mark>and</mark> you know kind of expand that's really also something that I just kind of, you know, I want the on be able to give other people that that opportunity in order to, you know, have a nice place to live. So right now I feel like the biggest struggles for me has been just pretty much Energy, like that's in like an in the house in the way. So just trying to figure out you know, what is it that I could do just to kind of be at my best self because back in school, you know, I was I was crushing their left <mark>and</mark> right, you know, I was pretty much manifesting everything that I wanted to <mark>and</mark> now I feel like it's hard for me to take action why I'm so that's I just feel like it's the negative influences of like my parents <mark>and</mark> <mark>and</mark> stuff like that. Why are you still home? Is it that you're taking care of your parents or they disabled or anything like that? Welcome 22 my well. So the reason why is New York's let expensive stuff trying to save a little money. Yep, just the kind of, you know, stay at stay at home for as long as I could but right now like I was I'm going to be eating I was actually yeah, I'm sorry, please finish. Yeah. No, I was actually debating know whether or not like I should go ahead <mark>and</mark> rent out an apartment. Like I know Ru I mean, it's really interesting. I almost feels like you're having a logical <mark>and</mark> an emotional conversation with yourself, which I think we all do I love that you're thinking about Saving <mark>and</mark> you have the humility at 22 to be in your home, which I love. Are you also in a place? Where are your are your parents negative by Nature?", "Start Time (s)": 1494.0, "End Time (s)": 1613.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in like an in the house in the way. So just trying to figure out you know, what is it that I could do just to kind of be at my best self because back in school, you know, I was I was crushing their left <mark>and</mark> right, you know, I was pretty much manifesting everything that I wanted to <mark>and</mark> now I feel like it's hard for me to take action why I'm so that's I just feel like it's the negative influences of like my parents <mark>and</mark> <mark>and</mark> stuff like that. Why are you still home? Is it that you're taking care of your parents or they disabled or anything like that? Welcome 22 my well. So the reason why is New York's let expensive stuff trying to save a little money. Yep, just the kind of, you know, stay at stay at home for as long as I could but right now like I was I'm going to be eating I was actually yeah, I'm sorry, please finish. Yeah. No, I was actually debating know whether or not like I should go ahead <mark>and</mark> rent out an apartment. Like I know Ru I mean, it's really interesting. I almost feels like you're having a logical <mark>and</mark> an emotional conversation with yourself, which I think we all do I love that you're thinking about Saving <mark>and</mark> you have the humility at 22 to be in your home, which I love. Are you also in a place? Where are your are your parents negative by Nature? Like is that like fucking you up? Yeah. So look, that's really what it's really worth spending on my mom <mark>and</mark> my dad separated when I was super young. So my mom has been she put four kids through college by herself, you know, he's to make less than $20,000 a year. So super challenging for her just to kind of balance everything. So that's kind of where that negative mindset comes from. Um <mark>and</mark> are you who are you? Who are you helping her? Yeah, or you say saving because that's she's an amazing. Oh gee mom, but she just happens to have you know through all that adversity some negative Vibes that are potentially fucking you up, right? I'll be honest you I'm not helping her as well. She's really proud. I'm about to save my money <mark>and</mark> kind of just go after it in the way. But if you did you did you happen to see the post I put over the weekend about this concept of like Build your", "Start Time (s)": 1544.9, "End Time (s)": 1664.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mean, it's really interesting. I almost feels like you're having a logical <mark>and</mark> an emotional conversation with yourself, which I think we all do I love that you're thinking about Saving <mark>and</mark> you have the humility at 22 to be in your home, which I love. Are you also in a place? Where are your are your parents negative by Nature? Like is that like fucking you up? Yeah. So look, that's really what it's really worth spending on my mom <mark>and</mark> my dad separated when I was super young. So my mom has been she put four kids through college by herself, you know, he's to make less than $20,000 a year. So super challenging for her just to kind of balance everything. So that's kind of where that negative mindset comes from. Um <mark>and</mark> are you who are you? Who are you helping her? Yeah, or you say saving because that's she's an amazing. Oh gee mom, but she just happens to have you know through all that adversity some negative Vibes that are potentially fucking you up, right? I'll be honest you I'm not helping her as well. She's really proud. I'm about to save my money <mark>and</mark> kind of just go after it in the way. But if you did you did you happen to see the post I put over the weekend about this concept of like Build your crew find out they're hungry people <mark>and</mark> live an hour <mark>and</mark> a half outside the city <mark>and</mark> like did that did when you when you saw that what did you think? No, honestly, I thought about doing that. The only thing you know, I do have a lot of loser friends like they're also going out partying. I'm 22, so that's what I that's what most kids there are doing my age, but I've noticed like hey, like what I posted when I posted the second post where I said take over my account everybody <mark>and</mark> find your people <mark>and</mark> the hundreds of People that posted in there. They're from New York. Did it cross your mind to DM like all of them be like yo, do you want to do you want to room up or was it what made you not think that podcast? What's good? Do you eat food? That is a very simple question I have for you. Do you food now if that", "Start Time (s)": 1596.3, "End Time (s)": 1715.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "No, honestly, I thought about doing that. The only thing you know, I do have a lot of loser friends like they're also going out partying. I'm 22, so that's what I that's what most kids there are doing my age, but I've noticed like hey, like what I posted when I posted the second post where I said take over my account everybody <mark>and</mark> find your people <mark>and</mark> the hundreds of People that posted in there. They're from New York. Did it cross your mind to DM like all of them be like yo, do you want to do you want to room up or was it what made you not think that podcast? What's good? Do you eat food? That is a very simple question I have for you. Do you food now if that food happens to be Gourmet stuff, like delicious olive oils or cookies or that kind of random shit. Then you need to go to Yummy text. Cam yummy why you mmy tex.com Gourmet Foods that ridiculous discounts just like wine text but for olive oils pastas hot sauces mustards <mark>and</mark> other exotic candies <mark>and</mark> such yummy tex.com the best place to buy gourmet food at ridiculously low prices. So I thought about it a hundred percent for me. Like I'm very cautious as to like who I interact with not now where it's not who I interact with but who I live within the Expect that because I feel like you know it for me it's just all about like having like the right energy <mark>and</mark> I guess that's kind of like limiting myself <mark>and</mark> my but aren't sure wait aren't you in that scenario saying no before you even met the fucking person? Yeah, because all you're saying is your family has negative energy in your friends a loser. So you have no other option. You can only go up by moving in with a bunch of guys or girls. I mean, you know people come over here from other countries <mark>and</mark> they ain't got time to play they're coming over here <mark>and</mark> they're living in something for $50 a week or <mark>and</mark> they're busting their ass <mark>and</mark> this full buildings of them in New York of dancer. Sirs <mark>and</mark> talented people <mark>and</mark> tech people. Why aren't you giving that a shot just for a month at least? You know, like where are you find you're not you're not working is going to be with the way the answers came out is", "Start Time (s)": 1675.9, "End Time (s)": 1794.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "why you mmy tex.com Gourmet Foods that ridiculous discounts just like wine text but for olive oils pastas hot sauces mustards <mark>and</mark> other exotic candies <mark>and</mark> such yummy tex.com the best place to buy gourmet food at ridiculously low prices. So I thought about it a hundred percent for me. Like I'm very cautious as to like who I interact with not now where it's not who I interact with but who I live within the Expect that because I feel like you know it for me it's just all about like having like the right energy <mark>and</mark> I guess that's kind of like limiting myself <mark>and</mark> my but aren't sure wait aren't you in that scenario saying no before you even met the fucking person? Yeah, because all you're saying is your family has negative energy in your friends a loser. So you have no other option. You can only go up by moving in with a bunch of guys or girls. I mean, you know people come over here from other countries <mark>and</mark> they ain't got time to play they're coming over here <mark>and</mark> they're living in something for $50 a week or <mark>and</mark> they're busting their ass <mark>and</mark> this full buildings of them in New York of dancer. Sirs <mark>and</mark> talented people <mark>and</mark> tech people. Why aren't you giving that a shot just for a month at least? You know, like where are you find you're not you're not working is going to be with the way the answers came out is Mike. The thing that I spent a lot of time thinking about is why are people saying no before they've tried <mark>and</mark> <mark>and</mark> the reason they're saying no, is there either not interested in actually putting in the work or they're insecure <mark>and</mark> they are fear-based which is okay. There's nothing wrong with that. I'm just trying to really like bring value on this. Call right, <mark>and</mark> I'm trying to really break down. Like are you also negative by Nature, you know, which is which is also fine. Like I really mean that like I'm trying to get like I want judgment out the fucking window. I want like assessment <mark>and</mark> action right? Like I'm not judging listen me being positive <mark>and</mark> optimistic is literally completely predicated on the fact that my parents had sex at that exact moment <mark>and</mark> gave me that DNA. Its I have no pride <mark>and</mark> that I'm optimistic that was fucking chance City USA. So as a matter of fact that that leads To gratitude", "Start Time (s)": 1725.3, "End Time (s)": 1845.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> they ain't got time to play they're coming over here <mark>and</mark> they're living in something for $50 a week or <mark>and</mark> they're busting their ass <mark>and</mark> this full buildings of them in New York of dancer. Sirs <mark>and</mark> talented people <mark>and</mark> tech people. Why aren't you giving that a shot just for a month at least? You know, like where are you find you're not you're not working is going to be with the way the answers came out is Mike. The thing that I spent a lot of time thinking about is why are people saying no before they've tried <mark>and</mark> <mark>and</mark> the reason they're saying no, is there either not interested in actually putting in the work or they're insecure <mark>and</mark> they are fear-based which is okay. There's nothing wrong with that. I'm just trying to really like bring value on this. Call right, <mark>and</mark> I'm trying to really break down. Like are you also negative by Nature, you know, which is which is also fine. Like I really mean that like I'm trying to get like I want judgment out the fucking window. I want like assessment <mark>and</mark> action right? Like I'm not judging listen me being positive <mark>and</mark> optimistic is literally completely predicated on the fact that my parents had sex at that exact moment <mark>and</mark> gave me that DNA. Its I have no pride <mark>and</mark> that I'm optimistic that was fucking chance City USA. So as a matter of fact that that leads To gratitude <mark>and</mark> guilt <mark>and</mark> deep humility <mark>and</mark> compassion for others because guess what my sister is not that <mark>and</mark> I've watched her like I have more I respect my sister more than me. The thing those things came natural to me. Like I respect the fact that I got into shape more than I have all these talents because I actually feel like I worked for that. This was gifted you just like you say no for the other party, by the way, I fully agree with you. I do not think that you should live with people that Don't jive with you fucking decided that every person that left a comment in my post was negative energy. You said no before you said, yes, right, right. Yeah, so I did a reverse I did the reverse when I am when I first saw the pool with fortunate to have a house. I went to work to Red Lobster for anywhere about 50 hours a week <mark>and</mark> I would then come home work on FUBU for", "Start Time (s)": 1775.3, "End Time (s)": 1895.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on the fact that my parents had sex at that exact moment <mark>and</mark> gave me that DNA. Its I have no pride <mark>and</mark> that I'm optimistic that was fucking chance City USA. So as a matter of fact that that leads To gratitude <mark>and</mark> guilt <mark>and</mark> deep humility <mark>and</mark> compassion for others because guess what my sister is not that <mark>and</mark> I've watched her like I have more I respect my sister more than me. The thing those things came natural to me. Like I respect the fact that I got into shape more than I have all these talents because I actually feel like I worked for that. This was gifted you just like you say no for the other party, by the way, I fully agree with you. I do not think that you should live with people that Don't jive with you fucking decided that every person that left a comment in my post was negative energy. You said no before you said, yes, right, right. Yeah, so I did a reverse I did the reverse when I am when I first saw the pool with fortunate to have a house. I went to work to Red Lobster for anywhere about 50 hours a week <mark>and</mark> I would then come home work on FUBU for 30 hours a week. I was sleep three nights three hours a night. I have sewing machines in my living room <mark>and</mark> I slept next to Sonja she's <mark>and</mark> I rented out my bedroom <mark>and</mark> all the bedrooms in my house for $25 a piece because I wanted those pizzas strangers to pay the mortgage <mark>and</mark> they help pay the mortgage. I was getting money over Red Lobster for my day job <mark>and</mark> that helped me do food before five years. I would have to do two million dollars in sales <mark>and</mark> food would make the same amount of money. I walked away with <mark>and</mark> I wouldn't have done that <mark>and</mark> I wouldn't have had boob. I just have to make another sacrifice <mark>and</mark> some people pay some people didn't know got robbed in my hallway. My bathroom wall way one day it is what it is. But you know, I kick people out <mark>and</mark> that's Nana me, you know, you just have to you have to act. Okay, can I shoot question? Yeah, absolutely. How much entitlement or not entitlement do you think you have like from a self-assessment because I think a lot I think a lot about this. It's a really difficult question to ask somebody like hey how entitled are you? Nobody wants to be like all super fucking entitled but on the flip", "Start Time (s)": 1833.0, "End Time (s)": 1952.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because I wanted those pizzas strangers to pay the mortgage <mark>and</mark> they help pay the mortgage. I was getting money over Red Lobster for my day job <mark>and</mark> that helped me do food before five years. I would have to do two million dollars in sales <mark>and</mark> food would make the same amount of money. I walked away with <mark>and</mark> I wouldn't have done that <mark>and</mark> I wouldn't have had boob. I just have to make another sacrifice <mark>and</mark> some people pay some people didn't know got robbed in my hallway. My bathroom wall way one day it is what it is. But you know, I kick people out <mark>and</mark> that's Nana me, you know, you just have to you have to act. Okay, can I shoot question? Yeah, absolutely. How much entitlement or not entitlement do you think you have like from a self-assessment because I think a lot I think a lot about this. It's a really difficult question to ask somebody like hey how entitled are you? Nobody wants to be like all super fucking entitled but on the flip side, I do think entitlement in humility is an interesting framework for all of us to go through because if you're lucky enough on it then an order to figure it out. It can be really good. Right, so I'll be honest with you <mark>and</mark> you know, I grew up my whole life, you know, pretty much having nothing like literally there were days where I wouldn't even eat it. Why don't we have the meals that I had in school <mark>and</mark> I'll come home <mark>and</mark> wait those kind of you know, 8 hours 10 hours <mark>and</mark> go to breakfast run over <mark>and</mark> then just kind of go from there. So that may be super humble, you know, just being a very grateful <mark>and</mark> appreciative of what I do have it's great because you know, but back in school back in college people always always saw me as like the positive person. They don't like I was never negative or anything like that. Being home, I'll be honest with you has made me slightly more negative. Now in the sense that you know, it's that energy just kind of like rubs off on me. So right now so in terms of kind of my entitlement, I feel like I've gotten slightly a little more titles in the sense that like, hey, like why can't I just have like a regular place to live in the way which is kind of weird just negative energy comes from but but you can't but you can write like like I guess my question is like have you got caught up in like New York's expensive? <mark>And</mark> I have no options,", "Start Time (s)": 1906.7, "End Time (s)": 2025.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Right, so I'll be honest with you <mark>and</mark> you know, I grew up my whole life, you know, pretty much having nothing like literally there were days where I wouldn't even eat it. Why don't we have the meals that I had in school <mark>and</mark> I'll come home <mark>and</mark> wait those kind of you know, 8 hours 10 hours <mark>and</mark> go to breakfast run over <mark>and</mark> then just kind of go from there. So that may be super humble, you know, just being a very grateful <mark>and</mark> appreciative of what I do have it's great because you know, but back in school back in college people always always saw me as like the positive person. They don't like I was never negative or anything like that. Being home, I'll be honest with you has made me slightly more negative. Now in the sense that you know, it's that energy just kind of like rubs off on me. So right now so in terms of kind of my entitlement, I feel like I've gotten slightly a little more titles in the sense that like, hey, like why can't I just have like a regular place to live in the way which is kind of weird just negative energy comes from but but you can't but you can write like like I guess my question is like have you got caught up in like New York's expensive? <mark>And</mark> I have no options, right? Exactly. <mark>And</mark> you know, I'm sorry. I got a little distracted. Do you have a job I do. Okay so fucking commute longer. Bro, commute further like who the fuck said you had to live in Williamsburg Bushwick or Manhattan? Yeah, like what like right there's people have been her media that commute two <mark>and</mark> a half hours to be here. I don't know like like this is where I'm going. It's an infant <mark>and</mark> I'm coming from Love <mark>and</mark> I hope you can feel it. Like no. No, I was hooked back there <mark>and</mark> I feel like you can pick it up to I'm excited about this. Like I'm trying to like on some real option shit. Like why not move as far as fuck <mark>and</mark> come you two hours every morning. So Gary I was going to ask you actually so I really want to I plan on it, you know investing in New Jersey like Union County <mark>and</mark> stuff like that. Okay, so should I just move over there <mark>and</mark> just be like fuck it like just go through it <mark>and</mark> then just figure it out later see this I can say this based on what I'm", "Start Time (s)": 1964.9, "End Time (s)": 2084.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but but you can't but you can write like like I guess my question is like have you got caught up in like New York's expensive? <mark>And</mark> I have no options, right? Exactly. <mark>And</mark> you know, I'm sorry. I got a little distracted. Do you have a job I do. Okay so fucking commute longer. Bro, commute further like who the fuck said you had to live in Williamsburg Bushwick or Manhattan? Yeah, like what like right there's people have been her media that commute two <mark>and</mark> a half hours to be here. I don't know like like this is where I'm going. It's an infant <mark>and</mark> I'm coming from Love <mark>and</mark> I hope you can feel it. Like no. No, I was hooked back there <mark>and</mark> I feel like you can pick it up to I'm excited about this. Like I'm trying to like on some real option shit. Like why not move as far as fuck <mark>and</mark> come you two hours every morning. So Gary I was going to ask you actually so I really want to I plan on it, you know investing in New Jersey like Union County <mark>and</mark> stuff like that. Okay, so should I just move over there <mark>and</mark> just be like fuck it like just go through it <mark>and</mark> then just figure it out later see this I can say this based on what I'm hearing. <mark>And</mark> this is a hot take off of fucking 9 minutes <mark>and</mark> 40 seconds. I think that you should definitely get out of the house. Okay, <mark>and</mark> so for me whether it's Union, New Jersey, which are arbitrarily picking like dude, I it sounds like you're very far away from real estate investing. No. I mean, so my whole plan was, you know to work with other other investors have been in the game for quite some time. Okay, some deals in kind of have them pay me in that app. So we got to learning I get for I get like, you know stuff like that. Yeah. I just think there's a huge opportunity for you to live further away where you can afford it <mark>and</mark> you're good. I think people Pick convenience <mark>and</mark> like to me like an extra hour commute for that mental happiness is like a monster win for you. You were the fucking man at All because you had freedom. I'm just like cool. We won this game move", "Start Time (s)": 2017.0, "End Time (s)": 2136.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "option shit. Like why not move as far as fuck <mark>and</mark> come you two hours every morning. So Gary I was going to ask you actually so I really want to I plan on it, you know investing in New Jersey like Union County <mark>and</mark> stuff like that. Okay, so should I just move over there <mark>and</mark> just be like fuck it like just go through it <mark>and</mark> then just figure it out later see this I can say this based on what I'm hearing. <mark>And</mark> this is a hot take off of fucking 9 minutes <mark>and</mark> 40 seconds. I think that you should definitely get out of the house. Okay, <mark>and</mark> so for me whether it's Union, New Jersey, which are arbitrarily picking like dude, I it sounds like you're very far away from real estate investing. No. I mean, so my whole plan was, you know to work with other other investors have been in the game for quite some time. Okay, some deals in kind of have them pay me in that app. So we got to learning I get for I get like, you know stuff like that. Yeah. I just think there's a huge opportunity for you to live further away where you can afford it <mark>and</mark> you're good. I think people Pick convenience <mark>and</mark> like to me like an extra hour commute for that mental happiness is like a monster win for you. You were the fucking man at All because you had freedom. I'm just like cool. We won this game move it our further away get a little less sleep or a little less convenience on that hour commute the extra hour on the train you get a lot of shit done <mark>and</mark> you to be happy as fuck. Yeah, like I got you. Look I think that's what I'm doing is a case that makes sense to you right because that's why I asked about entitlement like yes. I know you want to save <mark>and</mark> I love you for that. I fucking love you for that. You've also assessed that the environments negative. So I'm like wait a minute. You could win both here. You can really drive down your rent. If you're just willing to live an hour <mark>and</mark> a half from the city. This is New York City the most expensive place if you go an hour <mark>and</mark> a half commute outside of here shit gets cheaper. We don't necessarily know the moms negative. Mom busted. I asked to put four kids through college <mark>and</mark> maybe she's telling him some of the things that means maybe she told me some of the shit. They", "Start Time (s)": 2066.3, "End Time (s)": 2186.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> you're good. I think people Pick convenience <mark>and</mark> like to me like an extra hour commute for that mental happiness is like a monster win for you. You were the fucking man at All because you had freedom. I'm just like cool. We won this game move it our further away get a little less sleep or a little less convenience on that hour commute the extra hour on the train you get a lot of shit done <mark>and</mark> you to be happy as fuck. Yeah, like I got you. Look I think that's what I'm doing is a case that makes sense to you right because that's why I asked about entitlement like yes. I know you want to save <mark>and</mark> I love you for that. I fucking love you for that. You've also assessed that the environments negative. So I'm like wait a minute. You could win both here. You can really drive down your rent. If you're just willing to live an hour <mark>and</mark> a half from the city. This is New York City the most expensive place if you go an hour <mark>and</mark> a half commute outside of here shit gets cheaper. We don't necessarily know the moms negative. Mom busted. I asked to put four kids through college <mark>and</mark> maybe she's telling him some of the things that means maybe she told me some of the shit. They may be selling something shitty don't want to hear either but you know, you never know right but either way he got to go out <mark>and</mark> do it on his own whether she's right or friends, right? He just needs to eliminate another excuse right to the point. She might by the way say, okay, I think you might know this she might be right. It's actually relevant that you're on it. They mean like she's a G4 single mom put for fucking people through school. She's a fucking Gangster let there be no confusion her execution <mark>and</mark> doesn't want anything now. Are you kidding me fucking gangster now? No. I know. It's a small space. It's a small space. All I want you to do is eliminate the excuse of your mom. Right. I'm telling you this not because I'm shitting on her. I'm actually shitting on the situation <mark>and</mark> I'm hopeful that if you move an hour <mark>and</mark> a half out, this is notice what I asked you how entitled are you like <mark>and</mark> I have no problem moving it hour <mark>and</mark> a half hour. Like I don't give a fuck like out of my eating", "Start Time (s)": 2122.7, "End Time (s)": 2242.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We don't necessarily know the moms negative. Mom busted. I asked to put four kids through college <mark>and</mark> maybe she's telling him some of the things that means maybe she told me some of the shit. They may be selling something shitty don't want to hear either but you know, you never know right but either way he got to go out <mark>and</mark> do it on his own whether she's right or friends, right? He just needs to eliminate another excuse right to the point. She might by the way say, okay, I think you might know this she might be right. It's actually relevant that you're on it. They mean like she's a G4 single mom put for fucking people through school. She's a fucking Gangster let there be no confusion her execution <mark>and</mark> doesn't want anything now. Are you kidding me fucking gangster now? No. I know. It's a small space. It's a small space. All I want you to do is eliminate the excuse of your mom. Right. I'm telling you this not because I'm shitting on her. I'm actually shitting on the situation <mark>and</mark> I'm hopeful that if you move an hour <mark>and</mark> a half out, this is notice what I asked you how entitled are you like <mark>and</mark> I have no problem moving it hour <mark>and</mark> a half hour. Like I don't give a fuck like out of my eating shit, you know for the next 5 10 15 years of my life just to kind of amazing where I want to be so good news move out <mark>and</mark> make it inconvenient gosh, <mark>and</mark> now what about in terms of like saving money or should I just bout just budget? That case. Yeah that figures like like like if you're truly trying to save money <mark>and</mark> now you've taken on a five hundred or thousand dollars more of expenses all of a sudden every nice little thing you like has to be looked at. Yeah. I mean as Ivory I don't I don't buy clothes that I don't go. Wow <mark>and</mark> the way they got I just buy books <mark>and</mark> <mark>and</mark> they'd read <mark>and</mark> good man. Kind of, you know, don't buy books The Internet's free as fuck. Like I'm being serious like every but like pirate <mark>and</mark> pirate back like pirate that shit go Google fucking pow. Go look at Power shift <mark>and</mark> crush it on fucking Pirate Bay or if that's still around. It's not enough. It's not a fucking steal steal that shit. That's not a", "Start Time (s)": 2178.6, "End Time (s)": 2297.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that if you move an hour <mark>and</mark> a half out, this is notice what I asked you how entitled are you like <mark>and</mark> I have no problem moving it hour <mark>and</mark> a half hour. Like I don't give a fuck like out of my eating shit, you know for the next 5 10 15 years of my life just to kind of amazing where I want to be so good news move out <mark>and</mark> make it inconvenient gosh, <mark>and</mark> now what about in terms of like saving money or should I just bout just budget? That case. Yeah that figures like like like if you're truly trying to save money <mark>and</mark> now you've taken on a five hundred or thousand dollars more of expenses all of a sudden every nice little thing you like has to be looked at. Yeah. I mean as Ivory I don't I don't buy clothes that I don't go. Wow <mark>and</mark> the way they got I just buy books <mark>and</mark> <mark>and</mark> they'd read <mark>and</mark> good man. Kind of, you know, don't buy books The Internet's free as fuck. Like I'm being serious like every but like pirate <mark>and</mark> pirate back like pirate that shit go Google fucking pow. Go look at Power shift <mark>and</mark> crush it on fucking Pirate Bay or if that's still around. It's not enough. It's not a fucking steal steal that shit. That's not a statement. Do you endorse? This? Don't buy shit. People don't know how to save anymore. Yeah, that's that's always the hard part <mark>and</mark> you know, even back in college out everything every little pastry that I got saving saving saving saving <mark>and</mark> you know building up we know what's happened. You know, what's happening right. Now. This is where you're getting caught I think tell me if I'm wrong the fact that you're not paying rent <mark>and</mark> saving is allowing you to spend money on a couple things that you wouldn't have <mark>and</mark> that's where the Cycles playing. Not not not not really good that I have right now is just food <mark>and</mark>", "Start Time (s)": 2231.4, "End Time (s)": 2348.5, "Clip Length (min)": 1.95, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "go Google fucking pow. Go look at Power shift <mark>and</mark> crush it on fucking Pirate Bay or if that's still around. It's not enough. It's not a fucking steal steal that shit. That's not a statement. Do you endorse? This? Don't buy shit. People don't know how to save anymore. Yeah, that's that's always the hard part <mark>and</mark> you know, even back in college out everything every little pastry that I got saving saving saving saving <mark>and</mark> you know building up we know what's happened. You know, what's happening right. Now. This is where you're getting caught I think tell me if I'm wrong the fact that you're not paying rent <mark>and</mark> saving is allowing you to spend money on a couple things that you wouldn't have <mark>and</mark> that's where the Cycles playing. Not not not not really good that I have right now is just food <mark>and</mark> then I would say for happiness instead of this happening in 11 years. Let it happen in 14 years by moving an hour <mark>and</mark> a half out gotta get one more thing, you know, <mark>and</mark> this is also kind of like a job <mark>and</mark> stuff like that. Just a lot of people who like don't care about saving <mark>and</mark> just you know, you know every every other day just going out for drinks <mark>and</mark> stuff like that gives a fuck. They're like does nothing who gives a fuck right? That's good. I like when everybody else is doing dumb shit. That means I'm about to win. Guys are so pretty. Do you feel it? Wait a minute. Wait a minute. Are you telling me that you feel fomo when everybody goes out on fucking thirsty Thursday <mark>and</mark> looking mojito? No, I don't feel I just feel like it's the people who aren't focused like I'm focused <mark>and</mark> don't have the same goal. Let me tell you. Let me tell you something really good don't judge anyone. Okay, you see where I'm going. I'm watching a", "Start Time (s)": 2288.9, "End Time (s)": 2408.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Not not not not really good that I have right now is just food <mark>and</mark> then I would say for happiness instead of this happening in 11 years. Let it happen in 14 years by moving an hour <mark>and</mark> a half out gotta get one more thing, you know, <mark>and</mark> this is also kind of like a job <mark>and</mark> stuff like that. Just a lot of people who like don't care about saving <mark>and</mark> just you know, you know every every other day just going out for drinks <mark>and</mark> stuff like that gives a fuck. They're like does nothing who gives a fuck right? That's good. I like when everybody else is doing dumb shit. That means I'm about to win. Guys are so pretty. Do you feel it? Wait a minute. Wait a minute. Are you telling me that you feel fomo when everybody goes out on fucking thirsty Thursday <mark>and</mark> looking mojito? No, I don't feel I just feel like it's the people who aren't focused like I'm focused <mark>and</mark> don't have the same goal. Let me tell you. Let me tell you something really good don't judge anyone. Okay, you see where I'm going. I'm watching a lot of judgment come now. I'm starting to spend some time with you. Like if we were having a for our dinners homies of like bro, stop judging people know he gonna judge you after you get so you see where I'm going. No, bro, <mark>and</mark> I got love for you to like honestly be empathetic like be grateful that you're not in a like I what when I talk I hate, you know, I've been trying to tell people I don't have advice I have I'm like every other human where animals that like to share. Hypotheses opinions are hot takes but like like don't judge them. Yeah, <mark>and</mark> don't don't envy them I hate when people like damn yeah because there's dad's paying for a shit. He gets to go to the club <mark>and</mark> deep down. He fucking thinks he's a loser because his dad's paying for everything next next like they're like, oh damn, they're just buying those drinks or those clothes to fit in", "Start Time (s)": 2341.9, "End Time (s)": 2458.7, "Clip Length (min)": 1.95, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like be grateful that you're not in a like I what when I talk I hate, you know, I've been trying to tell people I don't have advice I have I'm like every other human where animals that like to share. Hypotheses opinions are hot takes but like like don't judge them. Yeah, <mark>and</mark> don't don't envy them I hate when people like damn yeah because there's dad's paying for a shit. He gets to go to the club <mark>and</mark> deep down. He fucking thinks he's a loser because his dad's paying for everything next next like they're like, oh damn, they're just buying those drinks or those clothes to fit in don't judge them feel bad for them that their whole life is about other people's fucking acceptance, so they have to fucking ruin their own. Lives just so everybody thinks they're cool. I think you're spending a lot of time on judgment. Don't even think about it. I knew nothing. I knew nothing of what anybody was doing in my 20s. I didn't know if they were winning losing going out not going out unless they walked into the fucking liquor store which some of them did I literally had no fucking idea get quiet <mark>and</mark> focus on your own shit. I love that. Does that make sense to you? Yeah, no, like I feel like that was I feel like I've been no struggle with her for like the past literally six eight months since I graduated <mark>and</mark> I feel like this is gave me a little more clarity <mark>and</mark> like <mark>and</mark> <mark>and</mark> K <mark>and</mark> K. I'll tell you something else. You're probably judging because there is a little underlining envy <mark>and</mark> fomo which is okay because we're humans. Yep, right. You said I'm going right right right now hundred percent <mark>and</mark> that's okay for me. Like it's just I feel like I'm not taking the strides towards where I Want to be we're impatient know your six fucking months or eight months in we all were impatient though at that age. No. No, but I like I like I said, hold on hold on don't confuse ambition with lack of pit. You were patient. I was patient. Okay, I will but I was I was patient but I was patient because I was making as many moves <mark>and</mark> mistakes as I could <mark>and</mark> I was saying, all right, this is this is something", "Start Time (s)": 2424.7, "End Time (s)": 2543.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "store which some of them did I literally had no fucking idea get quiet <mark>and</mark> focus on your own shit. I love that. Does that make sense to you? Yeah, no, like I feel like that was I feel like I've been no struggle with her for like the past literally six eight months since I graduated <mark>and</mark> I feel like this is gave me a little more clarity <mark>and</mark> like <mark>and</mark> <mark>and</mark> K <mark>and</mark> K. I'll tell you something else. You're probably judging because there is a little underlining envy <mark>and</mark> fomo which is okay because we're humans. Yep, right. You said I'm going right right right now hundred percent <mark>and</mark> that's okay for me. Like it's just I feel like I'm not taking the strides towards where I Want to be we're impatient know your six fucking months or eight months in we all were impatient though at that age. No. No, but I like I like I said, hold on hold on don't confuse ambition with lack of pit. You were patient. I was patient. Okay, I will but I was I was patient but I was patient because I was making as many moves <mark>and</mark> mistakes as I could <mark>and</mark> I was saying, all right, this is this is something I'm not interested. This is what I'm learning. I kept moving forward. I can't move. That's different than when you're impatient. <mark>And</mark> you start fucking like looking at things from a net you were you were happy <mark>and</mark> patient too many people are sad <mark>and</mark> impatient because they can't wait to get to the Finish Line without fucking even warming up bro. You're 40 seconds in Yeah, what do you think? We can be a fucking real estate Tycoon by 24 with the fuck? I'm 22 years old <mark>and</mark> in the way, I feel like I got to have go to sleep for the next 10 years. Don't even call me until you're 32 <mark>and</mark> don't talk to nobody <mark>and</mark> go to sleep go hibernate for a decade <mark>and</mark> just fucking eat shit <mark>and</mark> work <mark>and</mark> be patient <mark>and</mark> then maybe kind of sort at 32 youngest fuck. Maybe we can have a conversation about something maybe. Yeah, everybody's fucking deciding at 22 your fucking 8 months out of school. But it is Faith is like I feel like I know what I want to be doing.", "Start Time (s)": 2480.2, "End Time (s)": 2600.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, what do you think? We can be a fucking real estate Tycoon by 24 with the fuck? I'm 22 years old <mark>and</mark> in the way, I feel like I got to have go to sleep for the next 10 years. Don't even call me until you're 32 <mark>and</mark> don't talk to nobody <mark>and</mark> go to sleep go hibernate for a decade <mark>and</mark> just fucking eat shit <mark>and</mark> work <mark>and</mark> be patient <mark>and</mark> then maybe kind of sort at 32 youngest fuck. Maybe we can have a conversation about something maybe. Yeah, everybody's fucking deciding at 22 your fucking 8 months out of school. But it is Faith is like I feel like I know what I want to be doing. I'm just you know, me too. Me too. I knew I wanted to win a fucking Super Bowl is the owner of the New York Jets. So I decide to be patient for fifty two fucking years. I knew to Good News me too. Now what I didn't say a peep. I fucking worked in the liquor store in the fucking basement for 15 years before I even pop my head up to make a YouTube video didn't say a word didn't go to a club then by shit fucking work <mark>and</mark> punchline built it for my dad <mark>and</mark> started over in a fucking conference room. But 34. Are you watching do you see how His eyeballs are bulging. Okay now that's just that's fasciitis. I mean, you can't pay for that anywhere else <mark>and</mark> what I want for you is pate <mark>and</mark> you know what I want for you patients <mark>and</mark> self-awareness. You're going to be people lose by <mark>and</mark> being impatient patience, bro. It's super real <mark>and</mark> it's super hard. It is it is I feel like I've been working on that like a tremendously I feel like that's what's giving me my success, you know back in school. <mark>And</mark> that was it's like hold on before we go any further now. I'm really caught up in a snap. He got the band camp. He got that one day at band camp. He got that Al Bundy shit like this because when he was a school, he was hot <mark>and</mark> sexy <mark>and</mark> now he went back to the hood <mark>and</mark> he's gonna shit yourself <mark>and</mark> he's like, I don't deserve this. You were happy you were having him. I was I was like I", "Start Time (s)": 2563.8, "End Time (s)": 2681.5, "Clip Length (min)": 1.96, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "now that's just that's fasciitis. I mean, you can't pay for that anywhere else <mark>and</mark> what I want for you is pate <mark>and</mark> you know what I want for you patients <mark>and</mark> self-awareness. You're going to be people lose by <mark>and</mark> being impatient patience, bro. It's super real <mark>and</mark> it's super hard. It is it is I feel like I've been working on that like a tremendously I feel like that's what's giving me my success, you know back in school. <mark>And</mark> that was it's like hold on before we go any further now. I'm really caught up in a snap. He got the band camp. He got that one day at band camp. He got that Al Bundy shit like this because when he was a school, he was hot <mark>and</mark> sexy <mark>and</mark> now he went back to the hood <mark>and</mark> he's gonna shit yourself <mark>and</mark> he's like, I don't deserve this. You were happy you were having him. I was I was like I was living life. But why why I felt like my mission was to kind of not be that positive right in other people's lives. Okay, <mark>and</mark> I feel like just having a software into myself <mark>and</mark> everything that I've been through in my life. I felt like if I could translate that story <mark>and</mark> share it with others <mark>and</mark> you know, just kind of I was really like kind of like a mini Gary Vee. That's really what people are calling me. Okay, you know <mark>and</mark> then that lets me kind of, you know, Awards <mark>and</mark> stuff like that means absolutely shit, but you can appreciate That's the part that gets confusing about Gary Vee to a lot of people as I fucking like, I'm positive <mark>and</mark> optimistic, but it's all based on Merit <mark>and</mark> execution, right? You can't build a business on just being positive <mark>and</mark> optimistic. Like that's not my business, right? That's just that's my that's my giving actually, you know be called back in school, you know, like like I had a had a good GPA know I was taking care of my academics, but also social in the sense that you know, you hate me so I'm", "Start Time (s)": 2630.3, "End Time (s)": 2749.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of I was really like kind of like a mini Gary Vee. That's really what people are calling me. Okay, you know <mark>and</mark> then that lets me kind of, you know, Awards <mark>and</mark> stuff like that means absolutely shit, but you can appreciate That's the part that gets confusing about Gary Vee to a lot of people as I fucking like, I'm positive <mark>and</mark> optimistic, but it's all based on Merit <mark>and</mark> execution, right? You can't build a business on just being positive <mark>and</mark> optimistic. Like that's not my business, right? That's just that's my that's my giving actually, you know be called back in school, you know, like like I had a had a good GPA know I was taking care of my academics, but also social in the sense that you know, you hate me so I'm curious. New side of me that I've never seen before outside yes to put him in the environment where he blossomed <mark>and</mark> bandcamp <mark>and</mark> now he's going back to shit <mark>and</mark> wondering why aren't times good like before? Okay kind of yeah, <mark>and</mark> now Mom is your fault now I put my name on the milk in the fridge. Don't touch that that's mine mommy, but I see where you're coming from <mark>and</mark> also nobody's keeping you at home, right you're choosing to be at home. Matter back moms like no don't give me none. Don't give me no mom's kilims kind of like we need to leave homie. I already said whole lecture. Okay one more time. Nobody wants their baby leaving. Oh, no,", "Start Time (s)": 2698.4, "End Time (s)": 2813.9, "Clip Length (min)": 1.93, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "why aren't times good like before? Okay kind of yeah, <mark>and</mark> now Mom is your fault now I put my name on the milk in the fridge. Don't touch that that's mine mommy, but I see where you're coming from <mark>and</mark> also nobody's keeping you at home, right you're choosing to be at home. Matter back moms like no don't give me none. Don't give me no mom's kilims kind of like we need to leave homie. I already said whole lecture. Okay one more time. Nobody wants their baby leaving. Oh, no, bro, you need to be careful here because if she doesn't want you leaving <mark>and</mark> she paid for your college you're getting coddled. She doesn't want me to leave because she's scared of being alone in the way because nobody else is there. Well, she has like my siblings but she's scared that I'm gonna be the by himself. No, no like that has nothing to do with you, right? You're being coddled. You know that right? Do you know me people right now in my community are like mad as hell at you because they're in debt <mark>and</mark> they have nowhere to go. You know that right? Yeah, you need to be careful here in a good way. This is why this is fun. Like this is all love as you can tell solo man. You tough love be careful. Be careful here. You need to be real careful here because your mom is fucking amazing <mark>and</mark> a lot of times when I talk about parents that create fake environments. We always paint them as Super rich white families. Well, we don't talk enough about is immigrants or humble", "Start Time (s)": 2762.2, "End Time (s)": 2881.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "She doesn't want me to leave because she's scared of being alone in the way because nobody else is there. Well, she has like my siblings but she's scared that I'm gonna be the by himself. No, no like that has nothing to do with you, right? You're being coddled. You know that right? Do you know me people right now in my community are like mad as hell at you because they're in debt <mark>and</mark> they have nowhere to go. You know that right? Yeah, you need to be careful here in a good way. This is why this is fun. Like this is all love as you can tell solo man. You tough love be careful. Be careful here. You need to be real careful here because your mom is fucking amazing <mark>and</mark> a lot of times when I talk about parents that create fake environments. We always paint them as Super rich white families. Well, we don't talk enough about is immigrants or humble fucking work their whole lives for their kids <mark>and</mark> put their kids on <mark>and</mark> you need to be careful here because you're coddled. <mark>And</mark> I want to see every receipt because the second you bought one cup of Starbucks. I'm mad at you. I've never bought some fact. I've even heard coffee respect bro, but you have but what but I'm really serious on this on you might be coddled. You know that right? Right. Look it's rare to not have to pay rent. It's rare. It's rare real quick. It's rare for your parent to pay for college completely. It's rare. It's rare for you to be able to not pay rent. So you might be getting caught because you're entitled. I mean, I'm super humbled by the fact that you know, I don't have to pay around. I know you're appreciative. Oh, yeah, super appreciative of that fact, but your butt but humility, you know comes in the form of", "Start Time (s)": 2828.7, "End Time (s)": 2944.2, "Clip Length (min)": 1.93, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>And</mark> I want to see every receipt because the second you bought one cup of Starbucks. I'm mad at you. I've never bought some fact. I've even heard coffee respect bro, but you have but what but I'm really serious on this on you might be coddled. You know that right? Right. Look it's rare to not have to pay rent. It's rare. It's rare real quick. It's rare for your parent to pay for college completely. It's rare. It's rare for you to be able to not pay rent. So you might be getting caught because you're entitled. I mean, I'm super humbled by the fact that you know, I don't have to pay around. I know you're appreciative. Oh, yeah, super appreciative of that fact, but your butt but humility, you know comes in the form of like you started this call with you know, friends are losers <mark>and</mark> negative energy in a home. You're not paying for that's called non accountability humility comes with Mom. How can I have more value to you? What can I do to get out of this house <mark>and</mark> get things done? That's right, <mark>and</mark> I help you. <mark>And</mark> you're using my sibling you're using the excuse of mom doesn't want me to leave. Yeah, because she says she loves you <mark>and</mark> loves having you around. Right fake environment bro it is, you know <mark>and</mark> you know, I'm feel like I actually like even though I when I do leave I think it may hurt her in one aspect, but I feel like if when she sees that I'm doing well. It looks like even me going away to college of stuff for her but your Sprouts. Yeah, of course parents love their kids, especially the way you're painting your mom. Here's the other thing. She's ready for you to be a man. I promised my favorite movie Step Brothers <mark>and</mark> they lived in the house. So they're 40. I got a I got Family called boom. You've got the close out the show. Okay. I love you. I'm being dead serious plug away for four minutes. I love her. All right, man. Okay. Gotta go. All right. Appreciate so much Gary. Thank you. Thank you.", "Start Time (s)": 2891.4, "End Time (s)": 3009.1, "Clip Length (min)": 1.96, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Mom. How can I have more value to you? What can I do to get out of this house <mark>and</mark> get things done? That's right, <mark>and</mark> I help you. <mark>And</mark> you're using my sibling you're using the excuse of mom doesn't want me to leave. Yeah, because she says she loves you <mark>and</mark> loves having you around. Right fake environment bro it is, you know <mark>and</mark> you know, I'm feel like I actually like even though I when I do leave I think it may hurt her in one aspect, but I feel like if when she sees that I'm doing well. It looks like even me going away to college of stuff for her but your Sprouts. Yeah, of course parents love their kids, especially the way you're painting your mom. Here's the other thing. She's ready for you to be a man. I promised my favorite movie Step Brothers <mark>and</mark> they lived in the house. So they're 40. I got a I got Family called boom. You've got the close out the show. Okay. I love you. I'm being dead serious plug away for four minutes. I love her. All right, man. Okay. Gotta go. All right. Appreciate so much Gary. Thank you. Thank you. Thank you Eric. Absolutely. All right. So anyway, so we're going to close out man, <mark>and</mark> I'm going to take one more call about I want you to remember. The one thing power Chef is the exclusive ownership of Daymond John it is it is watermarks any rebroadcast <mark>and</mark> or downloading on content illegal, you will go to the charity. r All the best brother. Thank you so much. I really appreciate it. Thank you, man. That's great. Cool. I like that one. We Gary I don't know when we went back <mark>and</mark> forth. Love them hated him got his ass. I would really absolutely amazing. Listen one more call. Let's do one more call. This next segment is brought to you by power shift Gary V his favorite book. He uses this all the time. I sent him a copy change his life goes on. MacGyver I already like this guy. I'm going to like it more if it's a girl.", "Start Time (s)": 2954.9, "End Time (s)": 3069.3, "Clip Length (min)": 1.91, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "How are you doing? All right. All right represent. So we got a question a comment or something like that. yeah, man, I just That ain't you I appreciate that's impressive. I want people to know that they don't necessarily <mark>and</mark> I'm not saying anything's wrong with college if you can afford <mark>and</mark> you know to go to college people like you <mark>and</mark> me, I barely finished high school. We went out there we bust it out. But <mark>and</mark> <mark>and</mark> that's that's really honestly what the book is about like creating influence you moved up in the company that you said you moved up in the company. Why why was it because of purely your talents or the way you work with people? It's a couple of days. Are 15 20 hours a week <mark>and</mark> I actually became VP of the company <mark>and</mark> continue to grow <mark>and</mark> have you no further opportunity since then rolling. So this on", "Start Time (s)": 3092.3, "End Time (s)": 3211.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That ain't you I appreciate that's impressive. I want people to know that they don't necessarily <mark>and</mark> I'm not saying anything's wrong with college if you can afford <mark>and</mark> you know to go to college people like you <mark>and</mark> me, I barely finished high school. We went out there we bust it out. But <mark>and</mark> <mark>and</mark> that's that's really honestly what the book is about like creating influence you moved up in the company that you said you moved up in the company. Why why was it because of purely your talents or the way you work with people? It's a couple of days. Are 15 20 hours a week <mark>and</mark> I actually became VP of the company <mark>and</mark> continue to grow <mark>and</mark> have you no further opportunity since then rolling. So this on thankful man, that's for sure. I think you just hit on the head. You know when Gary was talking to the gentleman earlier today talking about, you know, being a sports agent people need to like you. I mean the whole theory of polisher the whole theory of power shift is that you have to build influence <mark>and</mark> how do you build influence? Look you you drop out of school? You went to a company you will getting minimum wage as a designer. Or a system designer you moved up to be the VP the reality is that whether you are, you know in power shift whether you're trying to get a better job get an investment from me or do something else people want to be around people. They like people want to be around people that they can sit next to for eight hours a day five days a week for the next five years. <mark>And</mark> if you're a problem solver <mark>and</mark> you shift power to other people when you see that they can do something <mark>and</mark> they shift power back to you <mark>and</mark> then you nurture those relationships you're doing exactly why I wrote the book of this too many people out there using There's an excuse there's people out there", "Start Time (s)": 3145.1, "End Time (s)": 3263.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Are 15 20 hours a week <mark>and</mark> I actually became VP of the company <mark>and</mark> continue to grow <mark>and</mark> have you no further opportunity since then rolling. So this on thankful man, that's for sure. I think you just hit on the head. You know when Gary was talking to the gentleman earlier today talking about, you know, being a sports agent people need to like you. I mean the whole theory of polisher the whole theory of power shift is that you have to build influence <mark>and</mark> how do you build influence? Look you you drop out of school? You went to a company you will getting minimum wage as a designer. Or a system designer you moved up to be the VP the reality is that whether you are, you know in power shift whether you're trying to get a better job get an investment from me or do something else people want to be around people. They like people want to be around people that they can sit next to for eight hours a day five days a week for the next five years. <mark>And</mark> if you're a problem solver <mark>and</mark> you shift power to other people when you see that they can do something <mark>and</mark> they shift power back to you <mark>and</mark> then you nurture those relationships you're doing exactly why I wrote the book of this too many people out there using There's an excuse there's people out there that would have been you <mark>and</mark> said I dropped out of school. I'm only starting a minimum wage. I got all these hours. They'll never gonna respect me. The company's only three people. It's never going to grow 15 <mark>and</mark> that's exactly the mentality. So I thank you as well for learning from Gary me <mark>and</mark> all the other people out there who just take the time to put the information out there free or anywhere you can find it <mark>and</mark> <mark>and</mark> I hope you're doing the same for the people coming up underneath you. Oh, absolutely, man. I'm involved heavily in the community <mark>and</mark> the business world <mark>and</mark> I'm actually been working on want to start something called creative culture one day <mark>and</mark> that creative kind of stands for a community of real entrepreneurs <mark>and</mark> aspiring Trail Blazers with imperfections to add value <mark>and</mark> really it's about this empowering other people. Like if I can do it at a high school dropout got two felonies when I turn 18 like the whole nine yard, I mean should not be", "Start Time (s)": 3201.6, "End Time (s)": 3313.9, "Clip Length (min)": 1.87, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "next to for eight hours a day five days a week for the next five years. <mark>And</mark> if you're a problem solver <mark>and</mark> you shift power to other people when you see that they can do something <mark>and</mark> they shift power back to you <mark>and</mark> then you nurture those relationships you're doing exactly why I wrote the book of this too many people out there using There's an excuse there's people out there that would have been you <mark>and</mark> said I dropped out of school. I'm only starting a minimum wage. I got all these hours. They'll never gonna respect me. The company's only three people. It's never going to grow 15 <mark>and</mark> that's exactly the mentality. So I thank you as well for learning from Gary me <mark>and</mark> all the other people out there who just take the time to put the information out there free or anywhere you can find it <mark>and</mark> <mark>and</mark> I hope you're doing the same for the people coming up underneath you. Oh, absolutely, man. I'm involved heavily in the community <mark>and</mark> the business world <mark>and</mark> I'm actually been working on want to start something called creative culture one day <mark>and</mark> that creative kind of stands for a community of real entrepreneurs <mark>and</mark> aspiring Trail Blazers with imperfections to add value <mark>and</mark> really it's about this empowering other people. Like if I can do it at a high school dropout got two felonies when I turn 18 like the whole nine yard, I mean should not be where I am today. I forgot my ups <mark>and</mark> downs, but I definitely should not have the if I can do it any <mark>Joe</mark> Schmo can you know what I mean <mark>and</mark> I want to help those in need to power other people realize what I feel like you doing I want to make sure the people listening to needs to understand that the mentality of an entrepreneur can be used within a system you know when I'm at my company all my people think is entrepreneurs because if I was the only one thinking like that these guys would just be putting you know round pegs in round holes but if you're an entrepreneur you think within the system I need to depend on my staff <mark>and</mark> people like you who think like entrepreneurs so Gary veins back I don't know if you got a question for him <mark>and</mark> I think going to sign off right after that we got great guy <mark>and</mark> he dropped out of school", "Start Time (s)": 3245.6, "End Time (s)": 3363.3, "Clip Length (min)": 1.96, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "stands for a community of real entrepreneurs <mark>and</mark> aspiring Trail Blazers with imperfections to add value <mark>and</mark> really it's about this empowering other people. Like if I can do it at a high school dropout got two felonies when I turn 18 like the whole nine yard, I mean should not be where I am today. I forgot my ups <mark>and</mark> downs, but I definitely should not have the if I can do it any <mark>Joe</mark> Schmo can you know what I mean <mark>and</mark> I want to help those in need to power other people realize what I feel like you doing I want to make sure the people listening to needs to understand that the mentality of an entrepreneur can be used within a system you know when I'm at my company all my people think is entrepreneurs because if I was the only one thinking like that these guys would just be putting you know round pegs in round holes but if you're an entrepreneur you think within the system I need to depend on my staff <mark>and</mark> people like you who think like entrepreneurs so Gary veins back I don't know if you got a question for him <mark>and</mark> I think going to sign off right after that we got great guy <mark>and</mark> he dropped out of school <mark>and</mark> is crushing it so love congratulations thanks them for holding it down as we end today it's podcast I want to give a huge shout out to the people you know it's so funny people that leave reviews <mark>and</mark> written reviews of this podcast on Apple Spotify <mark>and</mark> all the other platforms just mean the world to me you've taken an extra 13 to 95 seconds to show love <mark>and</mark> also give context to people of why this is a worthwhile podcast so I appreciate that so much <mark>and</mark> even more fun because I think we all love a little cosine or a shout out or a little awareness I'm gonna have the team give a couple of shoutouts daily on our favorite reviews so Dean", "Start Time (s)": 3298.8, "End Time (s)": 3418.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> is crushing it so love congratulations thanks them for holding it down as we end today it's podcast I want to give a huge shout out to the people you know it's so funny people that leave reviews <mark>and</mark> written reviews of this podcast on Apple Spotify <mark>and</mark> all the other platforms just mean the world to me you've taken an extra 13 to 95 seconds to show love <mark>and</mark> also give context to people of why this is a worthwhile podcast so I appreciate that so much <mark>and</mark> even more fun because I think we all love a little cosine or a shout out or a little awareness I'm gonna have the team give a couple of shoutouts daily on our favorite reviews so Dean take it away which were our favorites this week thank you Today's review is Gary V with that knowledge <mark>and</mark> love this podcast written by Logan from Texas <mark>and</mark> Phillip Mr. Say Gary takes ideas about branding <mark>and</mark> marketing <mark>and</mark> breaks them down into simple workable practical strategies that anyone can do at any second of the day the amount of free advice <mark>and</mark> information we have access to thanks to GV is insane. You'd be a fool not to apply this knowledge to your everyday practices. <mark>And</mark> secondly, thanks Gary V for all that you do. I've been watching your content for the past couple of years <mark>and</mark> it's helped me change my perspective on life. I've been in a rough patch these last. Several months <mark>and</mark> now in a recovery phase hearing your content gives me the motivation to give each day my best at bat <mark>and</mark> not get down on myself that come up short. Keep it up Take Care. Thank you both so much for riding in <mark>and</mark> remember keep leaving reviews because yours could be next.", "Start Time (s)": 3381.2, "End Time (s)": 3464.4, "Clip Length (min)": 1.39, "show_uri": "spotify:show:6SZVsPIxPfVs6aavqM1peY", "show_name": "The GaryVee Audio Experience", "show_description": "Welcome to The Garyvee Audio Experience, hosted by entrepreneur, CEO, investor, vlogger, and public speaker Gary Vaynerchuk. On this podcast you'll find a mix of my #AskGaryVee show episodes, keynote speeches on marketing and business, segments from my WEEKLYVEE video series, interviews and fireside chats I've given, as well as new and current thoughts I record originally for this audio experience!", "publisher": "Gary Vaynerchuk", "episode_uri": "spotify:episode:00y3rxCkHBrbY1xwqojEGR", "episode_name": "How Entitled Are You? w/ Daymond John", "episode_description": "For today\u2019s episode I sit down with Daymond John, one of the stars behind the entrepreneurial television show Shark Tank. I had a lot of fun during this episode as we talk about all the forms of communication and how to deploy humility within entitlement. Make sure to check out Daymond's new book 'Powershift' and hit me up to let me know what you thought! Tweet Me! @garyvee Text Me! 212-931-5731 My Appearances: garyvee.com/events My Newsletter: garyvee.com/newsletter https://www.instagram.com/thesharkdaymond/ ", "score": 7.5262246, "explanation": "{\n  \"value\": 7.5262246,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11900871,\n      \"description\": \"weight(word_list:joe in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11900871,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.13988385,\n      \"description\": \"weight(word_list:and in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.13988385,\n          \"description\": \"score(LMDirichletSimilarity, freq=375.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9534048,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 375.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.8202007,\n      \"description\": \"weight(word_list:elon in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.8202007,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.4471312,\n      \"description\": \"weight(word_list:musk in 26) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.4471312,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "With traffic errands <mark>and</mark> parking cars can be a chore but a great car can be an adventure a getaway <mark>and</mark> a prized possession whatever your budget or family require. There's a car out there. You'll love we're here to help you find it. I'm Todd. I'm Paul <mark>and</mark> this is the everyday driver car debate. I am so happy for you that you got the Lotus out the heating pads weren't you're happy for me. I'm thrilled for you're happy for me. Honestly driving. Sports cars in the winter sort of revelatory isn't out but just driving it period it honestly I last started it the day after Christmas because I had to get it out of the garage <mark>and</mark> having some work done start start. I'm trying to wrap my head around this you started it last night started was the day after Christmas. So that's been like what three months as of this report. Last time. It moved was a month before that. Oh my gosh. So the tires by the way, where there's one thing. I mean I could tell mean granted it's not a heavy car is true. I could tell that the tires needed a kind of they needed to go in a circle for a bit. You to roll? Yeah. Yeah,", "Start Time (s)": 1.0, "End Time (s)": 61.6, "Clip Length (min)": 1.01, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "car can be an adventure a getaway <mark>and</mark> a prized possession whatever your budget or family require. There's a car out there. You'll love we're here to help you find it. I'm Todd. I'm Paul <mark>and</mark> this is the everyday driver car debate. I am so happy for you that you got the Lotus out the heating pads weren't you're happy for me. I'm thrilled for you're happy for me. Honestly driving. Sports cars in the winter sort of revelatory isn't out but just driving it period it honestly I last started it the day after Christmas because I had to get it out of the garage <mark>and</mark> having some work done start start. I'm trying to wrap my head around this you started it last night started was the day after Christmas. So that's been like what three months as of this report. Last time. It moved was a month before that. Oh my gosh. So the tires by the way, where there's one thing. I mean I could tell mean granted it's not a heavy car is true. I could tell that the tires needed a kind of they needed to go in a circle for a bit. You to roll? Yeah. Yeah, but but they settled in okay, it was about 40 degrees yesterday. <mark>And</mark> you heard me on the last podcast talking about my Insanity of burning a single track into my driveway, which I accomplished. I'm surprised you went out there with a hair dryer heat gun. Like I was the track of the driveway melting everything because last year labeling the last faster / it was almost April for I was in the car. Oh my God, so I thought I buy it because it's been warm enough in the roads been dry enough, but my driveway is the problem. Yeah, so I had errands to run yesterday <mark>and</mark> I got the Lotus started <mark>and</mark> I took it <mark>and</mark> it was here's the thing. I didn't really know how I was going to feel about it having not been in it for four months <mark>and</mark> having driven the Phaeton. Sure. Sure. Yeah, <mark>and</mark> you know what? Okay, hang on. I was a child after driving this car I of the for the next like two hours after I drove it for like 20 minutes. I was just walking around just happy just it's awesome Kitty that's almost ridiculous is <mark>and</mark> kind of surprising. The Phaeton is crazy comfortable. Yeah, just yeah, it's big heavy fat <mark>and</mark> comfort. You know, it's got great seat heaters", "Start Time (s)": 5.2, "End Time (s)": 124.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they settled in okay, it was about 40 degrees yesterday. <mark>And</mark> you heard me on the last podcast talking about my Insanity of burning a single track into my driveway, which I accomplished. I'm surprised you went out there with a hair dryer heat gun. Like I was the track of the driveway melting everything because last year labeling the last faster / it was almost April for I was in the car. Oh my God, so I thought I buy it because it's been warm enough in the roads been dry enough, but my driveway is the problem. Yeah, so I had errands to run yesterday <mark>and</mark> I got the Lotus started <mark>and</mark> I took it <mark>and</mark> it was here's the thing. I didn't really know how I was going to feel about it having not been in it for four months <mark>and</mark> having driven the Phaeton. Sure. Sure. Yeah, <mark>and</mark> you know what? Okay, hang on. I was a child after driving this car I of the for the next like two hours after I drove it for like 20 minutes. I was just walking around just happy just it's awesome Kitty that's almost ridiculous is <mark>and</mark> kind of surprising. The Phaeton is crazy comfortable. Yeah, just yeah, it's big heavy fat <mark>and</mark> comfort. You know, it's got great seat heaters seat massagers. You got a bunch of room. You're sure hounding on your, you know mobile couch. So <mark>and</mark> so the Lotus obviously the other end of the spectrum sacrifice mmm, but I remember how to get in which is novel because there is a procedure <mark>and</mark> I do have the flip shift shirt was you asking I have the Lotus position a shirt. I bought it. It's awesome. But so I get in there <mark>and</mark> once I start driving <mark>and</mark> I like actually driving <mark>and</mark> I realized this this is actually perfect to sit in. I don't know how they've done it to jump in it after not being in it regularly. Yeah <mark>and</mark> having been in big pushing Madness. That is the Phaeton. Mmm. You can tell how thin the seat is in the Lotus Hotel House of Crossing. There is everywhere around you <mark>and</mark> yet they've nailed it sure. It's perfectly ergonomically awesome. <mark>And</mark> I was a giddy little child everywhere. I went yesterday <mark>and</mark> I did have a few people who snapped their necks like wait. What is that doing out here? It was awesome <mark>and</mark> I was reminded by Small it was when I sat behind a Honda CRV at the light. Mmm looking at their", "Start Time (s)": 62.5, "End Time (s)": 182.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The Phaeton is crazy comfortable. Yeah, just yeah, it's big heavy fat <mark>and</mark> comfort. You know, it's got great seat heaters seat massagers. You got a bunch of room. You're sure hounding on your, you know mobile couch. So <mark>and</mark> so the Lotus obviously the other end of the spectrum sacrifice mmm, but I remember how to get in which is novel because there is a procedure <mark>and</mark> I do have the flip shift shirt was you asking I have the Lotus position a shirt. I bought it. It's awesome. But so I get in there <mark>and</mark> once I start driving <mark>and</mark> I like actually driving <mark>and</mark> I realized this this is actually perfect to sit in. I don't know how they've done it to jump in it after not being in it regularly. Yeah <mark>and</mark> having been in big pushing Madness. That is the Phaeton. Mmm. You can tell how thin the seat is in the Lotus Hotel House of Crossing. There is everywhere around you <mark>and</mark> yet they've nailed it sure. It's perfectly ergonomically awesome. <mark>And</mark> I was a giddy little child everywhere. I went yesterday <mark>and</mark> I did have a few people who snapped their necks like wait. What is that doing out here? It was awesome <mark>and</mark> I was reminded by Small it was when I sat behind a Honda CRV at the light. Mmm looking at their bumper as guess. I looking up at their exhaust. Yeah, the Honda CRV is not a big truck. Yeah. No, that's great. I mean my drive Bays been clear. So I've been able to get the came in at once in a while. So I've been I've been a little bit more fed, I guess sooner than you <mark>and</mark> so I've just I took it for a drive on Saturday <mark>and</mark> was just loving it again. <mark>And</mark> so but that's because I think it's been a bit of a mild winter compared to the snow we had last year. So the roads have been cleared but you're right the driveway I mean Todd Out there, like my stupid stuff is ask guns <mark>and</mark> heating pads <mark>and</mark> everything right about right about mid-February it ices over <mark>and</mark> then I'm dealing with doesn't snow blower be damned. I'm dealing with ice <mark>and</mark> at one point seriously. I have sections on my drive with more than you ever wanted to hear but like eight inches thick ice. Yeah, just yeah well melt <mark>and</mark> then it freezes over night. Yeah melts a little bit more in freezes again, <mark>and</mark> we get a huge side side wind all evening <mark>and</mark> it blows everything over. It's awesome. There was coming actually on one of the next fate <mark>and</mark> pieces in fact of", "Start Time (s)": 117.3, "End Time (s)": 235.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was a giddy little child everywhere. I went yesterday <mark>and</mark> I did have a few people who snapped their necks like wait. What is that doing out here? It was awesome <mark>and</mark> I was reminded by Small it was when I sat behind a Honda CRV at the light. Mmm looking at their bumper as guess. I looking up at their exhaust. Yeah, the Honda CRV is not a big truck. Yeah. No, that's great. I mean my drive Bays been clear. So I've been able to get the came in at once in a while. So I've been I've been a little bit more fed, I guess sooner than you <mark>and</mark> so I've just I took it for a drive on Saturday <mark>and</mark> was just loving it again. <mark>And</mark> so but that's because I think it's been a bit of a mild winter compared to the snow we had last year. So the roads have been cleared but you're right the driveway I mean Todd Out there, like my stupid stuff is ask guns <mark>and</mark> heating pads <mark>and</mark> everything right about right about mid-February it ices over <mark>and</mark> then I'm dealing with doesn't snow blower be damned. I'm dealing with ice <mark>and</mark> at one point seriously. I have sections on my drive with more than you ever wanted to hear but like eight inches thick ice. Yeah, just yeah well melt <mark>and</mark> then it freezes over night. Yeah melts a little bit more in freezes again, <mark>and</mark> we get a huge side side wind all evening <mark>and</mark> it blows everything over. It's awesome. There was coming actually on one of the next fate <mark>and</mark> pieces in fact of the next fate in. Peace. You will see my hmm frustrated attempt to use the Phaeton midwinter as just a snowplow. Oh yelling ice burying it deeply into my driveway, which is very fun. Thank God. I got the Lotus out now. So the driveway is getting better. Good good. I'm glad you're listening to the podcast here the driveway update <mark>and</mark> we'll see you guys tonight. Yeah. Well speaking of spectrum of sacrifice. We've got a question from Anthony be in Denver Colorado who apparently we've turned into an everyday driver catchphrase billboard, which I'm glad about. That's frightening. I'm glad your proclivity. Could align with ours, I think well, he's writing specifically about wanting that because he's got a high turnover in his car ownership for the last at least 25 years. He's been through a lot of cars which you will hear <mark>and</mark> this is very much he wants to cars both at the ends. So we've got to shop for you know, something big <mark>and</mark> heavy for the dogs <mark>and</mark> something just", "Start Time (s)": 168.3, "End Time (s)": 287.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> at one point seriously. I have sections on my drive with more than you ever wanted to hear but like eight inches thick ice. Yeah, just yeah well melt <mark>and</mark> then it freezes over night. Yeah melts a little bit more in freezes again, <mark>and</mark> we get a huge side side wind all evening <mark>and</mark> it blows everything over. It's awesome. There was coming actually on one of the next fate <mark>and</mark> pieces in fact of the next fate in. Peace. You will see my hmm frustrated attempt to use the Phaeton midwinter as just a snowplow. Oh yelling ice burying it deeply into my driveway, which is very fun. Thank God. I got the Lotus out now. So the driveway is getting better. Good good. I'm glad you're listening to the podcast here the driveway update <mark>and</mark> we'll see you guys tonight. Yeah. Well speaking of spectrum of sacrifice. We've got a question from Anthony be in Denver Colorado who apparently we've turned into an everyday driver catchphrase billboard, which I'm glad about. That's frightening. I'm glad your proclivity. Could align with ours, I think well, he's writing specifically about wanting that because he's got a high turnover in his car ownership for the last at least 25 years. He's been through a lot of cars which you will hear <mark>and</mark> this is very much he wants to cars both at the ends. So we've got to shop for you know, something big <mark>and</mark> heavy for the dogs <mark>and</mark> something just raw screamingly lightweight <mark>and</mark> very sacrificial. Yes at the other end. So we've also got a debate from Dennis F who is a Honda guy. He's a Honda Person through <mark>and</mark> through I noticed that yeah, he says, you know, I need something for my wife first, but then what do I get? He's torn between two different Honda's which will go into but before we do that, we've got to get into some Geneva reveals. We've got to talk about those <mark>and</mark> by the way, Saturday is a repeat of the return. So the Supra game an S&M to competition that is tomorrow <mark>and</mark> that is like I said a repeat from airing earlier in the season. It was the I believe the first episode it was these actual prior episode of season 6 that will be is available at The is is repeat <mark>and</mark> on Vimeo <mark>and</mark> also it is again repeating this weekend early in the morning on Saturday morning. By the way. That is tomorrow morning. Happy Friday. Yeah, so you'll see that super piece <mark>and</mark> I think I always feel", "Start Time (s)": 219.1, "End Time (s)": 338.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a lot of cars which you will hear <mark>and</mark> this is very much he wants to cars both at the ends. So we've got to shop for you know, something big <mark>and</mark> heavy for the dogs <mark>and</mark> something just raw screamingly lightweight <mark>and</mark> very sacrificial. Yes at the other end. So we've also got a debate from Dennis F who is a Honda guy. He's a Honda Person through <mark>and</mark> through I noticed that yeah, he says, you know, I need something for my wife first, but then what do I get? He's torn between two different Honda's which will go into but before we do that, we've got to get into some Geneva reveals. We've got to talk about those <mark>and</mark> by the way, Saturday is a repeat of the return. So the Supra game an S&M to competition that is tomorrow <mark>and</mark> that is like I said a repeat from airing earlier in the season. It was the I believe the first episode it was these actual prior episode of season 6 that will be is available at The is is repeat <mark>and</mark> on Vimeo <mark>and</mark> also it is again repeating this weekend early in the morning on Saturday morning. By the way. That is tomorrow morning. Happy Friday. Yeah, so you'll see that super piece <mark>and</mark> I think I always feel bad when I say this, but I'm pretty sure by the time you hear this or maybe a couple days later. All seven episodes will be available on Amazon Prime, I sure hope so. I'm glad they're finally coming through for us. So yes watch said that <mark>and</mark> well we've got to get into Geneva here because the 911 Turbo S was revealed. I'm studying it. <mark>And</mark> I'm just happy I'm just happy that it exists 650 horsepower. You said you'd kind of called it. But yeah what 650? Yeah, I mean there's cars with more but well, it means it's now like a hundred down from the GT2 RS. I yeah, <mark>and</mark> it's going to be I just I just like it I just like it. Well, I do Porsche has shown with the turbo in the past. I mean their cars <mark>and</mark> are about the turbo in the past. A 911 has a hundred to 200 horsepower less than its competition. It's every bit as fast as this competition. Well, that's just it launches harder <mark>and</mark> quicker <mark>and</mark> it's faster a 600-horsepower", "Start Time (s)": 276.7, "End Time (s)": 396.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "morning. Happy Friday. Yeah, so you'll see that super piece <mark>and</mark> I think I always feel bad when I say this, but I'm pretty sure by the time you hear this or maybe a couple days later. All seven episodes will be available on Amazon Prime, I sure hope so. I'm glad they're finally coming through for us. So yes watch said that <mark>and</mark> well we've got to get into Geneva here because the 911 Turbo S was revealed. I'm studying it. <mark>And</mark> I'm just happy I'm just happy that it exists 650 horsepower. You said you'd kind of called it. But yeah what 650? Yeah, I mean there's cars with more but well, it means it's now like a hundred down from the GT2 RS. I yeah, <mark>and</mark> it's going to be I just I just like it I just like it. Well, I do Porsche has shown with the turbo in the past. I mean their cars <mark>and</mark> are about the turbo in the past. A 911 has a hundred to 200 horsepower less than its competition. It's every bit as fast as this competition. Well, that's just it launches harder <mark>and</mark> quicker <mark>and</mark> it's faster a 600-horsepower 911 is going to feel like a 7 to 800 horsepower. Whatever else me now. It's at the numbers that people have tuned their older 911 Jeremiah to get up to <mark>and</mark> let you know they think okay. Now it's fast this thing is gonna be unbelievable which are the meanest excited about it's funny because I part of me thought honestly thought we were going to reach a okay. We're done we're going to go. Another way with the horsepower Wars, but honestly, I think that the electric car reality is perpetuated in what sense you mean because of the the electric horsepower numbers are getting so bonkers the combination of the crazy numbers that electric cars are accomplished combined with the instant roller coaster launch feel that is now available to tons of people <mark>and</mark> shiftless feel you both back to Lurch in a feel <mark>and</mark> an upshift <mark>and</mark> that's not there totally. The people that have never at I think this is honestly I think this is most of us. Hmm, there's there. I think the vast majority of people that drive have never been in a car that could do 0 to 60 in four seconds or", "Start Time (s)": 333.9, "End Time (s)": 453.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "600-horsepower 911 is going to feel like a 7 to 800 horsepower. Whatever else me now. It's at the numbers that people have tuned their older 911 Jeremiah to get up to <mark>and</mark> let you know they think okay. Now it's fast this thing is gonna be unbelievable which are the meanest excited about it's funny because I part of me thought honestly thought we were going to reach a okay. We're done we're going to go. Another way with the horsepower Wars, but honestly, I think that the electric car reality is perpetuated in what sense you mean because of the the electric horsepower numbers are getting so bonkers the combination of the crazy numbers that electric cars are accomplished combined with the instant roller coaster launch feel that is now available to tons of people <mark>and</mark> shiftless feel you both back to Lurch in a feel <mark>and</mark> an upshift <mark>and</mark> that's not there totally. The people that have never at I think this is honestly I think this is most of us. Hmm, there's there. I think the vast majority of people that drive have never been in a car that could do 0 to 60 in four seconds or less. Okay, <mark>and</mark> actually felt that I mean he'll until Tesla's start showing up in your neighborhood. Yeah, <mark>and</mark> because they are so Unity by everywhere <mark>and</mark> everybody suffers about the Tesla right there. Now there is a general populace that is just aware of that kind of acceleration. <mark>And</mark> that is I think I do. I think it's a given a shot in the arm <mark>and</mark> perpetuated the crazy horse power Wars from Whatwhat are we honestly what are we doing with a 650 horsepower? 911 that is just for sale. I don't mean like tuned is a different thing. It's just for sale lusting after want to get desperately because that's why cars cell <mark>and</mark> its numbers its performance. That's why it's the its motion marketing moshus of it's not even marketing its emotion about the numbers marketing is one thing because marketing talks up average cars <mark>and</mark> you think well the marketing seems to be way better than the All car but then there's cars with huge crazy numbers <mark>and</mark> that is why we're selling electric cars based solely on StraightLine performance. All the YouTube videos", "Start Time (s)": 395.4, "End Time (s)": 515.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that drive have never been in a car that could do 0 to 60 in four seconds or less. Okay, <mark>and</mark> actually felt that I mean he'll until Tesla's start showing up in your neighborhood. Yeah, <mark>and</mark> because they are so Unity by everywhere <mark>and</mark> everybody suffers about the Tesla right there. Now there is a general populace that is just aware of that kind of acceleration. <mark>And</mark> that is I think I do. I think it's a given a shot in the arm <mark>and</mark> perpetuated the crazy horse power Wars from Whatwhat are we honestly what are we doing with a 650 horsepower? 911 that is just for sale. I don't mean like tuned is a different thing. It's just for sale lusting after want to get desperately because that's why cars cell <mark>and</mark> its numbers its performance. That's why it's the its motion marketing moshus of it's not even marketing its emotion about the numbers marketing is one thing because marketing talks up average cars <mark>and</mark> you think well the marketing seems to be way better than the All car but then there's cars with huge crazy numbers <mark>and</mark> that is why we're selling electric cars based solely on StraightLine performance. All the YouTube videos were all comparing to 60s muscle cars. <mark>And</mark> that's why electric cars are selling well emotion as it is it's emotion because as humans we are all kind of at everybody's different like my wife is on the extreme end, but we're all list makers. We're all making a categorized list in our head always about everything that's bigger than this. This is smaller than that that cost more than this <mark>and</mark> so that big number Something we're all benchmarking always. Yeah, this is why look I was this kid. This is why if you are 14 <mark>and</mark> you are dreaming about driving a car with a zero to 60 of 3.6 is significantly better than a car with the 0 to 60 of 3.8 just that it's just better. Yeah, it's better. It's better. Hey sis continuing. Yeah, <mark>and</mark> I'm talking from the position of loving horsepower. I do I love power. I also do love the power to weight. So it's not I don't have to have 600 horsepower. But if I've got like in my Cayman Hundred 350 in a three thousand pound", "Start Time (s)": 449.7, "End Time (s)": 569.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "well emotion as it is it's emotion because as humans we are all kind of at everybody's different like my wife is on the extreme end, but we're all list makers. We're all making a categorized list in our head always about everything that's bigger than this. This is smaller than that that cost more than this <mark>and</mark> so that big number Something we're all benchmarking always. Yeah, this is why look I was this kid. This is why if you are 14 <mark>and</mark> you are dreaming about driving a car with a zero to 60 of 3.6 is significantly better than a car with the 0 to 60 of 3.8 just that it's just better. Yeah, it's better. It's better. Hey sis continuing. Yeah, <mark>and</mark> I'm talking from the position of loving horsepower. I do I love power. I also do love the power to weight. So it's not I don't have to have 600 horsepower. But if I've got like in my Cayman Hundred 350 in a three thousand pound car still pretty quick. I'm happy about that. Did you see that email a couple of weeks ago? We did it. We did a car debate here for a guy in Florida looking for a 500 plus horsepower <mark>and</mark> Karan. Yeah, he wrote back in response to what we had recommended <mark>and</mark> he laughed because he described me <mark>and</mark> I as I quote as the the guy that doesn't like horsepower <mark>and</mark> then he laughed about the fact that I said just get a Hellcat. So yeah, I am the guy that doesn't like horsepower <mark>and</mark> you were the guy that wants it which is one of the reasons that this works well. I don't think that's really true. I do think you love power, especially on track. I do think you love it. I was at the Lotus yesterday going this is perfect at this is tidy. Yeah. So the turbo is out. There's also the Alpine A110 Legend GT which now has warm Amber leather coating the inside surfaces <mark>and</mark> the safety belts. Finally. I know I don't know what they've been waiting for. So that car is definitely on our list to drive it sort of like the French build a game <mark>and</mark> that's what I'm all about driving. That car I cannot wait. Yeah, I think it's the middle car between a Cayman <mark>and</mark> a Lotus Elise. You think it might be the car that blends the two of you think it's the pollen dust those two carbon Adriana. Maybe it's not as powerful as", "Start Time (s)": 519.1, "End Time (s)": 638.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm happy about that. Did you see that email a couple of weeks ago? We did it. We did a car debate here for a guy in Florida looking for a 500 plus horsepower <mark>and</mark> Karan. Yeah, he wrote back in response to what we had recommended <mark>and</mark> he laughed because he described me <mark>and</mark> I as I quote as the the guy that doesn't like horsepower <mark>and</mark> then he laughed about the fact that I said just get a Hellcat. So yeah, I am the guy that doesn't like horsepower <mark>and</mark> you were the guy that wants it which is one of the reasons that this works well. I don't think that's really true. I do think you love power, especially on track. I do think you love it. I was at the Lotus yesterday going this is perfect at this is tidy. Yeah. So the turbo is out. There's also the Alpine A110 Legend GT which now has warm Amber leather coating the inside surfaces <mark>and</mark> the safety belts. Finally. I know I don't know what they've been waiting for. So that car is definitely on our list to drive it sort of like the French build a game <mark>and</mark> that's what I'm all about driving. That car I cannot wait. Yeah, I think it's the middle car between a Cayman <mark>and</mark> a Lotus Elise. You think it might be the car that blends the two of you think it's the pollen dust those two carbon Adriana. Maybe it's not as powerful as came <mark>and</mark> it's a step down its lighter, but it's more of a substantial car than Analyse <mark>and</mark> I think it's right in between. I think we both wanted the Alfa 4C to be that <mark>and</mark> it didn't quite get there. I agree with that variously. We are longer story here, but we are trying to get the Alpine A110 in an episode of TV or working. It will see where it goes that's on the list. There's a lot you realize honestly, you're not talk. That's recently. We are not only planning season seven. We already have talked about two episodes will be in season 8. It's just what we gotta dammit. It's all happened. It's really cool. All right, what else Aston Martin V12 Speedster, which is just luscious looking. I mean, I don't know that I ever needed or wanted but I just I love looking at cars that we need to look at cars on a daily basis. I don't know about you guys, but I need to just look at cars all the time daily basis. It's at a dealership in a magazine online. I don't care. Are any wasn't over there at cars here step into my garage or just look at", "Start Time (s)": 571.6, "End Time (s)": 690.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Alpine A110 in an episode of TV or working. It will see where it goes that's on the list. There's a lot you realize honestly, you're not talk. That's recently. We are not only planning season seven. We already have talked about two episodes will be in season 8. It's just what we gotta dammit. It's all happened. It's really cool. All right, what else Aston Martin V12 Speedster, which is just luscious looking. I mean, I don't know that I ever needed or wanted but I just I love looking at cars that we need to look at cars on a daily basis. I don't know about you guys, but I need to just look at cars all the time daily basis. It's at a dealership in a magazine online. I don't care. Are any wasn't over there at cars here step into my garage or just look at this is cooled or garage right now is the tools for the job. It's not bad. It's not somebody crazy. I'm thankful for that. Alright, so the crazy for seat 3-cylinder Koenigsegg Jumeirah Gamera Gamera. I don't know. Yeah. Wow, so Sasha sleeping of had a hand in developing this he's the designer that designed the Bugatti Chiron also spent some time at Genesis but has since joined Koenigsegg <mark>and</mark> on his Instagram is very proud of this new project. I'm astounded by its majority. I love Koenigsegg for just dropping something else that nobody expected <mark>and</mark> they're suddenly into four seats <mark>and</mark> we thought well, you can't do that because you're a fast sports car. Well for C. Let's go for C. <mark>And</mark> this is their first car they're doing with whatever their valveless technology. Is that the Christian working on forever <mark>and</mark> had his own Volvo. <mark>And</mark> so all of that is actually on on sale if you will in this car not like you're going to run down to your local dealer <mark>and</mark> get a but you know what I mean? There it is on a road car while being a four-seat rocket ship Chip with a price tag that there are they eight figures yet. I mean its just oh man their stuff is so crazy expensive. It's awesome. It's incredibly cool. But wow. Alright McLaren 765 long tail 755 horsepower not there better get better. But the McLaren 720 is already good <mark>and</mark> now there's the long tail flavor of its exactly okay, <mark>and</mark> then this car that I actually saw when I visited icon 4x4.", "Start Time (s)": 653.5, "End Time (s)": 773.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "had a hand in developing this he's the designer that designed the Bugatti Chiron also spent some time at Genesis but has since joined Koenigsegg <mark>and</mark> on his Instagram is very proud of this new project. I'm astounded by its majority. I love Koenigsegg for just dropping something else that nobody expected <mark>and</mark> they're suddenly into four seats <mark>and</mark> we thought well, you can't do that because you're a fast sports car. Well for C. Let's go for C. <mark>And</mark> this is their first car they're doing with whatever their valveless technology. Is that the Christian working on forever <mark>and</mark> had his own Volvo. <mark>And</mark> so all of that is actually on on sale if you will in this car not like you're going to run down to your local dealer <mark>and</mark> get a but you know what I mean? There it is on a road car while being a four-seat rocket ship Chip with a price tag that there are they eight figures yet. I mean its just oh man their stuff is so crazy expensive. It's awesome. It's incredibly cool. But wow. Alright McLaren 765 long tail 755 horsepower not there better get better. But the McLaren 720 is already good <mark>and</mark> now there's the long tail flavor of its exactly okay, <mark>and</mark> then this car that I actually saw when I visited icon 4x4. All right in 2016. You cannot leave. 2016 or 17? I can't remember. So I was there with with another group <mark>and</mark> came across their 1949 Mercury Coupe electric their stuffing a Tesla battery <mark>and</mark> power train into this thing as you know, icon 4x4 builds these derelicts their old looking cars, but they got modern underpinnings modern everything <mark>and</mark> the details are very finely crafted. You think that's just a dull looking piece of chrome would in fact, it's nipple waiting or you know that just Looks like old leather. No, that's ostrich skin. Everything's done at a crazy crazy high level in a car that looks like you pulled it out of a barn <mark>and</mark> you were lucky to get it started this morning. Well, which is you know, I think kind of cool. I kind of dig it. See I don't get it you would like the you <mark>and</mark> I separated. I have some just like really but okay, I like this because I saw it", "Start Time (s)": 705.7, "End Time (s)": 825.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "horsepower not there better get better. But the McLaren 720 is already good <mark>and</mark> now there's the long tail flavor of its exactly okay, <mark>and</mark> then this car that I actually saw when I visited icon 4x4. All right in 2016. You cannot leave. 2016 or 17? I can't remember. So I was there with with another group <mark>and</mark> came across their 1949 Mercury Coupe electric their stuffing a Tesla battery <mark>and</mark> power train into this thing as you know, icon 4x4 builds these derelicts their old looking cars, but they got modern underpinnings modern everything <mark>and</mark> the details are very finely crafted. You think that's just a dull looking piece of chrome would in fact, it's nipple waiting or you know that just Looks like old leather. No, that's ostrich skin. Everything's done at a crazy crazy high level in a car that looks like you pulled it out of a barn <mark>and</mark> you were lucky to get it started this morning. Well, which is you know, I think kind of cool. I kind of dig it. See I don't get it you would like the you <mark>and</mark> I separated. I have some just like really but okay, I like this because I saw it then <mark>and</mark> I thought oh this is going to be cool. They have milled Billet blocks into a V8 shape that are the powertrain monitoring systems <mark>and</mark> Not necessarily batteries, but they put that up front. So when you pop the hood you think well, that's a cool looking VA. No, it's not that's not an engine interesting. That's just electric component Justin. Yeah, they moved into aluminum polished blocks to make it look like that. <mark>And</mark> so they've hidden this eighty five kilowatt Tesla battery in the car <mark>and</mark> the powertrain as well <mark>and</mark> it gives you a hundred fifty to two hundred miles of range which is fine for big heavy car. But what I love is it resurrects old cars <mark>and</mark> they're not necessarily it's not really a restomod. Although I guess it kind of is but it's heavy batteries in a car. That was Heavy then <mark>and</mark> it looks heavy <mark>and</mark> it's surprising <mark>and</mark> it is a Rex resurrects old cars in a way that you never thought possible. That's what I love about. It keeps the", "Start Time (s)": 761.6, "End Time (s)": 880.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "out of a barn <mark>and</mark> you were lucky to get it started this morning. Well, which is you know, I think kind of cool. I kind of dig it. See I don't get it you would like the you <mark>and</mark> I separated. I have some just like really but okay, I like this because I saw it then <mark>and</mark> I thought oh this is going to be cool. They have milled Billet blocks into a V8 shape that are the powertrain monitoring systems <mark>and</mark> Not necessarily batteries, but they put that up front. So when you pop the hood you think well, that's a cool looking VA. No, it's not that's not an engine interesting. That's just electric component Justin. Yeah, they moved into aluminum polished blocks to make it look like that. <mark>And</mark> so they've hidden this eighty five kilowatt Tesla battery in the car <mark>and</mark> the powertrain as well <mark>and</mark> it gives you a hundred fifty to two hundred miles of range which is fine for big heavy car. But what I love is it resurrects old cars <mark>and</mark> they're not necessarily it's not really a restomod. Although I guess it kind of is but it's heavy batteries in a car. That was Heavy then <mark>and</mark> it looks heavy <mark>and</mark> it's surprising <mark>and</mark> it is a Rex resurrects old cars in a way that you never thought possible. That's what I love about. It keeps the old stuff going. I think it's going to be more. I think it's going to be more common that we're going to see I don't think Commons the wrong word. I think we're going to consistently see that happening to old cars people figure out how to take new Drive trains <mark>and</mark> I think electric is a prime idea <mark>and</mark> resurrect these gorgeous. Shapes <mark>and</mark> not have to worry about where do I get a part for that engine from 60? Forget it Rose. It doesn't I don't even care. It doesn't even matter anymore. I think that's going to become even more reality <mark>and</mark> just cool Silent Running. My brother-in-law had a 1950 Mercury. So I think he's going to be totally all about this but he's busy with sobs currently. So anyway, we've got to jump into the debate here. Yes as he with Subs. That's excellent. I like this. Yep. Cars are absolutely made to be driven <mark>and</mark> we can't imagine a future without driving the cars. We love the folks at Haggerty feel the same way. <mark>And</mark> that's why they support our show one of the many things", "Start Time (s)": 812.6, "End Time (s)": 932.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> they're not necessarily it's not really a restomod. Although I guess it kind of is but it's heavy batteries in a car. That was Heavy then <mark>and</mark> it looks heavy <mark>and</mark> it's surprising <mark>and</mark> it is a Rex resurrects old cars in a way that you never thought possible. That's what I love about. It keeps the old stuff going. I think it's going to be more. I think it's going to be more common that we're going to see I don't think Commons the wrong word. I think we're going to consistently see that happening to old cars people figure out how to take new Drive trains <mark>and</mark> I think electric is a prime idea <mark>and</mark> resurrect these gorgeous. Shapes <mark>and</mark> not have to worry about where do I get a part for that engine from 60? Forget it Rose. It doesn't I don't even care. It doesn't even matter anymore. I think that's going to become even more reality <mark>and</mark> just cool Silent Running. My brother-in-law had a 1950 Mercury. So I think he's going to be totally all about this but he's busy with sobs currently. So anyway, we've got to jump into the debate here. Yes as he with Subs. That's excellent. I like this. Yep. Cars are absolutely made to be driven <mark>and</mark> we can't imagine a future without driving the cars. We love the folks at Haggerty feel the same way. <mark>And</mark> that's why they support our show one of the many things Haggerty offers for people who love cars is insurance for enthusiasts Vehicles. This includes classic cars <mark>and</mark> trucks <mark>and</mark> motorcycles, but it also includes newer Collectibles <mark>and</mark> boats. They also protect vehicles that go on track that can be an actual race vehicle on <mark>and</mark> off the track or your personal vehicle on track for a high-performance driving day. Or attract a in fact we use Haggerty track-day Insurance. Every time we drive the Caiman or Lotus or any of our own cars on our local track. It has a huge piece of mind. You can learn more about Haggerty <mark>and</mark> quote insurance at Haggerty.com every day. Anthony be is in Denver <mark>and</mark> he says I got a car debate for you with hopes of purchasing both cars while we're still in the winter months here in Denver for potential offseason savings. You know, the joke Anthony. Did you buy the car then you didn't save money true. That's the old Joe. But but at the same time if you live in a winter", "Start Time (s)": 864.1, "End Time (s)": 983.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on track that can be an actual race vehicle on <mark>and</mark> off the track or your personal vehicle on track for a high-performance driving day. Or attract a in fact we use Haggerty track-day Insurance. Every time we drive the Caiman or Lotus or any of our own cars on our local track. It has a huge piece of mind. You can learn more about Haggerty <mark>and</mark> quote insurance at Haggerty.com every day. Anthony be is in Denver <mark>and</mark> he says I got a car debate for you with hopes of purchasing both cars while we're still in the winter months here in Denver for potential offseason savings. You know, the joke Anthony. Did you buy the car then you didn't save money true. That's the old Joe. But but at the same time if you live in a winter climate like we do or if you just don't you want to shop in a winter climate by a convertible in like February? Well, yeah, you'll get a deal that person needs to sell that corn. I need to sell that car. Yeah, right. He currently has a Lexus lx570. For everyday use but he's realizing it's too precious to do the things he needs it to hauling around too soon to be three hundred <mark>and</mark> twenty pound plus pound dogs <mark>and</mark> sitting in parking lots Like Home Depot. He has a hard time keeping cars for more than a year or two. Even when he says he will so we either need something really special that we're keeping cat food captivated or something that he won't take a bath on if he sells it in a year or two, but he tends to do better when keeping them when he has two cars. So that's where he's headed. Added his ICU cars <mark>and</mark> at the end of the spectrums of sacrifice, like both had a good. Yeah something big <mark>and</mark> heavy for the Home Depot runs the dogs the family all that kind of stuff, but I just want to say if you've got a Lexus lx570 <mark>and</mark> that's too precious. Can you coat the inside <mark>and</mark> covercraft car cover stuff the seat covers <mark>and</mark> the cargo it covers. Yeah <mark>and</mark> just not worry about it anymore. Could you yeah, but at least he could hear just as you thought I have to go there on level 1 he could because some of that stuff is borderline bulletproof <mark>and</mark> it would be awesome. Four dogs the problem with Anthony though is he just needs to move on he just moves on so much that he's", "Start Time (s)": 944.4, "End Time (s)": 1063.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "For everyday use but he's realizing it's too precious to do the things he needs it to hauling around too soon to be three hundred <mark>and</mark> twenty pound plus pound dogs <mark>and</mark> sitting in parking lots Like Home Depot. He has a hard time keeping cars for more than a year or two. Even when he says he will so we either need something really special that we're keeping cat food captivated or something that he won't take a bath on if he sells it in a year or two, but he tends to do better when keeping them when he has two cars. So that's where he's headed. Added his ICU cars <mark>and</mark> at the end of the spectrums of sacrifice, like both had a good. Yeah something big <mark>and</mark> heavy for the Home Depot runs the dogs the family all that kind of stuff, but I just want to say if you've got a Lexus lx570 <mark>and</mark> that's too precious. Can you coat the inside <mark>and</mark> covercraft car cover stuff the seat covers <mark>and</mark> the cargo it covers. Yeah <mark>and</mark> just not worry about it anymore. Could you yeah, but at least he could hear just as you thought I have to go there on level 1 he could because some of that stuff is borderline bulletproof <mark>and</mark> it would be awesome. Four dogs the problem with Anthony though is he just needs to move on he just moves on so much that he's realized he honestly I feel like he has positioned himself that the fact that it's too precious. Is that moving excuse for why I must move on the truth is he just wants to move on I guess so so but but the funny thing here is he's actually saying I've owned <mark>and</mark> he sent us a Carlos that honestly is maybe too long to even cover because it if you can think of a car Anthony's probably owned it. I pulled the highlights out. So we'll touch on some highlights insane. Yeah, but but he's talking about the fact that he's on Plenty of SUVs when he looks at this he realizes what I really need is tons of cargo space, right <mark>and</mark> the ability for dogs to be in it <mark>and</mark> it not damage anything <mark>and</mark> I don't care <mark>and</mark> so he's going should I just buy an old beater minivan? Well, he says do you think as a 40 year old executive? No kids we can make minivans cool again. No, he says I think", "Start Time (s)": 997.5, "End Time (s)": 1116.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "himself that the fact that it's too precious. Is that moving excuse for why I must move on the truth is he just wants to move on I guess so so but but the funny thing here is he's actually saying I've owned <mark>and</mark> he sent us a Carlos that honestly is maybe too long to even cover because it if you can think of a car Anthony's probably owned it. I pulled the highlights out. So we'll touch on some highlights insane. Yeah, but but he's talking about the fact that he's on Plenty of SUVs when he looks at this he realizes what I really need is tons of cargo space, right <mark>and</mark> the ability for dogs to be in it <mark>and</mark> it not damage anything <mark>and</mark> I don't care <mark>and</mark> so he's going should I just buy an old beater minivan? Well, he says do you think as a 40 year old executive? No kids we can make minivans cool again. No, he says I think it would do the job. You just need well. Yeah, but then you're still in a minivan. So I like your idea about a Ford Expedition EL. It's essentially the car that I've got the SUV that I've got <mark>and</mark> it's huge <mark>and</mark> lumbering <mark>and</mark> gobs of space. It's endless cavernous space in the back. <mark>And</mark> again anything you do by just cover with all those cargo liner from covercraft right? Then you won't worry about it. It doesn't matter you do it with a guy in Idaho with the Expedition. I've put the Cayenne one back at the Phaeton. It's amazing how well it did the dogs can hang out in the back seat of plus there now luxury. I've now shown Offering the dog. Yeah, so freeing the dogs put in the back of fate <mark>and</mark> it's absurd but you're right you could do all of that but just saying but here's the thing the van isn't a bad idea here. No, we can find one for you but act vanning. Yeah. Well, no, hang on hashtag ban life Lookout is a hole is a hole you want to talk about being he's in the middle of nowhere. Oh, wow, hashtag bad life. Yeah. Anyway, yeah, so that's going on but but you could do this <mark>and</mark> because the other thing about it is I wonder if you buy Minivan here. I am selling a minivan to this person. But if you buy like to hear this <mark>and</mark> you don't spend much money on it, but as a result, it just", "Start Time (s)": 1066.7, "End Time (s)": 1186.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "about a Ford Expedition EL. It's essentially the car that I've got the SUV that I've got <mark>and</mark> it's huge <mark>and</mark> lumbering <mark>and</mark> gobs of space. It's endless cavernous space in the back. <mark>And</mark> again anything you do by just cover with all those cargo liner from covercraft right? Then you won't worry about it. It doesn't matter you do it with a guy in Idaho with the Expedition. I've put the Cayenne one back at the Phaeton. It's amazing how well it did the dogs can hang out in the back seat of plus there now luxury. I've now shown Offering the dog. Yeah, so freeing the dogs put in the back of fate <mark>and</mark> it's absurd but you're right you could do all of that but just saying but here's the thing the van isn't a bad idea here. No, we can find one for you but act vanning. Yeah. Well, no, hang on hashtag ban life Lookout is a hole is a hole you want to talk about being he's in the middle of nowhere. Oh, wow, hashtag bad life. Yeah. Anyway, yeah, so that's going on but but you could do this <mark>and</mark> because the other thing about it is I wonder if you buy Minivan here. I am selling a minivan to this person. But if you buy like to hear this <mark>and</mark> you don't spend much money on it, but as a result, it just has that job. I think you're going to avoid any preciousness because you're going to think I have a minivan. Yeah, <mark>and</mark> so it because it what he's really needing is huge amounts of cargo space talk about a hundred cubic feet plus of cargo space be really wants that then I think it behooves you to buy the thing that is just you two. ility Because then K the dogs are muddy, it's fine like something you can hose out after you're done. Well Atlanta of whether whether it's got that or not. You just you're not you're not concerned about it. Yeah, <mark>and</mark> so I can see because he isn't as he admits. He's not a minivan guy a part of me goes perfect because I'll give you I'll give you a Counterpoint. I am not a big sedan guy. Mmm <mark>and</mark> yet every time I drive the fate <mark>and</mark> I got let me tell you five things that are great about this right here. Yeah, but is anybody a minivan guy or minivan person? Like I'm into minivan well, but see but I think I think there are plenty", "Start Time (s)": 1122.5, "End Time (s)": 1242.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "think you're going to avoid any preciousness because you're going to think I have a minivan. Yeah, <mark>and</mark> so it because it what he's really needing is huge amounts of cargo space talk about a hundred cubic feet plus of cargo space be really wants that then I think it behooves you to buy the thing that is just you two. ility Because then K the dogs are muddy, it's fine like something you can hose out after you're done. Well Atlanta of whether whether it's got that or not. You just you're not you're not concerned about it. Yeah, <mark>and</mark> so I can see because he isn't as he admits. He's not a minivan guy a part of me goes perfect because I'll give you I'll give you a Counterpoint. I am not a big sedan guy. Mmm <mark>and</mark> yet every time I drive the fate <mark>and</mark> I got let me tell you five things that are great about this right here. Yeah, but is anybody a minivan guy or minivan person? Like I'm into minivan well, but see but I think I think there are plenty of families that are not car people that will tell you all the things that are great about their Minivan <mark>and</mark> <mark>and</mark> their right <mark>and</mark> are absolutely right you <mark>and</mark> I the way we've used them on shoots where you practically open up the side door <mark>and</mark> Chuck the Pelican case from five feet away. I mean, this is what they're going for. So I actually am wondering since Anthony is a car guy. He's never owned one. He needs something that is just utility Part of Me Goes by it. You won't be precious at all. The dogs will love you <mark>and</mark> the Home Depot runs can get even bigger <mark>and</mark> oops the 2x4 went through that side window. I'll get it fixed eventually, you know what? I mean? Duct tape <mark>and</mark> some plastic sheeting. We're good the that has that has carried many cars from any I don't recommend this but there's a whole fenders made of that stuff. Yeah. Okay. Alright. Well, I'm not all the way there in the minivan thing because I still want you to like driving whatever that is. <mark>And</mark> even if it's a giant SUV, I still think it's going to be better than a minivan personally. I see. Hey, the the AI Justin's going to be rear-wheel drive. It has it has decent ride to it. Yours has a great ride to it. It does I do an upgraded to bills teens on it <mark>and</mark> it's actually even tighter with the summer wheels <mark>and</mark> tires on it. It's spry as the wrong word. It's the wrong word.", "Start Time (s)": 1188.8, "End Time (s)": 1308.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that are not car people that will tell you all the things that are great about their Minivan <mark>and</mark> <mark>and</mark> their right <mark>and</mark> are absolutely right you <mark>and</mark> I the way we've used them on shoots where you practically open up the side door <mark>and</mark> Chuck the Pelican case from five feet away. I mean, this is what they're going for. So I actually am wondering since Anthony is a car guy. He's never owned one. He needs something that is just utility Part of Me Goes by it. You won't be precious at all. The dogs will love you <mark>and</mark> the Home Depot runs can get even bigger <mark>and</mark> oops the 2x4 went through that side window. I'll get it fixed eventually, you know what? I mean? Duct tape <mark>and</mark> some plastic sheeting. We're good the that has that has carried many cars from any I don't recommend this but there's a whole fenders made of that stuff. Yeah. Okay. Alright. Well, I'm not all the way there in the minivan thing because I still want you to like driving whatever that is. <mark>And</mark> even if it's a giant SUV, I still think it's going to be better than a minivan personally. I see. Hey, the the AI Justin's going to be rear-wheel drive. It has it has decent ride to it. Yours has a great ride to it. It does I do an upgraded to bills teens on it <mark>and</mark> it's actually even tighter with the summer wheels <mark>and</mark> tires on it. It's spry as the wrong word. It's the wrong word. But but it it's a little bit lighter on its feet. Maybe it's that it's the largest linebacker. I'm going to sports reference is the largest linebacker on the line that everybody goes he moves really well for a big guy. It's that car. Yeah, I guess so. Yeah it is. All right, so on Other end of the spectrum he wants something convertible preferably manual transmission. He's got six foot to 225 broad shoulders. He doesn't fit well in the small stuff <mark>and</mark> I hear you on that but as you've seen between Todd <mark>and</mark> I I'm all legs. He's all torso. So that is in my opinion more important because of the length where your seating position is <mark>and</mark> your torso because that definitely affects your head space your head room in the car rather than your width necessarily I think with is a little bit easier to deal with <mark>and</mark> a lot of seats rather than the The the spine height torso right. Now. If your head is touching you're just you're just unhappy. That's true. Yeah, so he says doesn't fit well in the small stuff the", "Start Time (s)": 1243.8, "End Time (s)": 1362.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "than a minivan personally. I see. Hey, the the AI Justin's going to be rear-wheel drive. It has it has decent ride to it. Yours has a great ride to it. It does I do an upgraded to bills teens on it <mark>and</mark> it's actually even tighter with the summer wheels <mark>and</mark> tires on it. It's spry as the wrong word. It's the wrong word. But but it it's a little bit lighter on its feet. Maybe it's that it's the largest linebacker. I'm going to sports reference is the largest linebacker on the line that everybody goes he moves really well for a big guy. It's that car. Yeah, I guess so. Yeah it is. All right, so on Other end of the spectrum he wants something convertible preferably manual transmission. He's got six foot to 225 broad shoulders. He doesn't fit well in the small stuff <mark>and</mark> I hear you on that but as you've seen between Todd <mark>and</mark> I I'm all legs. He's all torso. So that is in my opinion more important because of the length where your seating position is <mark>and</mark> your torso because that definitely affects your head space your head room in the car rather than your width necessarily I think with is a little bit easier to deal with <mark>and</mark> a lot of seats rather than the The the spine height torso right. Now. If your head is touching you're just you're just unhappy. That's true. Yeah, so he says doesn't fit well in the small stuff the Miata like Scoops, even the Focus RS all made him claustrophobic. Okay fair enough, he would drive it daily as much as possible. So it can't be full Lotus crazy. That's the shirt. I blowed his crazy full Lotus crazy. He'd love to carve canyons <mark>and</mark> maybe track at once in a while. <mark>And</mark> he says I'm not in a midlife crisis no matter what his fiancee says, so he doesn't know about considering the vet. There's been a conversation. Do you hear the conversation behind? It's I'm not no matter what my fiance says. I am not having a bit life crisis. You're in an almost crisis. Like the rest of you are you're in a just yeah cars forever. Yep. He says I've tried to explain to her. This is a disease of had for 25 years has she has she seen this car list. This is not a new problem. I'm guessing she's experienced some of them to high fiance. By the way. If you haven't seen it yet have him show you his car list of these are the cars. I've owned. Hmm because II probably bet you it's probably dwarfed in just", "Start Time (s)": 1293.2, "End Time (s)": 1413.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so he says doesn't fit well in the small stuff the Miata like Scoops, even the Focus RS all made him claustrophobic. Okay fair enough, he would drive it daily as much as possible. So it can't be full Lotus crazy. That's the shirt. I blowed his crazy full Lotus crazy. He'd love to carve canyons <mark>and</mark> maybe track at once in a while. <mark>And</mark> he says I'm not in a midlife crisis no matter what his fiancee says, so he doesn't know about considering the vet. There's been a conversation. Do you hear the conversation behind? It's I'm not no matter what my fiance says. I am not having a bit life crisis. You're in an almost crisis. Like the rest of you are you're in a just yeah cars forever. Yep. He says I've tried to explain to her. This is a disease of had for 25 years has she has she seen this car list. This is not a new problem. I'm guessing she's experienced some of them to high fiance. By the way. If you haven't seen it yet have him show you his car list of these are the cars. I've owned. Hmm because II probably bet you it's probably dwarfed in just sheer number forget variety probably do warped anyone. She's known probably probably haven't you have a card disease my friend <mark>and</mark> <mark>and</mark> we're not here to cure it. We're just here to encourage you to go. Yep. That's a bad case. There it is. For sure. Alright, well here is the Crux of the debate <mark>and</mark> that is assuming he pays cash for the van <mark>and</mark> of the spectrum does he spend 30 to $35,000 Max? He's looking at me with a car loan on something like a 981 Boxster S or an early 997 Cabriolet or something else or does he spend 15 grand or less with no car loan <mark>and</mark> get something old. Our higher mileage that he can just drive. It's already taken the residual hit. He says he mentions a Honda S2000 which he seems to fit in. Yeah or something more GT like like a Mercedes SL Ali-A 5S V something like that. He's had a Boxster 986 not a fan of The Styling on the nine eight seven so we can take those off <mark>and</mark> he doesn't like Camaros or Mustang. So those are off to or does he go back to his roots <mark>and</mark> find a nice z32 300ZX again Anthony's all those owned three Three 1990s by the way, three in this giant", "Start Time (s)": 1360.1, "End Time (s)": 1479.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you to go. Yep. That's a bad case. There it is. For sure. Alright, well here is the Crux of the debate <mark>and</mark> that is assuming he pays cash for the van <mark>and</mark> of the spectrum does he spend 30 to $35,000 Max? He's looking at me with a car loan on something like a 981 Boxster S or an early 997 Cabriolet or something else or does he spend 15 grand or less with no car loan <mark>and</mark> get something old. Our higher mileage that he can just drive. It's already taken the residual hit. He says he mentions a Honda S2000 which he seems to fit in. Yeah or something more GT like like a Mercedes SL Ali-A 5S V something like that. He's had a Boxster 986 not a fan of The Styling on the nine eight seven so we can take those off <mark>and</mark> he doesn't like Camaros or Mustang. So those are off to or does he go back to his roots <mark>and</mark> find a nice z32 300ZX again Anthony's all those owned three Three 1990s by the way, three in this giant crab 1990s a black one a red one <mark>and</mark> a yellow one. <mark>And</mark> the thing is up into 96 1996 but the 91 to 95 they were steadily being refined. The 90s are kind of the I'm wrong. I had one the I-90 of the Oddball wears like you need this part unless you have a 90 <mark>and</mark> now you need this part. So I think it's actually the Reason Not only own three, but he's owned three 1990s of that car. I have to say it again. I think I love it. I would like to have another one if I have you know some massive garage. Let's hope so. I have some massive garage with a bunch of cars in a like a 300ZX to be in there, but I still think you should move on. I think we should not get another one of those some other highlights on the list are in 87 Supra. He's had a Lexus SC 430 Sadie's SLK. He said an LS 400 the accurate EXs wagon, <mark>and</mark> he's also had Porsche cayennes Jeep Wranglers for excursions for a bigger than the Expedition <mark>and</mark> he's also had multiple Porsches 911 2009-11 to 911 yeah, honestly, it's all on this list. I'll be the range is incredible <mark>and</mark> there's a lot of stuff on here", "Start Time (s)": 1422.4, "End Time (s)": 1541.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "1990s a black one a red one <mark>and</mark> a yellow one. <mark>And</mark> the thing is up into 96 1996 but the 91 to 95 they were steadily being refined. The 90s are kind of the I'm wrong. I had one the I-90 of the Oddball wears like you need this part unless you have a 90 <mark>and</mark> now you need this part. So I think it's actually the Reason Not only own three, but he's owned three 1990s of that car. I have to say it again. I think I love it. I would like to have another one if I have you know some massive garage. Let's hope so. I have some massive garage with a bunch of cars in a like a 300ZX to be in there, but I still think you should move on. I think we should not get another one of those some other highlights on the list are in 87 Supra. He's had a Lexus SC 430 Sadie's SLK. He said an LS 400 the accurate EXs wagon, <mark>and</mark> he's also had Porsche cayennes Jeep Wranglers for excursions for a bigger than the Expedition <mark>and</mark> he's also had multiple Porsches 911 2009-11 to 911 yeah, honestly, it's all on this list. I'll be the range is incredible <mark>and</mark> there's a lot of stuff on here that enthusiasts will just dig into <mark>and</mark> just by I'll give an example Toyota Land Cruiser. There's people that just by Land Cruisers, they bought nothing but a Land Cruiser ever. He's had them. Yeah, you know what? I mean? He's covered all kinds of Audi Allroad. Yep. It's in here to I mean it's over <mark>and</mark> over again <mark>and</mark> a lot of things he keeps cycling back to as well. Like there's more than one Land Cruiser on here. Hmm <mark>and</mark> so it's interesting. I love that you keep changing cars as much. I wish we could all do this this fast. No kid had the problem. We have to try to solve it for a little bit. Well that leads me to this serious conversation. We need to have Anthony about leasing versus your high turnover buying because that cost just as much in terms of tax title <mark>and</mark> registration. If you do the high turnover buying thing plus you're losing money every time you know, how there's some amount down for leasing. We've got to have 3,000 down plus. Yeah, however much mantor 5,000 down sure that's almost as much as you're already paying each time you do the tax title <mark>and</mark> registration interest. I know. You still have to do that with the least car too? Yeah, but I'm wondering is leasing for you because", "Start Time (s)": 1480.1, "End Time (s)": 1600.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to 911 yeah, honestly, it's all on this list. I'll be the range is incredible <mark>and</mark> there's a lot of stuff on here that enthusiasts will just dig into <mark>and</mark> just by I'll give an example Toyota Land Cruiser. There's people that just by Land Cruisers, they bought nothing but a Land Cruiser ever. He's had them. Yeah, you know what? I mean? He's covered all kinds of Audi Allroad. Yep. It's in here to I mean it's over <mark>and</mark> over again <mark>and</mark> a lot of things he keeps cycling back to as well. Like there's more than one Land Cruiser on here. Hmm <mark>and</mark> so it's interesting. I love that you keep changing cars as much. I wish we could all do this this fast. No kid had the problem. We have to try to solve it for a little bit. Well that leads me to this serious conversation. We need to have Anthony about leasing versus your high turnover buying because that cost just as much in terms of tax title <mark>and</mark> registration. If you do the high turnover buying thing plus you're losing money every time you know, how there's some amount down for leasing. We've got to have 3,000 down plus. Yeah, however much mantor 5,000 down sure that's almost as much as you're already paying each time you do the tax title <mark>and</mark> registration interest. I know. You still have to do that with the least car too? Yeah, but I'm wondering is leasing for you because you do rocket through cars. It's a serious question <mark>and</mark> could it be? Yeah, the monthly of you're throwing down for 35 cash. I wonder if the payment the down payment the payment would be doing per month. You actually might be able to something that's a little bit higher. I like where you're going. I do. Well, I'm just wondering will this turn over disease continued or can you begin to live with a car longer than three to five years you're living with them for two or so I'm asking three two. I've at stretching Anthony. But yeah, but if we're going for full spectrum of sacrifice, I like where you're going. The van is fine. The Expedition is fine. How about let's push it further on that Spectrum more sacrificial to like a Defender 90 or Defender 110 or an old Toyota fj40 problem is it's not nearly enough space for what he wants <mark>and</mark> I think he'd wind up feeling a bit precious about it. That's the issue dogs in the back <mark>and</mark> the lumber in the back <mark>and</mark> I think he's gonna be like do I", "Start Time (s)": 1534.7, "End Time (s)": 1653.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "plus. Yeah, however much mantor 5,000 down sure that's almost as much as you're already paying each time you do the tax title <mark>and</mark> registration interest. I know. You still have to do that with the least car too? Yeah, but I'm wondering is leasing for you because you do rocket through cars. It's a serious question <mark>and</mark> could it be? Yeah, the monthly of you're throwing down for 35 cash. I wonder if the payment the down payment the payment would be doing per month. You actually might be able to something that's a little bit higher. I like where you're going. I do. Well, I'm just wondering will this turn over disease continued or can you begin to live with a car longer than three to five years you're living with them for two or so I'm asking three two. I've at stretching Anthony. But yeah, but if we're going for full spectrum of sacrifice, I like where you're going. The van is fine. The Expedition is fine. How about let's push it further on that Spectrum more sacrificial to like a Defender 90 or Defender 110 or an old Toyota fj40 problem is it's not nearly enough space for what he wants <mark>and</mark> I think he'd wind up feeling a bit precious about it. That's the issue dogs in the back <mark>and</mark> the lumber in the back <mark>and</mark> I think he's gonna be like do I want to do this with this? Car, okay. Alright. So because I like it I like it <mark>and</mark> it would be a very new experience for him. But I think the preciousness factor would creep in then how about a Tahoe or an Expedition or just something like that with plenty of space <mark>and</mark> you can beat on it. You won't worry about it <mark>and</mark> it'll run it'll be cheap to fix it. Let's just do that. Just go back on Suburbans until you hit the exact spectrum of the amount you want to spend <mark>and</mark> your budget versus the year just try to find it because if you're going to look at Expeditions, you should look at the at the big suburban <mark>and</mark> they've made them forever. Like a travel all from the sixties, it's craziness. Yeah something but I want to focus on the other end of the spectrum <mark>and</mark> I love that you like the nine eight ones you've considered those <mark>and</mark> I highly recommend the nine eight one just base came in if you can get into that. I think you'd love it, but I don't think it's sacrificial enough for what you're looking for because of your list. It's", "Start Time (s)": 1586.9, "End Time (s)": 1706.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that. Just go back on Suburbans until you hit the exact spectrum of the amount you want to spend <mark>and</mark> your budget versus the year just try to find it because if you're going to look at Expeditions, you should look at the at the big suburban <mark>and</mark> they've made them forever. Like a travel all from the sixties, it's craziness. Yeah something but I want to focus on the other end of the spectrum <mark>and</mark> I love that you like the nine eight ones you've considered those <mark>and</mark> I highly recommend the nine eight one just base came in if you can get into that. I think you'd love it, but I don't think it's sacrificial enough for what you're looking for because of your list. It's not like you're just starting out trying cars. You've had a number of cars big-time sick. So many more than many people. So, how about I think I do have your car but I'm going to get there first. Okay, some of them are kind of half joking like a factory five eight one eight. I have some fun ones to break up for Anthony to yeah. How about a flying Miata are a monster Miata? Sure. Yeah, <mark>and</mark> that's extreme. What a Morgan three-wheeler. That's just different <mark>and</mark> extreme. He's going to fit in the Morgan 3 Wheeler because 3/4 of your body is out of the car. Yeah. I mean, I'm half Siri I see where you are yet. Okay, get more serious. How about a 427 Cobra replica? You want raw you want horsepower you want? Yeah, no sound deadening <mark>and</mark> the pipes are next to your ears. How about a cobra replica honest sure sure sure fast it'll take your head off. I don't care what year what replica doesn't matter who builds it get one for 35 Holy Moly. Okay, but then we need to start going towards the Lotus Esprit use of the world. Could you get one for sure? Could you get a noble 400 something for that kind of money? Okay different. Sacrificial. Hey the first generation Viper RT 10 is sacrificial. Yeah. I mean when your windows have zippers on them, you know your kind of sacrificing a few things Viper Wrangler. What do they have in common but the car I think you should consider the", "Start Time (s)": 1671.4, "End Time (s)": 1791.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because 3/4 of your body is out of the car. Yeah. I mean, I'm half Siri I see where you are yet. Okay, get more serious. How about a 427 Cobra replica? You want raw you want horsepower you want? Yeah, no sound deadening <mark>and</mark> the pipes are next to your ears. How about a cobra replica honest sure sure sure fast it'll take your head off. I don't care what year what replica doesn't matter who builds it get one for 35 Holy Moly. Okay, but then we need to start going towards the Lotus Esprit use of the world. Could you get one for sure? Could you get a noble 400 something for that kind of money? Okay different. Sacrificial. Hey the first generation Viper RT 10 is sacrificial. Yeah. I mean when your windows have zippers on them, you know your kind of sacrificing a few things Viper Wrangler. What do they have in common but the car I think you should consider the most to my not Chagrin wrong word. But to my I guess it kind of depends on what you want to do <mark>and</mark> how you like it the Alfa 4C. You need to go drive it if you're just tracking it once in awhile fine, if Doing track Duty with it. I would suggest something else. I agree with that kind of driving you want. It's got a carbon chassis. It's got plenty of power will feel raw, but it's a modern enough car. <mark>And</mark> I think the prices are down where you could spring from one interest is different enough from everything else. You've had I think four C is your car it because you're right. It's not full Lotus crazy. No <mark>and</mark> <mark>and</mark> the place where that car shines is as a spider. Yes. Yes on a back road <mark>and</mark> it's still just sacrificial enough. It's Not super practical but you could try to make it work for errands <mark>and</mark> a few things but then you've got the Tahoe over here or whatever because because on a track as a hardtop, it's not as good as it needs to be. Yeah trying to drive that. We've talked about it up one side <mark>and</mark> down the other tribe drive it as hard as you can possibly drive it. You're not going to like it enough. But watch our Pacific Coast Highway peace, when we first drove the spider it was perfect. It was perfect <mark>and</mark> it was it was perfect on", "Start Time (s)": 1738.5, "End Time (s)": 1858.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I guess it kind of depends on what you want to do <mark>and</mark> how you like it the Alfa 4C. You need to go drive it if you're just tracking it once in awhile fine, if Doing track Duty with it. I would suggest something else. I agree with that kind of driving you want. It's got a carbon chassis. It's got plenty of power will feel raw, but it's a modern enough car. <mark>And</mark> I think the prices are down where you could spring from one interest is different enough from everything else. You've had I think four C is your car it because you're right. It's not full Lotus crazy. No <mark>and</mark> <mark>and</mark> the place where that car shines is as a spider. Yes. Yes on a back road <mark>and</mark> it's still just sacrificial enough. It's Not super practical but you could try to make it work for errands <mark>and</mark> a few things but then you've got the Tahoe over here or whatever because because on a track as a hardtop, it's not as good as it needs to be. Yeah trying to drive that. We've talked about it up one side <mark>and</mark> down the other tribe drive it as hard as you can possibly drive it. You're not going to like it enough. But watch our Pacific Coast Highway peace, when we first drove the spider it was perfect. It was perfect <mark>and</mark> it was it was perfect on we had a gorgeous day. We're going plenty quickly, but neither one of us were trying to drive as hard as we could <mark>and</mark> we just thought This everything's aligned his car just clicks right here. How I do like that about it. That's really good. Just a verbal things your mother almost daschle. I have I have a wild card for your van idea. Okay. All right. I really like guys <mark>and</mark> you're gonna all think I'm insane. He wants a hundred cubic feet of cargo space. It almost has. Oh, it's in the mid-90s. It's like 93-95 cubic feet of space garbage cart. I'm bracing for impact because here's what think you've never owned anything like this. It's a conversation. Sensation starter, they're ridiculously cheap <mark>and</mark> you're not going to feel precious about it at all. Get yourself a Pontiac Aztek. You didn't go minivan what go with me here. You didn't come minivan listening. But this is a ridiculously bad car that it enthusiasts will strike up a conversation with you at a gas station. You're not going to buy any minivan on the on the planet to have a conversation at a gas", "Start Time (s)": 1797.0, "End Time (s)": 1916.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hard as we could <mark>and</mark> we just thought This everything's aligned his car just clicks right here. How I do like that about it. That's really good. Just a verbal things your mother almost daschle. I have I have a wild card for your van idea. Okay. All right. I really like guys <mark>and</mark> you're gonna all think I'm insane. He wants a hundred cubic feet of cargo space. It almost has. Oh, it's in the mid-90s. It's like 93-95 cubic feet of space garbage cart. I'm bracing for impact because here's what think you've never owned anything like this. It's a conversation. Sensation starter, they're ridiculously cheap <mark>and</mark> you're not going to feel precious about it at all. Get yourself a Pontiac Aztek. You didn't go minivan what go with me here. You didn't come minivan listening. But this is a ridiculously bad car that it enthusiasts will strike up a conversation with you at a gas station. You're not going to buy any minivan on the on the planet to have a conversation at a gas station. You could take your clapped-out run down dog mud-covered Aztec to a Cars & Coffee <mark>and</mark> have a blast. Your minivan, it's gonna be like, why did you bring that thing? You see them saying? He's such a car guy that I wonder if Anthony buys kind of for the usability <mark>and</mark> kind of for the laughs an Aztec <mark>and</mark> just use it for the stuff. Wow. This is not sacrificial. This is the antithetical car. Would you see what I'm saying? Everything is it can actually do what he needs it to do but it's got enough of a I can't believe I own this laughs factor that I think you might actually like it in a way you don't like the van I actually Actually like this idea in a weird way. I knew you would I actually really like it that mean to say that that you're kind of going wait. I'm actually like it a lot. So Anthony there's my wild card for you on the van side is just go buy yourself a nice deck <mark>and</mark> just take the rear seat out leave it out. It becomes your dog. Holler Lumber hauler <mark>and</mark> also laugh Riot. I mean, it's the conversation starter <mark>and</mark> stopper but the fun to be had <mark>and</mark> the conversations to be had only <mark>and</mark> the bead on quality of that thing. You'll never care about it.", "Start Time (s)": 1863.4, "End Time (s)": 1983.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not going to buy any minivan on the on the planet to have a conversation at a gas station. You could take your clapped-out run down dog mud-covered Aztec to a Cars & Coffee <mark>and</mark> have a blast. Your minivan, it's gonna be like, why did you bring that thing? You see them saying? He's such a car guy that I wonder if Anthony buys kind of for the usability <mark>and</mark> kind of for the laughs an Aztec <mark>and</mark> just use it for the stuff. Wow. This is not sacrificial. This is the antithetical car. Would you see what I'm saying? Everything is it can actually do what he needs it to do but it's got enough of a I can't believe I own this laughs factor that I think you might actually like it in a way you don't like the van I actually Actually like this idea in a weird way. I knew you would I actually really like it that mean to say that that you're kind of going wait. I'm actually like it a lot. So Anthony there's my wild card for you on the van side is just go buy yourself a nice deck <mark>and</mark> just take the rear seat out leave it out. It becomes your dog. Holler Lumber hauler <mark>and</mark> also laugh Riot. I mean, it's the conversation starter <mark>and</mark> stopper but the fun to be had <mark>and</mark> the conversations to be had only <mark>and</mark> the bead on quality of that thing. You'll never care about it. Here's the thing, which is what Love the minute. They stopped selling knew I was still living in Los Angeles <mark>and</mark> they vanished <mark>and</mark> I moved here like five years later. <mark>And</mark> the first time it snowed I saw like six that they all still are out here <mark>and</mark> they're being used like this as winter beater cars every year my fate <mark>and</mark> my first fate <mark>and</mark> peace that we post them on YouTube the the end of that piece I talk comment about the fact that I happen to just in the wild pulled up behind a guy in an Aztec. Right? Right. So I'm putting it out there as my wild card for the For the utility car this leaves more money to spend on the other end of the spectrum <mark>and</mark> that he had probably does because they're going to be cheap are going to be like five six great <mark>and</mark> yeah, they might give you money to take it away. Please take my stick. I'll pay you <mark>and</mark> it's GM parts to it's not like that's the thing about it. It's not bought something that nobody's making parts for I mean body panels.", "Start Time (s)": 1913.7, "End Time (s)": 2033.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "seat out leave it out. It becomes your dog. Holler Lumber hauler <mark>and</mark> also laugh Riot. I mean, it's the conversation starter <mark>and</mark> stopper but the fun to be had <mark>and</mark> the conversations to be had only <mark>and</mark> the bead on quality of that thing. You'll never care about it. Here's the thing, which is what Love the minute. They stopped selling knew I was still living in Los Angeles <mark>and</mark> they vanished <mark>and</mark> I moved here like five years later. <mark>And</mark> the first time it snowed I saw like six that they all still are out here <mark>and</mark> they're being used like this as winter beater cars every year my fate <mark>and</mark> my first fate <mark>and</mark> peace that we post them on YouTube the the end of that piece I talk comment about the fact that I happen to just in the wild pulled up behind a guy in an Aztec. Right? Right. So I'm putting it out there as my wild card for the For the utility car this leaves more money to spend on the other end of the spectrum <mark>and</mark> that he had probably does because they're going to be cheap are going to be like five six great <mark>and</mark> yeah, they might give you money to take it away. Please take my stick. I'll pay you <mark>and</mark> it's GM parts to it's not like that's the thing about it. It's not bought something that nobody's making parts for I mean body panels. Thank God. No, but but otherwise, so anyway, there's my thought this is historic moment. We've never recommended an Aztec ever. This is a historic podcast. Yes. There you go. So wow, like the S2000 I like that as well. I am going to say too. Cars that are hardtop that I think you should consider though. Okay, the 86 you've never owned anything in that range get yourself a Scion FR-S <mark>and</mark> Subaru BRZ. Those are big guy cars big guys fit really well in those cars <mark>and</mark> they are just fun to drive <mark>and</mark> it has a lot of the lotus style about it, but much more usable. I think you'd like that car <mark>and</mark> drive it a lot. I also wonder if maybe one of those people worse like I'm going to throw a supercharger on this <mark>and</mark> love it. It's 86 is on there another one you could get for your money. We don't normally Commend because the problem I have with it is it's way too expensive new but they're out there used now <mark>and</mark> you want to go a little hardcore <mark>and</mark> different <mark>and</mark> new experience <mark>and</mark> you have Nissan in your background get yourself a 370 nice Mo.", "Start Time (s)": 1967.1, "End Time (s)": 2086.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "does because they're going to be cheap are going to be like five six great <mark>and</mark> yeah, they might give you money to take it away. Please take my stick. I'll pay you <mark>and</mark> it's GM parts to it's not like that's the thing about it. It's not bought something that nobody's making parts for I mean body panels. Thank God. No, but but otherwise, so anyway, there's my thought this is historic moment. We've never recommended an Aztec ever. This is a historic podcast. Yes. There you go. So wow, like the S2000 I like that as well. I am going to say too. Cars that are hardtop that I think you should consider though. Okay, the 86 you've never owned anything in that range get yourself a Scion FR-S <mark>and</mark> Subaru BRZ. Those are big guy cars big guys fit really well in those cars <mark>and</mark> they are just fun to drive <mark>and</mark> it has a lot of the lotus style about it, but much more usable. I think you'd like that car <mark>and</mark> drive it a lot. I also wonder if maybe one of those people worse like I'm going to throw a supercharger on this <mark>and</mark> love it. It's 86 is on there another one you could get for your money. We don't normally Commend because the problem I have with it is it's way too expensive new but they're out there used now <mark>and</mark> you want to go a little hardcore <mark>and</mark> different <mark>and</mark> new experience <mark>and</mark> you have Nissan in your background get yourself a 370 nice Mo. Okay. Okay a too expensive new but every time you every time we've driven one, I mean literally we're like pull out of the pit onto the track were like, this is really well done. Yeah, it does stand up even though we all want a new one <mark>and</mark> it needs to be refreshed but it does stand up <mark>and</mark> the nice MO is really really well sorted so An actual full mismo 370Z. Those are my two hard hard top versions <mark>and</mark> then my other one in the convertible range. You could get yourself a Jaguar F-Type. Oh, yes. Yes the Jag that's they're out there convertible. They're nice. They run Jaguar F-Type. Have a nice day. Here's the thing Jaguar F-Type park next to your Pontiac Aztek in your garage, or maybe the other ones. We've mentioned the Alfa 4C next year as to it. Just works tell me it doesn't work Anthony. Where longtime users <mark>and</mark> big Believers in grows garage car care products, that's because while many other brands are just rebranded", "Start Time (s)": 2019.4, "End Time (s)": 2139.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We don't normally Commend because the problem I have with it is it's way too expensive new but they're out there used now <mark>and</mark> you want to go a little hardcore <mark>and</mark> different <mark>and</mark> new experience <mark>and</mark> you have Nissan in your background get yourself a 370 nice Mo. Okay. Okay a too expensive new but every time you every time we've driven one, I mean literally we're like pull out of the pit onto the track were like, this is really well done. Yeah, it does stand up even though we all want a new one <mark>and</mark> it needs to be refreshed but it does stand up <mark>and</mark> the nice MO is really really well sorted so An actual full mismo 370Z. Those are my two hard hard top versions <mark>and</mark> then my other one in the convertible range. You could get yourself a Jaguar F-Type. Oh, yes. Yes the Jag that's they're out there convertible. They're nice. They run Jaguar F-Type. Have a nice day. Here's the thing Jaguar F-Type park next to your Pontiac Aztek in your garage, or maybe the other ones. We've mentioned the Alfa 4C next year as to it. Just works tell me it doesn't work Anthony. Where longtime users <mark>and</mark> big Believers in grows garage car care products, that's because while many other brands are just rebranded versions of the same few products grills garage has developed manufactured <mark>and</mark> bottled bespoke car care products since 1990. In fact, many of their first customers were collector cars displayed at Pebble Beach Rio's is a family company based in Washington state still dedicated to having the best products for every car in every budget. It's a matter of fact. I learned my certified Pol own car care style from crios. Both used grills garage car care products on our own cars for over 20 years <mark>and</mark> we wouldn't use anything else. If you're wondering how to get going. They offer free training <mark>and</mark> techniques through their videos <mark>and</mark> website <mark>and</mark> starter kits to help your car. Look its best grills garage products are 100% guaranteed <mark>and</mark> I'll liquid products are made in the USA. They offer a 100% lifetime guarantee. So give them a try when you're ordering a grills garage.com use the code every day for ten percent off your order. Enjoy. The finest Quality Car Care Products. You can buy at grills garage. cam", "Start Time (s)": 2074.1, "End Time (s)": 2192.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "grills garage has developed manufactured <mark>and</mark> bottled bespoke car care products since 1990. In fact, many of their first customers were collector cars displayed at Pebble Beach Rio's is a family company based in Washington state still dedicated to having the best products for every car in every budget. It's a matter of fact. I learned my certified Pol own car care style from crios. Both used grills garage car care products on our own cars for over 20 years <mark>and</mark> we wouldn't use anything else. If you're wondering how to get going. They offer free training <mark>and</mark> techniques through their videos <mark>and</mark> website <mark>and</mark> starter kits to help your car. Look its best grills garage products are 100% guaranteed <mark>and</mark> I'll liquid products are made in the USA. They offer a 100% lifetime guarantee. So give them a try when you're ordering a grills garage.com use the code every day for ten percent off your order. Enjoy. The finest Quality Car Care Products. You can buy at grills garage. cam Dennis F rights to us with lists of Hondas that he loves Dennis is a Honda person through <mark>and</mark> through he has multiple. He's actually currently restomod a 96 Prelude which caught my eye dentist because I've never heard of anybody rest am adding a Prelude that didn't seem like a normal sentence construction. But okay <mark>and</mark> I want to see photos. What are you putting in it? What's going on? Is this Honda parts? That's like an NSX engine going in a Prelude <mark>and</mark> you're creating some sort of monster thing that nobody's ever thought of is it the all wheel drive system? From some Acura <mark>and</mark> you're dumping that there you go. What is this? Carbon Prelude with the super handling all-wheel drive. That would actually be a cool build like how much money are you pouring at? This that concerned? You could leave money left over so we can buy more cars for well, but here's the thing. He's restomod in one because his wife drives a 99 Prelude He restored prior. Wow. All right, so currently he's saving to replace his aging Honda Element with a ridge line, but he fears that he's missing out on the S2000 those cars are not the same <mark>and</mark> he's also Tempted to blow his savings on an R SX s. Okay Honda through <mark>and</mark> through <mark>and</mark> inaccurate. That's", "Start Time (s)": 2140.8, "End Time (s)": 2260.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Dennis F rights to us with lists of Hondas that he loves Dennis is a Honda person through <mark>and</mark> through he has multiple. He's actually currently restomod a 96 Prelude which caught my eye dentist because I've never heard of anybody rest am adding a Prelude that didn't seem like a normal sentence construction. But okay <mark>and</mark> I want to see photos. What are you putting in it? What's going on? Is this Honda parts? That's like an NSX engine going in a Prelude <mark>and</mark> you're creating some sort of monster thing that nobody's ever thought of is it the all wheel drive system? From some Acura <mark>and</mark> you're dumping that there you go. What is this? Carbon Prelude with the super handling all-wheel drive. That would actually be a cool build like how much money are you pouring at? This that concerned? You could leave money left over so we can buy more cars for well, but here's the thing. He's restomod in one because his wife drives a 99 Prelude He restored prior. Wow. All right, so currently he's saving to replace his aging Honda Element with a ridge line, but he fears that he's missing out on the S2000 those cars are not the same <mark>and</mark> he's also Tempted to blow his savings on an R SX s. Okay Honda through <mark>and</mark> through <mark>and</mark> inaccurate. That's all this on this list as a side note. He says in 2010 is red o5 Hyundai Accent hatch was rear-ended <mark>and</mark> totaled he passed on the sport edition Kia Soul <mark>and</mark> instead bought the aforementioned element 2006 weird, like left turn into hyundai-kia now, we're back an hour back around. Okay doing that to Honda that felt straight. I gotta go back sit. Ten years hundred fifty thousand miles later. He still got the Element, although it's getting worse for wear <mark>and</mark> think that happen to Honda's. I thought that just Shrugged off the where <mark>and</mark> God I don't think the but I think the elements I think they succumbed to the elements. There are there I went because I think anybody that bought them beat on him pretty hard. They got used for a lots of stuff. Yeah. Yeah. All right. So he's owned a few second cars during this time as 74 MGB Roadster which He restored sold running 89 Prelude bought as a shell sold as a shelf. That means project. I'd never touched. That's what that", "Start Time (s)": 2194.2, "End Time (s)": 2312.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "also Tempted to blow his savings on an R SX s. Okay Honda through <mark>and</mark> through <mark>and</mark> inaccurate. That's all this on this list as a side note. He says in 2010 is red o5 Hyundai Accent hatch was rear-ended <mark>and</mark> totaled he passed on the sport edition Kia Soul <mark>and</mark> instead bought the aforementioned element 2006 weird, like left turn into hyundai-kia now, we're back an hour back around. Okay doing that to Honda that felt straight. I gotta go back sit. Ten years hundred fifty thousand miles later. He still got the Element, although it's getting worse for wear <mark>and</mark> think that happen to Honda's. I thought that just Shrugged off the where <mark>and</mark> God I don't think the but I think the elements I think they succumbed to the elements. There are there I went because I think anybody that bought them beat on him pretty hard. They got used for a lots of stuff. Yeah. Yeah. All right. So he's owned a few second cars during this time as 74 MGB Roadster which He restored sold running 89 Prelude bought as a shell sold as a shelf. That means project. I'd never touched. That's what that means <mark>and</mark> Think this 96 Prelude Mouse Nest. It was Day lead <mark>and</mark> an o-5 Civic which was gifted <mark>and</mark> re-gifted. It's a white elephant o5 Civic. All right, who know? Alright. So as you talked about his wife has the 99 Prelude, but she wants a 2010's Acura MDX <mark>and</mark> is Waiting For Better Credit. Just great. He says the ol5 Civic was not a peach but a fruitcake was a gift from considered co-worker got in his hand. He made it a hand-me-down. He said he used it for a commute for a year <mark>and</mark> then gave it to his sister last week 220,000 miles. <mark>And</mark> runs like butter. It's just I like the white elephant Civic ideas. If we keep next Christmas, I've given it to you. It's gotta be great. Yeah, it's really good. Keep handing it down. You know it the next Christmas party you attend. You could give a car away. The problem is that's the L5 Civic. Hey, but it is going to run. This is the good news Anthony. What about Anthony had fun before we're now having this fun. I what I'm going to do with you Dennis. Alright, so he gave away the Civic then the oil light came on <mark>and</mark> his wife's Prelude <mark>and</mark> the brakes", "Start Time (s)": 2252.8, "End Time (s)": 2372.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "touched. That's what that means <mark>and</mark> Think this 96 Prelude Mouse Nest. It was Day lead <mark>and</mark> an o-5 Civic which was gifted <mark>and</mark> re-gifted. It's a white elephant o5 Civic. All right, who know? Alright. So as you talked about his wife has the 99 Prelude, but she wants a 2010's Acura MDX <mark>and</mark> is Waiting For Better Credit. Just great. He says the ol5 Civic was not a peach but a fruitcake was a gift from considered co-worker got in his hand. He made it a hand-me-down. He said he used it for a commute for a year <mark>and</mark> then gave it to his sister last week 220,000 miles. <mark>And</mark> runs like butter. It's just I like the white elephant Civic ideas. If we keep next Christmas, I've given it to you. It's gotta be great. Yeah, it's really good. Keep handing it down. You know it the next Christmas party you attend. You could give a car away. The problem is that's the L5 Civic. Hey, but it is going to run. This is the good news Anthony. What about Anthony had fun before we're now having this fun. I what I'm going to do with you Dennis. Alright, so he gave away the Civic then the oil light came on <mark>and</mark> his wife's Prelude <mark>and</mark> the brakes when On the element He says all our cars got old when we weren't looking. Yeah that happens. I feel like I'm on the cusp of that right now. I'm realizing everything I own is 15 years old <mark>and</mark> going that might not be a good choice. Yeah, when the Phaeton is your reliable winter car. Yes, you might have an issue. Yeah, you might want to rethink that just a little bit. Yeah. Okay. So he says I think it would be poor form to by himself name another car number number of cars while his wife is still driving something from the 90s. So he needs to wait until she gets. Her M DX, which is great. All right, in the meantime, he's been saving for a year at the rate of four thousand dollars per year. Just do math do math folks. How much money does he have? Dennis has four thousand dollars. How did I get? It's like a word problem. I got my son. It's great. Yeah, how many gallons of milk consumed on the train from New York to out? I don't know. All right, if you can nurse the elements They don't serve milk on that traits right trick question surprise. All right, so if we can nurse the element along for three to five more years he can pay cash or put a large down payment on a lightly used 2nd. Gen", "Start Time (s)": 2311.5, "End Time (s)": 2431.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be a good choice. Yeah, when the Phaeton is your reliable winter car. Yes, you might have an issue. Yeah, you might want to rethink that just a little bit. Yeah. Okay. So he says I think it would be poor form to by himself name another car number number of cars while his wife is still driving something from the 90s. So he needs to wait until she gets. Her M DX, which is great. All right, in the meantime, he's been saving for a year at the rate of four thousand dollars per year. Just do math do math folks. How much money does he have? Dennis has four thousand dollars. How did I get? It's like a word problem. I got my son. It's great. Yeah, how many gallons of milk consumed on the train from New York to out? I don't know. All right, if you can nurse the elements They don't serve milk on that traits right trick question surprise. All right, so if we can nurse the element along for three to five more years he can pay cash or put a large down payment on a lightly used 2nd. Gen Honda Ridgeline. His wife neither wants her MDX used for truck stuff nor wants his savings to pay for her car. Okay, so there's some you know, give <mark>and</mark> take on both. They're Tryin. Yeah, but I think he wants an S2000, you know, it says remember I had an MGB but he's worried, you know prices of the s2000s will do the same thing that the first generation NSX did it says Fly Away out of my reach like a lost balloon on the third hand. He says an Acura RSX Type ass would make a great replacement for the Civic. <mark>And</mark> honor has fallen Accent Hatchback, but then he says ultimately I should be saving for a down payment for a house. Yes. Well, honestly, we all should be saving for something other than the car where we have to buy we all should be <mark>and</mark> we aren't going to which is why you're all here with us <mark>and</mark> we're glad about it Dennis. Hmm. Wow. Okay, first off happy wife happy life. I'm going to say that again. Okay, make sure your wife not only likes what she drives but it's reliable for her. Yeah, just just add on this. I've joked about it recently because it has made me laugh avoid that conversation. I had with my wife who's who's very nice to me about my car love with the whole which car might taking", "Start Time (s)": 2382.5, "End Time (s)": 2502.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we all should be saving for something other than the car where we have to buy we all should be <mark>and</mark> we aren't going to which is why you're all here with us <mark>and</mark> we're glad about it Dennis. Hmm. Wow. Okay, first off happy wife happy life. I'm going to say that again. Okay, make sure your wife not only likes what she drives but it's reliable for her. Yeah, just just add on this. I've joked about it recently because it has made me laugh avoid that conversation. I had with my wife who's who's very nice to me about my car love with the whole which car might taking because we're just everything has something going wrong avoid that so yeah, don't do that. Hmm. Alright, so he says thoughts he's saving cash. Well, first of all the cash savings rate that you're accomplishing. It should only take you two years to buy an $8,000 AP1 S2000. Yeah, right. I mean I went to art school. I'm not going At math I can operate my iPhone agreed. Oh, here's a while. We're there. Let me mention this on his 2000s back to your question about them leaving <mark>and</mark> I'll be coming expensive again Dennis. I think you're right. They will but I don't think the ones you want will okay, I think just I think the ones I think the ones that are going to nice one turn back <mark>and</mark> go really high or going to be the no mile AP twos. Yeah, or the CR is that they made for a while. They made the S2000 see ours <mark>and</mark> that blue with that then they destroyed Auto crosses everywhere. Yeah, I think He does <mark>and</mark> it can be the ones with no miles the ones that you're finding that are AP AP ones. Okay, by the way, that that car most cars have got the refresh in the middle like with Porsha's we talk about the point 1 <mark>and</mark> point 2. So the refresh in the middle of the S2000 is called the ap2. So the AP1 has the digital dash with the RPMs that go all the way over the top <mark>and</mark> a full Half Moon versus three quarters of the way in the ap2 lots of a little chain. That's the difference. That's the only thing that's the only difference actually the AP ones were a little more tail happy. But as a result that because they It's refined later. They aren't holding their value as well. <mark>And</mark> I think the AP twos with low miles pristine", "Start Time (s)": 2471.5, "End Time (s)": 2590.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a while. We're there. Let me mention this on his 2000s back to your question about them leaving <mark>and</mark> I'll be coming expensive again Dennis. I think you're right. They will but I don't think the ones you want will okay, I think just I think the ones I think the ones that are going to nice one turn back <mark>and</mark> go really high or going to be the no mile AP twos. Yeah, or the CR is that they made for a while. They made the S2000 see ours <mark>and</mark> that blue with that then they destroyed Auto crosses everywhere. Yeah, I think He does <mark>and</mark> it can be the ones with no miles the ones that you're finding that are AP AP ones. Okay, by the way, that that car most cars have got the refresh in the middle like with Porsha's we talk about the point 1 <mark>and</mark> point 2. So the refresh in the middle of the S2000 is called the ap2. So the AP1 has the digital dash with the RPMs that go all the way over the top <mark>and</mark> a full Half Moon versus three quarters of the way in the ap2 lots of a little chain. That's the difference. That's the only thing that's the only difference actually the AP ones were a little more tail happy. But as a result that because they It's refined later. They aren't holding their value as well. <mark>And</mark> I think the AP twos with low miles pristine <mark>and</mark> stock because many of them are no longer stock. True. Those are going to go up out of your reach if they aren't already they're going to keep going but an AP one that's just been driven <mark>and</mark> has some miles. I think you could buy one. Now. I think you could buy one three years from now. I think they're going to stay about the same. Mmm. Get ready for some tough love because I think you should sell the rest of modded Prelude I had Exact same thought <mark>and</mark> I put it under tough love as well. I but you know Dennis, I'm sorry. I love the idea. I don't know what it is. <mark>And</mark> unless you're pouring money at it to make it super cool because preludes were fun. But the problem is their front wheel drive. So preventing them from low-power front-wheel-drive. I'm into high power front-wheel-drive. Yeah, but they weren't in the era of the Fiesta ST where suddenly front-wheel drive doesn't matter anymore. You know what I mean? Because they were so good <mark>and</mark> handled so well, they weren't in that category yet. So by the MDX as soon as possible,", "Start Time (s)": 2526.1, "End Time (s)": 2645.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a little more tail happy. But as a result that because they It's refined later. They aren't holding their value as well. <mark>And</mark> I think the AP twos with low miles pristine <mark>and</mark> stock because many of them are no longer stock. True. Those are going to go up out of your reach if they aren't already they're going to keep going but an AP one that's just been driven <mark>and</mark> has some miles. I think you could buy one. Now. I think you could buy one three years from now. I think they're going to stay about the same. Mmm. Get ready for some tough love because I think you should sell the rest of modded Prelude I had Exact same thought <mark>and</mark> I put it under tough love as well. I but you know Dennis, I'm sorry. I love the idea. I don't know what it is. <mark>And</mark> unless you're pouring money at it to make it super cool because preludes were fun. But the problem is their front wheel drive. So preventing them from low-power front-wheel-drive. I'm into high power front-wheel-drive. Yeah, but they weren't in the era of the Fiesta ST where suddenly front-wheel drive doesn't matter anymore. You know what I mean? Because they were so good <mark>and</mark> handled so well, they weren't in that category yet. So by the MDX as soon as possible, okay, get ready to sell that estimated Prelude whether you finish it or not thing find somebody that wants to take over the project or part it out or whatever. That is. I know those are hurtful words. I'm not trying to play like that. But what would he would sell his wife's 99 <mark>and</mark> the one that he's working on? What are we walking away with money-wise? Yeah, that way it cuts down on the amount of cars. You have therefore leaving you more space more wiggle room for more carbs for more cars in the future we do. What it allows a easier conversation, I'll say hopefully yeah now keep saving for that S2000 because you can buy a Ridgeline anytime nothing is going to happen to the Ridgeline like we're talking about with the S2000 FairPoint the Ridgeline. Yeah, they're just going to keep making them. The old ones will be available. They'll be fine. Well, yeah blah. Have you driven the MX-5 with the turbo yet? Mmm, the MX-5 RF with the turbo. They're more", "Start Time (s)": 2579.6, "End Time (s)": 2699.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as possible, okay, get ready to sell that estimated Prelude whether you finish it or not thing find somebody that wants to take over the project or part it out or whatever. That is. I know those are hurtful words. I'm not trying to play like that. But what would he would sell his wife's 99 <mark>and</mark> the one that he's working on? What are we walking away with money-wise? Yeah, that way it cuts down on the amount of cars. You have therefore leaving you more space more wiggle room for more carbs for more cars in the future we do. What it allows a easier conversation, I'll say hopefully yeah now keep saving for that S2000 because you can buy a Ridgeline anytime nothing is going to happen to the Ridgeline like we're talking about with the S2000 FairPoint the Ridgeline. Yeah, they're just going to keep making them. The old ones will be available. They'll be fine. Well, yeah blah. Have you driven the MX-5 with the turbo yet? Mmm, the MX-5 RF with the turbo. They're more money. But once you start selling all this peripheral stuff Tough get your wife in the MDX <mark>and</mark> you're really pushing on the savings you're saving even more <mark>and</mark> suddenly you're able to put a nice down payment on an RF with the turbo delish. It's the modern car. It's the hard top. So it's convertible. It's everything that S2000 is I think in a modern iteration now with in a lot of ways you the turbo. I like it. I like it a lot to Dennis. We're both kind of thinking tough love for you. I'm going I'm going to say this it's going to hurt but I'm going to say it anyway. I want you to make a list. If you need to put it in front of you iconic computer do so put the word Honda Acura just put those words on one side. Okay, the other side make a list of every other car manufacturer. Oh every other one made <mark>and</mark> here is my question. Nothing from any of them. You had point us thinking Honda you've owned Kia <mark>and</mark> Hyundai, but honestly, there's a lot of great cars out. There's a lot of fun car manufacturers out there <mark>and</mark> there is a level of pay-to-play we've talked about this before you <mark>and</mark> I are experiencing. With these crazy sedans, but come on my Lotus all", "Start Time (s)": 2645.2, "End Time (s)": 2765.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They're more money. But once you start selling all this peripheral stuff Tough get your wife in the MDX <mark>and</mark> you're really pushing on the savings you're saving even more <mark>and</mark> suddenly you're able to put a nice down payment on an RF with the turbo delish. It's the modern car. It's the hard top. So it's convertible. It's everything that S2000 is I think in a modern iteration now with in a lot of ways you the turbo. I like it. I like it a lot to Dennis. We're both kind of thinking tough love for you. I'm going I'm going to say this it's going to hurt but I'm going to say it anyway. I want you to make a list. If you need to put it in front of you iconic computer do so put the word Honda Acura just put those words on one side. Okay, the other side make a list of every other car manufacturer. Oh every other one made <mark>and</mark> here is my question. Nothing from any of them. You had point us thinking Honda you've owned Kia <mark>and</mark> Hyundai, but honestly, there's a lot of great cars out. There's a lot of fun car manufacturers out there <mark>and</mark> there is a level of pay-to-play we've talked about this before you <mark>and</mark> I are experiencing. With these crazy sedans, but come on my Lotus all heck all the stuff I've owned there is that that impending danger of what if it goes wrong? I get it again <mark>and</mark> clearly you had great experience with Honda's <mark>and</mark> I understand you have Honda love but one of the things we really want for people is different experiences <mark>and</mark> Branch out <mark>and</mark> do something new. This is all you're thinking about is Honda or Acura product <mark>and</mark> I'm sure it feels really weird but I really want to encourage you for there's nothing else out there. Really? Yeah, I To admit I'm kind of same way. I need to take that medicine to because I just think okay. I like my Porsche. What's the next Porsha? I think that way to admit well <mark>and</mark> look at what's happened with you with Maserati. I've discovered Maserati. I mean honestly of if you had made this list Maserati wouldn't have even been a consideration thing now granted we live weird lives. So we went out <mark>and</mark> bought weird cars on purpose. Yes, because we get getting content", "Start Time (s)": 2699.0, "End Time (s)": 2818.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there's a lot of great cars out. There's a lot of fun car manufacturers out there <mark>and</mark> there is a level of pay-to-play we've talked about this before you <mark>and</mark> I are experiencing. With these crazy sedans, but come on my Lotus all heck all the stuff I've owned there is that that impending danger of what if it goes wrong? I get it again <mark>and</mark> clearly you had great experience with Honda's <mark>and</mark> I understand you have Honda love but one of the things we really want for people is different experiences <mark>and</mark> Branch out <mark>and</mark> do something new. This is all you're thinking about is Honda or Acura product <mark>and</mark> I'm sure it feels really weird but I really want to encourage you for there's nothing else out there. Really? Yeah, I To admit I'm kind of same way. I need to take that medicine to because I just think okay. I like my Porsche. What's the next Porsha? I think that way to admit well <mark>and</mark> look at what's happened with you with Maserati. I've discovered Maserati. I mean honestly of if you had made this list Maserati wouldn't have even been a consideration thing now granted we live weird lives. So we went out <mark>and</mark> bought weird cars on purpose. Yes, because we get getting content fodder out of it. You guys are laughing along with us. So we realize that's not a normal situation, but my point is Is you found things to love as I have with the Phaeton in cars? You never actually thought you'd like. Yeah. Yeah, MC 20. Come on Maserati, MC 20. Let's have it guys. Thank you for your questions write to us with your own debate everyday driver TV at gmail.com. Send us your topic Tuesday's you are on social media to <mark>and</mark> your car conclusions <mark>and</mark> you're awesome debates Keep It Coming. You can find us on the web site to on the contact button there. When we're searching for cars for this show or for our own crazy Obsession our searches always start with Auto Tempest instead of searching each car site separately. You can enter all your parameters in Auto Tempest one time <mark>and</mark> search them all at once without a tempest. You can enter your search one time <mark>and</mark> see results from cars.com TrueCar eBay <mark>and</mark> many more or you can jump to Craigslist auto trader or CarGurus without entering anything new They just added a", "Start Time (s)": 2755.5, "End Time (s)": 2875.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I've discovered Maserati. I mean honestly of if you had made this list Maserati wouldn't have even been a consideration thing now granted we live weird lives. So we went out <mark>and</mark> bought weird cars on purpose. Yes, because we get getting content fodder out of it. You guys are laughing along with us. So we realize that's not a normal situation, but my point is Is you found things to love as I have with the Phaeton in cars? You never actually thought you'd like. Yeah. Yeah, MC 20. Come on Maserati, MC 20. Let's have it guys. Thank you for your questions write to us with your own debate everyday driver TV at gmail.com. Send us your topic Tuesday's you are on social media to <mark>and</mark> your car conclusions <mark>and</mark> you're awesome debates Keep It Coming. You can find us on the web site to on the contact button there. When we're searching for cars for this show or for our own crazy Obsession our searches always start with Auto Tempest instead of searching each car site separately. You can enter all your parameters in Auto Tempest one time <mark>and</mark> search them all at once without a tempest. You can enter your search one time <mark>and</mark> see results from cars.com TrueCar eBay <mark>and</mark> many more or you can jump to Craigslist auto trader or CarGurus without entering anything new They just added a link to Facebook Marketplace to Auto Tempest can help you find your next. Next new or used car if there's a dozen in your neighborhood or two in the entire country. So if you're doing your drive homework, you're chasing your dream car or just looking to feed the disease as we always are head to Auto Tempest.com all the cars onesearch. Jump into questions. We've got a ton on here compliments to you guys for all your great questions. I'm jumping to Twitter <mark>and</mark> Simon MI5 mantle said if you had your own car brands, what would you call them? <mark>And</mark> what would be the brand ethos luxury speed speed at a competitive price. What would the motto be? What would it be? Okay. I'm not quite sure what the name of my car company would be I think. It takes a big ego to do it, but I will give", "Start Time (s)": 2805.9, "End Time (s)": 2925.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> see results from cars.com TrueCar eBay <mark>and</mark> many more or you can jump to Craigslist auto trader or CarGurus without entering anything new They just added a link to Facebook Marketplace to Auto Tempest can help you find your next. Next new or used car if there's a dozen in your neighborhood or two in the entire country. So if you're doing your drive homework, you're chasing your dream car or just looking to feed the disease as we always are head to Auto Tempest.com all the cars onesearch. Jump into questions. We've got a ton on here compliments to you guys for all your great questions. I'm jumping to Twitter <mark>and</mark> Simon MI5 mantle said if you had your own car brands, what would you call them? <mark>And</mark> what would be the brand ethos luxury speed speed at a competitive price. What would the motto be? What would it be? Okay. I'm not quite sure what the name of my car company would be I think. It takes a big ego to do it, but I will give <mark>Elon</mark> <mark>Musk</mark> a point for not naming his car company after himself because he was a first investor not the person that started it. I hate to say it trying to give him a point. I know you're desperately trying to give up Point preventing me from giving him. Sorry. Sorry, you're making a good point though. Keep going. It's not it's not the my agree. Nobody's driving a musk. Thank God doesn't sound right. It doesn't the elon's know better. It really, isn't. It really isn't throughout history just about every car. He is named after the founder after Direction fan, right? Absolutely. So a point to him for naming his car company after the technology same thing with Trevor Milton who is named his electric Class A semi truck company after Nicolas Nicolas. So it's not the Milton. We're driving. We have a Nikola transport truck that's hauling a bunch of Tesla's it's going to have some please do that. Oh, it's gonna want that photo because there it is. Yeah, they're gonna get together <mark>and</mark> somebody's going to figure that out <mark>and</mark> get to do it. But throughout history. Like I said everything in her, Horace Dodge <mark>and</mark> you're right your", "Start Time (s)": 2865.7, "End Time (s)": 2985.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Okay. I'm not quite sure what the name of my car company would be I think. It takes a big ego to do it, but I will give <mark>Elon</mark> <mark>Musk</mark> a point for not naming his car company after himself because he was a first investor not the person that started it. I hate to say it trying to give him a point. I know you're desperately trying to give up Point preventing me from giving him. Sorry. Sorry, you're making a good point though. Keep going. It's not it's not the my agree. Nobody's driving a musk. Thank God doesn't sound right. It doesn't the elon's know better. It really, isn't. It really isn't throughout history just about every car. He is named after the founder after Direction fan, right? Absolutely. So a point to him for naming his car company after the technology same thing with Trevor Milton who is named his electric Class A semi truck company after Nicolas Nicolas. So it's not the Milton. We're driving. We have a Nikola transport truck that's hauling a bunch of Tesla's it's going to have some please do that. Oh, it's gonna want that photo because there it is. Yeah, they're gonna get together <mark>and</mark> somebody's going to figure that out <mark>and</mark> get to do it. But throughout history. Like I said everything in her, Horace Dodge <mark>and</mark> you're right your Chevrolet <mark>and</mark> everything just welcome Brooklyn. Sure. Absolutely, right John DeLorean name the heart keeps going. I mean, I like Porsche but it has to sound right. I don't see anybody driving the Schmucker. I just don't because you know the short for that. Yeah. Anyway, yeah, you're off the yeah, you know it devolve into that so I don't see it. So it would be it would be something that that Is I don't know none threatening non-specific, I guess so it'd take me a while to come up with the name. I see how the name is something you could stuck on for a while supposedly could have IP <mark>and</mark> then you have who who already has that URL <mark>and</mark> suddenly your chain. This is why The Grand Tour finally became The Grand Tour they went through like 50 names trying to figure out what could it be that somebody doesn't already own saying was boring. So I'm still working on that. But my company would either be a company similar to", "Start Time (s)": 2918.9, "End Time (s)": 3038.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the yeah, you know it devolve into that so I don't see it. So it would be it would be something that that Is I don't know none threatening non-specific, I guess so it'd take me a while to come up with the name. I see how the name is something you could stuck on for a while supposedly could have IP <mark>and</mark> then you have who who already has that URL <mark>and</mark> suddenly your chain. This is why The Grand Tour finally became The Grand Tour they went through like 50 names trying to figure out what could it be that somebody doesn't already own saying was boring. So I'm still working on that. But my company would either be a company similar to Koenigsegg power speed Technology Innovation luxury. Lucidity I'll give you an a kitchen design example. Okay, when I was in my Furniture Design days we talked about would you rather design 5 or 10 really beautiful high-end kitchens with you know, really great details or a flat-pack Ikea kitchen. Okay as a designer, which would you rather do that cell to 20 million homes. Which would where do you want your products? <mark>And</mark> how do you want them to be perceived? It's a fair question <mark>and</mark> you can answer it either way. So I'm leaning more towards the Very part to really concentrate like Christian von Koenigsegg is doing the other company would be a 60s cars that never existed interesting Ferraris Jaguars <mark>and</mark> Aston Martin. So it looks like those <mark>and</mark> you think is that it no, that's a little different but the shapes are evoke in like that old manufacturing techniques like an English wheel <mark>and</mark> that's just now they made them but it's 60s cars that never existed that give you the feeling the same feeling as a Jaguar F-Type, but it's not like it that I like a lot you would do that. At well, like bring back beautiful form language with modern running gear. That's why I like icon four by fours <mark>and</mark> they're like, so not much. Yeah, but it's different. It's now beautiful design bespoke design. Yeah. I still think you can make a lot of money in bespoke <mark>and</mark> Niche cars for manufacturers doing that. I mean electric GT.com is doing the Ferrari 308 electric conversion with a manual transmission. Yeah,", "Start Time (s)": 3005.3, "End Time (s)": 3125.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or a flat-pack Ikea kitchen. Okay as a designer, which would you rather do that cell to 20 million homes. Which would where do you want your products? <mark>And</mark> how do you want them to be perceived? It's a fair question <mark>and</mark> you can answer it either way. So I'm leaning more towards the Very part to really concentrate like Christian von Koenigsegg is doing the other company would be a 60s cars that never existed interesting Ferraris Jaguars <mark>and</mark> Aston Martin. So it looks like those <mark>and</mark> you think is that it no, that's a little different but the shapes are evoke in like that old manufacturing techniques like an English wheel <mark>and</mark> that's just now they made them but it's 60s cars that never existed that give you the feeling the same feeling as a Jaguar F-Type, but it's not like it that I like a lot you would do that. At well, like bring back beautiful form language with modern running gear. That's why I like icon four by fours <mark>and</mark> they're like, so not much. Yeah, but it's different. It's now beautiful design bespoke design. Yeah. I still think you can make a lot of money in bespoke <mark>and</mark> Niche cars for manufacturers doing that. I mean electric GT.com is doing the Ferrari 308 electric conversion with a manual transmission. Yeah, let's take a further than that. It could be an awesome engine. It could be electric, but it's bespoke Bodywork. Like I'm not saying I want to go down the Fisker. Because he was just coach work on top of Mercedes SLS <mark>and</mark> BMWs. That's not what I'm talking about. But just something beautiful 60 scars that never existed very cool while you're on Twitter. <mark>And</mark> while you're talking designed to do see on songs question. I did I have to call you out here. He says he just found our podcast <mark>and</mark> he was very surprised. He's not why I found it to hear that you Paul went to Art Center because he's currently going to Art Center <mark>and</mark> so he says <mark>and</mark> I'm doing this to call you out directly Paul, right? He says do you still sketch Paul? <mark>And</mark> if so, would you share? Ah, I am Folks I am I'm trying here. I'm trying to get Paul to do a series on design. We talk about it often. Yeah, we're working on gear. I remind him. I am trying I am here", "Start Time (s)": 3056.2, "End Time (s)": 3176.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "transmission. Yeah, let's take a further than that. It could be an awesome engine. It could be electric, but it's bespoke Bodywork. Like I'm not saying I want to go down the Fisker. Because he was just coach work on top of Mercedes SLS <mark>and</mark> BMWs. That's not what I'm talking about. But just something beautiful 60 scars that never existed very cool while you're on Twitter. <mark>And</mark> while you're talking designed to do see on songs question. I did I have to call you out here. He says he just found our podcast <mark>and</mark> he was very surprised. He's not why I found it to hear that you Paul went to Art Center because he's currently going to Art Center <mark>and</mark> so he says <mark>and</mark> I'm doing this to call you out directly Paul, right? He says do you still sketch Paul? <mark>And</mark> if so, would you share? Ah, I am Folks I am I'm trying here. I'm trying to get Paul to do a series on design. We talk about it often. Yeah, we're working on gear. I remind him. I am trying I am here for you. I'm trying. All right, he's working on it. We're going to actually have Beyond just sketches Paul's going to be taking designs of cars <mark>and</mark> actually fixing them. I'm putting that in quotes. He's saying you went to this way for these reasons. Why not go this way for these reasons now, he's operating in a world where You don't have the checks <mark>and</mark> balances which is what's kind of fun about it because when you sit down <mark>and</mark> talk about that stuff, I just kind of sit back <mark>and</mark> get silent <mark>and</mark> I don't get silent often. So hopefully it's coming soon enough fair enough. I'm called out officially appreciate it. All right. So what else other questions you got on here Michael Newsome. He says I know I know this is not quite Apples to Apples. But okay charger or Julia. <mark>And</mark> why hmm now Michael, I think the answer here is the kind of driver <mark>and</mark> the location of where you are. If you're a person who likes power <mark>and</mark> lives in Texas or Florida charger. It's just big comfortable. Bruiser tons of power really, I mean got attitude you've got an on ramp <mark>and</mark> a hundred miles ahead of you. Let's go. Okay, but if you drive like I do you like light", "Start Time (s)": 3124.1, "End Time (s)": 3243.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "he's working on it. We're going to actually have Beyond just sketches Paul's going to be taking designs of cars <mark>and</mark> actually fixing them. I'm putting that in quotes. He's saying you went to this way for these reasons. Why not go this way for these reasons now, he's operating in a world where You don't have the checks <mark>and</mark> balances which is what's kind of fun about it because when you sit down <mark>and</mark> talk about that stuff, I just kind of sit back <mark>and</mark> get silent <mark>and</mark> I don't get silent often. So hopefully it's coming soon enough fair enough. I'm called out officially appreciate it. All right. So what else other questions you got on here Michael Newsome. He says I know I know this is not quite Apples to Apples. But okay charger or Julia. <mark>And</mark> why hmm now Michael, I think the answer here is the kind of driver <mark>and</mark> the location of where you are. If you're a person who likes power <mark>and</mark> lives in Texas or Florida charger. It's just big comfortable. Bruiser tons of power really, I mean got attitude you've got an on ramp <mark>and</mark> a hundred miles ahead of you. Let's go. Okay, but if you drive like I do you like light small agile stuff <mark>and</mark> you have the roads to match Julie every time fair enough petrol head 80 was watching the last episode of season 3 of The Grand Tour where the trio did a documentary on the Ford Cortina. Remember that <mark>and</mark> how it became the backbone of British Society. What car do we think was the backbone or is the backbone of American society I dug into this. I'm interested according to the American University in Washington DC's covid School of Business <mark>and</mark> their 2019 Auto index made in America ranking. Okay. It ranks the Corvette as number one according to parts <mark>and</mark> final assembly into the Mustang is important too but it's ranked 15th on that same list according to Parts sharing <mark>and</mark> final assembly. Okay <mark>and</mark> despite filin simply being the us only 46% of the Our u.s. Or Canadian made in the Mustang now. I know that you know, the manual transmissions made in China least maybe the", "Start Time (s)": 3178.6, "End Time (s)": 3298.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to match Julie every time fair enough petrol head 80 was watching the last episode of season 3 of The Grand Tour where the trio did a documentary on the Ford Cortina. Remember that <mark>and</mark> how it became the backbone of British Society. What car do we think was the backbone or is the backbone of American society I dug into this. I'm interested according to the American University in Washington DC's covid School of Business <mark>and</mark> their 2019 Auto index made in America ranking. Okay. It ranks the Corvette as number one according to parts <mark>and</mark> final assembly into the Mustang is important too but it's ranked 15th on that same list according to Parts sharing <mark>and</mark> final assembly. Okay <mark>and</mark> despite filin simply being the us only 46% of the Our u.s. Or Canadian made in the Mustang now. I know that you know, the manual transmissions made in China least maybe the prior generation was but yeah that is important. But if the argument is solely based on perception both Mustang <mark>and</mark> Corvette are in the similar position, I see the for taking the technicality out of it <mark>and</mark> just what's the perception of both of these cars. They're just American Muscle Cars sure because consider that you got a Mustang someone's sometime in your life the perception in the past you just you get a Mustang at some point because your car enthusiast But once you retire, then you get the Corvette the kids are grown <mark>and</mark> they're all completely finally out of the house, you know, <mark>and</mark> so you get a Corvette <mark>and</mark> that's been the generic perception but that is changing dramatically with both cars, which I love ya either change it move on but a large part of past American Car culture is about speed drag racing <mark>and</mark> cruising in the past. That's also morphing <mark>and</mark> changing because of sure Tesla's <mark>and</mark> you know, all that kind of thing, but that's been in the Has so those two cars. I'm calling out. I'm sort of leaving the technicalities out of it, even though we could, you know have an endless discussion but Mustang <mark>and</mark> Corvette, that's kind of been the backbone as far as American Car culture. I see where you're going. I actually Wonder because the Ford Cortina part of the", "Start Time (s)": 3245.6, "End Time (s)": 3365.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but yeah that is important. But if the argument is solely based on perception both Mustang <mark>and</mark> Corvette are in the similar position, I see the for taking the technicality out of it <mark>and</mark> just what's the perception of both of these cars. They're just American Muscle Cars sure because consider that you got a Mustang someone's sometime in your life the perception in the past you just you get a Mustang at some point because your car enthusiast But once you retire, then you get the Corvette the kids are grown <mark>and</mark> they're all completely finally out of the house, you know, <mark>and</mark> so you get a Corvette <mark>and</mark> that's been the generic perception but that is changing dramatically with both cars, which I love ya either change it move on but a large part of past American Car culture is about speed drag racing <mark>and</mark> cruising in the past. That's also morphing <mark>and</mark> changing because of sure Tesla's <mark>and</mark> you know, all that kind of thing, but that's been in the Has so those two cars. I'm calling out. I'm sort of leaving the technicalities out of it, even though we could, you know have an endless discussion but Mustang <mark>and</mark> Corvette, that's kind of been the backbone as far as American Car culture. I see where you're going. I actually Wonder because the Ford Cortina part of the discussion. There was the fact that it was a complete every man car <mark>and</mark> they kind of loved it <mark>and</mark> loathed it simultaneously. Hmm, which makes me wonder about the cake car. Is it the American equivalent of that discussion I'd could be that could be I don't I don't like them but there was an ERA where it was just like almost everything is cake our cake are thinking which by the way this is not cake our Japanese. This is cake our Chrysler k-car e Iacocca <mark>and</mark> everything was essentially made from the same idea. It's before Volkswagen even did the mqb platform made. Everything is a platform Chrysler that this would be any change the industry for a time into boredom. I'll note but anyway, I wonder about that did it did shape a lot <mark>and</mark> people Love them <mark>and</mark> hate him price because you could finally afford a car a new car <mark>and</mark> you know hated him for everything else for all of the other stuff going on. Let's see, this is Cham Cham MJ. He's listening to the podcast for a while. He enjoys our", "Start Time (s)": 3299.3, "End Time (s)": 3418.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>and</mark> people Love them <mark>and</mark> hate him price because you could finally afford a car a new car <mark>and</mark> you know hated him for everything else for all of the other stuff going on. Let's see, this is Cham Cham MJ. He's listening to the podcast for a while. He enjoys our YouTube stuff. He doesn't have Amazon or cable. He feels like you know, I have enough subscriptions. So he is a subscriber to Motor Trend on demand. Are we on there? I want to clarify this again. I know there's a lot of ongoing confusion are so I'm just I'm trying to go too far. Our but here's the thing. We are on Motor Trend cable channel. Yes. We are Independent Producers on the Motor Trend cable channel, which means Motor Trend doesn't own our show we own the show. Yes odor trend on demand essentially puts things on demand that they either own or license they put on the app. They don't pay a us an additional license fee. So we are not on their app. I know it's very confusing but that's the deal which is why we put it elsewhere. It's on Vimeo for all International markets <mark>and</mark> it is on Amazon. On as well. We have six seasons on Amazon. Now the first four are free on Prime as they as Seasons get older. They become free on Prime. I hear you on all the subscriptions. I'm going to say this real quick. This is odd. I read a stat once where 75% of people that have Amazon Prime. Have it for free shipping many of those people don't even know Amazon has content. You're kidding me that's changing its changing the first year <mark>and</mark> a half. That was the stat. Holy. Moly slime is just associated with free shipping is exit. <mark>And</mark> that's all the benefits I get. Exactly. So why my question for you is do you have Prime <mark>and</mark> just don't watch it up. Do you get free packages from Amazon, you might Because if you've got Prime then you've got Pride exactly then you've got the ability to watch. I also know that means extra money for their stuff. But honestly, the reason that I have it with my wife is free packaging because we live apparently too far from normal mailboxes. So a lot of stuff comes in Amazon boxes, so I get to watch stuff as a result. But I hope that", "Start Time (s)": 3403.6, "End Time (s)": 3522.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "even know Amazon has content. You're kidding me that's changing its changing the first year <mark>and</mark> a half. That was the stat. Holy. Moly slime is just associated with free shipping is exit. <mark>And</mark> that's all the benefits I get. Exactly. So why my question for you is do you have Prime <mark>and</mark> just don't watch it up. Do you get free packages from Amazon, you might Because if you've got Prime then you've got Pride exactly then you've got the ability to watch. I also know that means extra money for their stuff. But honestly, the reason that I have it with my wife is free packaging because we live apparently too far from normal mailboxes. So a lot of stuff comes in Amazon boxes, so I get to watch stuff as a result. But I hope that clarifies a little bit of how to get it. I'm sorry that it's not on the Amazon. Pardon me at not on the Motor Trend app if they would like to pay us a little bit to have our content on there because let's be honest with make them money. We would have that discussion. Mmm. There's a question from a are posting on Facebook from Ryan Chang asking why can't cheap cars be beautiful let's find cheap but if they're inexpensive have you checked out what Mazdas doing have you looked <mark>and</mark> really look closely at the curated shut lines <mark>and</mark> the way the urethane body bumper covers meet the body some car manufacturers Just draw a line <mark>and</mark> okay that's where we need to do it because we need to have that pull off there <mark>and</mark> because the tooling <mark>and</mark> Manufacturing let's just draw a line Mazda is designing that line super clean yeah on the Mazda3 that's a cheap car right can we all agree that there this Mazda 3 is pretty much a cheap car the cx-3 is cheap the the Miata is cheap I mean the base versions of all these cars inexpensive for new cars look at the lines <mark>and</mark> what they've done where the washout send <mark>and</mark> where new character lines start down the hood <mark>and</mark> then look at the surface it's not too full it's not too thin <mark>and</mark> that that just means the swell of the surface it's not puffed out too much it's not just flat it's just got a nice curvature in there <mark>and</mark> to get that out of the manufacturing it's one thing to design it it's another thing for the people who make it to pull that design <mark>and</mark> make it", "Start Time (s)": 3486.8, "End Time (s)": 3606.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "let's find cheap but if they're inexpensive have you checked out what Mazdas doing have you looked <mark>and</mark> really look closely at the curated shut lines <mark>and</mark> the way the urethane body bumper covers meet the body some car manufacturers Just draw a line <mark>and</mark> okay that's where we need to do it because we need to have that pull off there <mark>and</mark> because the tooling <mark>and</mark> Manufacturing let's just draw a line Mazda is designing that line super clean yeah on the Mazda3 that's a cheap car right can we all agree that there this Mazda 3 is pretty much a cheap car the cx-3 is cheap the the Miata is cheap I mean the base versions of all these cars inexpensive for new cars look at the lines <mark>and</mark> what they've done where the washout send <mark>and</mark> where new character lines start down the hood <mark>and</mark> then look at the surface it's not too full it's not too thin <mark>and</mark> that that just means the swell of the surface it's not puffed out too much it's not just flat it's just got a nice curvature in there <mark>and</mark> to get that out of the manufacturing it's one thing to design it it's another thing for the people who make it to pull that design <mark>and</mark> make it right yeah <mark>and</mark> how many times that sheet metal is stamped over pressed <mark>and</mark> then it Springs back just slightly because of the steel material its are for sure gonna <mark>and</mark> coaxing that shape out that such an art form I want you to appreciate that but I do take your point most cheap cars are ugly yeah a lot of times that's because it depends on what the size is an Aston Martin Long wheelbase Beautiful flowing lines. It's a GT car. You can you can really stretch the lines where the shirt versus a small compact cars many times less expensive <mark>and</mark> it's harder to make beautiful long flowing lines that are really sexy <mark>and</mark> attractive on something. So small. Look at what Aston Martin did when they made the Signet took my smart car <mark>and</mark> they made the Aston Martin Cygnet. The S2000 is a great example of pure form just mirrors", "Start Time (s)": 3541.6, "End Time (s)": 3660.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the swell of the surface it's not puffed out too much it's not just flat it's just got a nice curvature in there <mark>and</mark> to get that out of the manufacturing it's one thing to design it it's another thing for the people who make it to pull that design <mark>and</mark> make it right yeah <mark>and</mark> how many times that sheet metal is stamped over pressed <mark>and</mark> then it Springs back just slightly because of the steel material its are for sure gonna <mark>and</mark> coaxing that shape out that such an art form I want you to appreciate that but I do take your point most cheap cars are ugly yeah a lot of times that's because it depends on what the size is an Aston Martin Long wheelbase Beautiful flowing lines. It's a GT car. You can you can really stretch the lines where the shirt versus a small compact cars many times less expensive <mark>and</mark> it's harder to make beautiful long flowing lines that are really sexy <mark>and</mark> attractive on something. So small. Look at what Aston Martin did when they made the Signet took my smart car <mark>and</mark> they made the Aston Martin Cygnet. The S2000 is a great example of pure form just mirrors arrest without Here ill you know hard edges. It's just pure surface your Lotus Elise, even though I don't consider that cheap necessarily it wasn't to start with but now inexpensive. Yeah, that's a small car with a beautiful design. There's a there's a much bigger cars design put on that car. It does still work. You're right. Absolutely. It looks so beautiful caimans it that way even those are expensive <mark>and</mark> so bigger but yeah, you know that yeah. Yeah, I take your point, but right usually depends on just size <mark>and</mark> then again how much investment our car companies putting into Seen that shape <mark>and</mark> really paying attention or they just satisfied. Alright, just you know, two or three, you know stamps of the sheet metal <mark>and</mark> all right, we're good with it. We're not trying to do something really fine <mark>and</mark> beautiful out of that surface. It's just, you know, we'll tack on some cladding afterwards to kind of make it whatever that was Pontiacs demise, I think cladding <mark>and</mark> rounded buttons this color radical on Instagram says, what are our thoughts on the Subaru", "Start Time (s)": 3593.4, "End Time (s)": 3712.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Look at what Aston Martin did when they made the Signet took my smart car <mark>and</mark> they made the Aston Martin Cygnet. The S2000 is a great example of pure form just mirrors arrest without Here ill you know hard edges. It's just pure surface your Lotus Elise, even though I don't consider that cheap necessarily it wasn't to start with but now inexpensive. Yeah, that's a small car with a beautiful design. There's a there's a much bigger cars design put on that car. It does still work. You're right. Absolutely. It looks so beautiful caimans it that way even those are expensive <mark>and</mark> so bigger but yeah, you know that yeah. Yeah, I take your point, but right usually depends on just size <mark>and</mark> then again how much investment our car companies putting into Seen that shape <mark>and</mark> really paying attention or they just satisfied. Alright, just you know, two or three, you know stamps of the sheet metal <mark>and</mark> all right, we're good with it. We're not trying to do something really fine <mark>and</mark> beautiful out of that surface. It's just, you know, we'll tack on some cladding afterwards to kind of make it whatever that was Pontiacs demise, I think cladding <mark>and</mark> rounded buttons this color radical on Instagram says, what are our thoughts on the Subaru Crosstrek? He hasn't heard us talk about it. We do talk about it now <mark>and</mark> then if you'd like to see a piece on it, we actually put it in a five-seat feet arms piece. That's part of season. Three you can watch a big discussion about that. They sell really well. There's a lot of good things about them. They are cvts which we don't like too much but they are go anywhere do anything which is good driver-focused said on the other in the Spectrum quick question is a Lotus evora still worth it without the supercharger. Oh, I like that. You're taking this short answer. Yes. Here's the thing about the evora the first time ever drove <mark>and</mark> I drove without a supercharger <mark>and</mark> I drove it on a track <mark>and</mark> halfway around the first lap. I realized Yep. This could take out her more horsepower. Okay. it was still very fun it was still really agile <mark>and</mark> it still didn't feel slow but I would liken it to the base Kaman okay okay if you drive a base Cayman it's a caiman the handling is excellent interior is very nice all the interactions really excellent all of the", "Start Time (s)": 3648.8, "End Time (s)": 3768.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this color radical on Instagram says, what are our thoughts on the Subaru Crosstrek? He hasn't heard us talk about it. We do talk about it now <mark>and</mark> then if you'd like to see a piece on it, we actually put it in a five-seat feet arms piece. That's part of season. Three you can watch a big discussion about that. They sell really well. There's a lot of good things about them. They are cvts which we don't like too much but they are go anywhere do anything which is good driver-focused said on the other in the Spectrum quick question is a Lotus evora still worth it without the supercharger. Oh, I like that. You're taking this short answer. Yes. Here's the thing about the evora the first time ever drove <mark>and</mark> I drove without a supercharger <mark>and</mark> I drove it on a track <mark>and</mark> halfway around the first lap. I realized Yep. This could take out her more horsepower. Okay. it was still very fun it was still really agile <mark>and</mark> it still didn't feel slow but I would liken it to the base Kaman okay okay if you drive a base Cayman it's a caiman the handling is excellent interior is very nice all the interactions really excellent all of the ergonomics of the pedals <mark>and</mark> everything you're enjoying yourself you're just aware this could go faster this could be more powerful <mark>and</mark> it would be fine it wouldn't be anything the least bit scary that's the of or without a supercharger if you are considering a nerve or without a supercharger reverses Analyse or an exceeds with a supercharger had a question like that which one of those how usable do you need it to be the The Sweet Spot of at Lisa's is oh eight <mark>and</mark> up Factory supercharged those are so nice but they are still much more raw <mark>and</mark> less usable than a base of Aura so if you want any kind of usability you're going to want the evora guys thank you so much for all your questions I always thank you but you're always coming through the forests <mark>and</mark> it's you that <mark>and</mark> make the podcast thanks for telling us what's on your mind we appreciate it on social media thanks for following there's so much more to come so we're looking forward to it cheers everyone", "Start Time (s)": 3709.7, "End Time (s)": 3819.7, "Clip Length (min)": 1.83, "show_uri": "spotify:show:1IKqHz85nuwypnteIcFKyD", "show_name": "Everyday Driver Car Debate", "show_description": "\"The hosts of \"\"Everyday Driver\"\", Paul and Todd, get behind the microphone to answer questions and help viewers find the right car for their needs. Disagreement and debate are bound to happen. Along the way they discuss what goes on behind the scenes of their review films and other topics throughout the car industry.\"", "publisher": "Everyday Driver", "episode_uri": "spotify:episode:7AkSwKS9QXaeVvKqMDoYZz", "episode_name": "482: Full Lotus Crazy, The Aztec Works, White Elephant Civic ", "episode_description": "Wanting to own a fun sports car isn\u2019t a mid-life crisis, it\u2019s a life-long crisis! Anthony B. in Denver, CO wants two cars on opposite ends of the Spectrum Of Sacrifice. Dennis F. is a huge fan of Hondas and currently resto-modding an old Prelude, but thinks S2000\u2019s might quickly rise in value and wondering if he should get one soon? Social media questions ask what car is the backbone of American society, what would the guys name their own car companies, and is an Evora still worthy without the supercharger? Season 6 is now airing on the Motor Trend cable channel, and soon to be available on Amazon Prime and Vimeo worldwide. Rate and review us on iTunes, the Everyday Driver show on IMDB and Amazon, and write to us with your Topic Tuesday discussions and podcast debates at everydaydrivertv@gmail.com or everydaydriver.com. Share the podcast with your fellow car enthusiast friends! ", "score": 7.51081, "explanation": "{\n  \"value\": 7.51081,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:joe in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9325297,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=378.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.960247,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 378.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.5966659,\n      \"description\": \"weight(word_list:elon in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.5966659,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7940365e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7940365e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.914144,\n      \"description\": \"weight(word_list:musk in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.914144,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.0370557,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 13336.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "well, hello guys, welcome to the first episode of the haven't we thought of a name yet? I was want to do breakfast at Perkins given my last name kind of lame. But but then I was told that people may think that breakfast at Perkins. Could have some potential copyright with you know, the actual restaurant program, so I might do breakfast with Perkins. I don't know. Anyway, how we doing? How's everyone doing? I figured I would start a podcast. Maybe to help kind of supplement my thoughts that I have on other social media platforms whether it be Snapchat Facebook Instagram. What have you first let me apologize. I just ate Indian food <mark>and</mark> it's stuck in my throat. First off. Let me give a shout out to India star. You never been to India star phenomenal food. Phenomenal phenomenal phenomenal Buffet you go there between the hours of what is 11:30 <mark>and</mark> 215 get yourself an all-you-can-eat Indian buffet <mark>and</mark> it's like 8 bucks its cheapest fuck kitten calm down. But yes. So I figured that if you've if anyone's ever listen to Bill Burrs podcast or just him rambling on about random shit with no really Rhyme or Reason as to what's going on. Just kind of going on with the based in his life. I'm going to do the same thing. I don't know how long these will be. I don't know when I'm going to release them. But I figure with the name like breakfast with Perkins should be in that. Nope. Didn't come over here. Don't You Gonna Knock this over? I'm", "Start Time (s)": 1.9, "End Time (s)": 113.3, "Clip Length (min)": 1.86, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Phenomenal phenomenal phenomenal Buffet you go there between the hours of what is 11:30 <mark>and</mark> 215 get yourself an all-you-can-eat Indian buffet <mark>and</mark> it's like 8 bucks its cheapest fuck kitten calm down. But yes. So I figured that if you've if anyone's ever listen to Bill Burrs podcast or just him rambling on about random shit with no really Rhyme or Reason as to what's going on. Just kind of going on with the based in his life. I'm going to do the same thing. I don't know how long these will be. I don't know when I'm going to release them. But I figure with the name like breakfast with Perkins should be in that. Nope. Didn't come over here. Don't You Gonna Knock this over? I'm over here. You gotta figure named breakfast at Perkins should really sit in the morning time. That makes sense. Wouldn't it? Oh <mark>and</mark> see what's going on. Well, I don't know who knows this or who needs to know or whatever. But Granite City in Clive is now closed which sucks sucks hard. I love that place that better cheddar bacon burger. Let me tell you something. better cheddar bacon burger with the Granite City dip <mark>and</mark> the waffle fries unreal fucking unreal great fucking Burger I could give a fuck less for the brewery aspect of Granite City. I'm not a big drinker. So that doesn't mean anything but you know, it is what it is <mark>and</mark> it's crazy to I was just craving that better cheddar bacon burger. I crave it about once or twice every two three weeks <mark>and</mark> now I can never have that again. I don't know if it's a company-wide thing or if it's a", "Start Time (s)": 62.0, "End Time (s)": 180.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "gotta figure named breakfast at Perkins should really sit in the morning time. That makes sense. Wouldn't it? Oh <mark>and</mark> see what's going on. Well, I don't know who knows this or who needs to know or whatever. But Granite City in Clive is now closed which sucks sucks hard. I love that place that better cheddar bacon burger. Let me tell you something. better cheddar bacon burger with the Granite City dip <mark>and</mark> the waffle fries unreal fucking unreal great fucking Burger I could give a fuck less for the brewery aspect of Granite City. I'm not a big drinker. So that doesn't mean anything but you know, it is what it is <mark>and</mark> it's crazy to I was just craving that better cheddar bacon burger. I crave it about once or twice every two three weeks <mark>and</mark> now I can never have that again. I don't know if it's a company-wide thing or if it's a specific to the Clive store, but either way, all right P to Granite City, rhymed kind of lame Anyway, who's who old owner <mark>Joe</mark> <mark>Rogan</mark> who's got tickets to go to that? I was right there with the pre-orders making sure I was going I was a huge fan of <mark>Joe</mark> Rogan's stand up but his podcast I was like, I don't know anyone who doesn't listen to JRE <mark>Joe</mark> <mark>Rogan</mark> Experience for those that don't know he's podcast is phenomenal <mark>and</mark> I was the same way with Bill Burr for those that do know Bill Burr is one of my top 5 Dead or Alive comedians of all time. I wasn't huge in the Bill Burr stand up until I started listening to it in conjunction with his his podcast.", "Start Time (s)": 115.0, "End Time (s)": 234.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "never have that again. I don't know if it's a company-wide thing or if it's a specific to the Clive store, but either way, all right P to Granite City, rhymed kind of lame Anyway, who's who old owner <mark>Joe</mark> <mark>Rogan</mark> who's got tickets to go to that? I was right there with the pre-orders making sure I was going I was a huge fan of <mark>Joe</mark> Rogan's stand up but his podcast I was like, I don't know anyone who doesn't listen to JRE <mark>Joe</mark> <mark>Rogan</mark> Experience for those that don't know he's podcast is phenomenal <mark>and</mark> I was the same way with Bill Burr for those that do know Bill Burr is one of my top 5 Dead or Alive comedians of all time. I wasn't huge in the Bill Burr stand up until I started listening to it in conjunction with his his podcast. <mark>And</mark> for some reason that did it for me, so I'm thinking I was never too big in a rogue <mark>and</mark> stand-ups. So I'm thinking now having listened to the podcasts. It kind of helps me understand him more <mark>and</mark> is stand-ups will be kind of kind of appealed to me more but we'll find out. I'm curious as to who the supporting Act is going to be. That's real interesting. It'd be really dope if he could get like a I said this on Facebook earlier. If you don't be don't you can get like a Joey Diaz out there. That'd be really dope. I see that happening. No, but it would be fucking awesome. You don't know other thing too is I sit here <mark>and</mark> I don't know how long the show is going to be how long it should be. I feel like I've been rambling on forever now. <mark>And</mark> it's just now five minutes. So I gotta think of something. I want to shoot for at least a half hour.", "Start Time (s)": 175.6, "End Time (s)": 295.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "comedians of all time. I wasn't huge in the Bill Burr stand up until I started listening to it in conjunction with his his podcast. <mark>And</mark> for some reason that did it for me, so I'm thinking I was never too big in a rogue <mark>and</mark> stand-ups. So I'm thinking now having listened to the podcasts. It kind of helps me understand him more <mark>and</mark> is stand-ups will be kind of kind of appealed to me more but we'll find out. I'm curious as to who the supporting Act is going to be. That's real interesting. It'd be really dope if he could get like a I said this on Facebook earlier. If you don't be don't you can get like a Joey Diaz out there. That'd be really dope. I see that happening. No, but it would be fucking awesome. You don't know other thing too is I sit here <mark>and</mark> I don't know how long the show is going to be how long it should be. I feel like I've been rambling on forever now. <mark>And</mark> it's just now five minutes. So I gotta think of something. I want to shoot for at least a half hour. I feel like a half-hour no guests with a life. That's not as crazy. As you know other people's I think 30 minutes should be should suffice. So we'll see I guess many of you know, I'm a gamer. I'm a huge gamer. I guess one thing that's awesome. Is that Yakuza so obviously you Sony fuck boys. I mean Fanboys whatever the fuck not so many people are cool. The Sony Camp. It's jealousy is what it is the jealousy manifests <mark>and</mark> anger because you guys do have the better exclusives than we do on Xbox but over the weekend, we just got Yakuza, which is one of the", "Start Time (s)": 225.7, "End Time (s)": 345.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a half hour. I feel like a half-hour no guests with a life. That's not as crazy. As you know other people's I think 30 minutes should be should suffice. So we'll see I guess many of you know, I'm a gamer. I'm a huge gamer. I guess one thing that's awesome. Is that Yakuza so obviously you Sony fuck boys. I mean Fanboys whatever the fuck not so many people are cool. The Sony Camp. It's jealousy is what it is the jealousy manifests <mark>and</mark> anger because you guys do have the better exclusives than we do on Xbox but over the weekend, we just got Yakuza, which is one of the many exclusive so many titles that we don't get didn't get in till now. I wonder if they're going to make a cross over to Xbox or this is like a one <mark>and</mark> done thing that didn't make any sense if there is going to one <mark>and</mark> done Yakuza 0 <mark>and</mark> then that you guys don't get any more. Maybe it's the marketing Ploy. They give us a taste of Yakuza. It's a little therefore make us want to go get PlayStations <mark>and</mark> then buy more Yakuza games who the fuck knows? But I'm having fun with it the gameplay took me a little bit of time to get into but the story is Top Notch very top notch story. a lot of cutscenes though lot of cussing sure that I feel that's kind of indicative of Japanese developed games whether it be your final fantasies or your shin amuse or your you know, yakuza's what have you Especially what's the guy who's fuck? What's his name? The guy that pretty much just made a fucking movie with the last what was this about Silent Hill?", "Start Time (s)": 294.4, "End Time (s)": 411.0, "Clip Length (min)": 1.94, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "movie with the last what was this about Silent Hill? Oh fuck what's his name? It's going to piss me off. He's the guy that did the metal gear games or was he the guy that did the listen it doesn't matter. You guys know who I'm talking about though. But the last game he released was essentially just a fucking movie with like no gaming in it. Just must be indicative of of that. I was gonna get a PlayStation 3 nice PlayStation 3. What is this fucking no for I wasn't going to Play Station 3. I was gonna get a PlayStation. What's for whatever the fuck the new one is. Because shenmue I don't know who knows about shenme shenme was originally released on the Dreamcast phenomenal game. If you've not played shenmue 1 or 2 there on the Xbox game pass. I believe for free very very good games. Some people don't like them for like the QuickTime events <mark>and</mark> stuff like that. I like quick time events. I'm putting it down. Sorry. That was a that was a thing. You can work as a doc with a dock worker to make a little bit extra Yen. Okay now talking about it. I sounds fucking stupid. You can work at the as a dock worker to make extra yet. <mark>And</mark> one of the QuickTime events was you had to lift boxes up you had to move these boxes around <mark>and</mark> it was you would move the Box. <mark>And</mark> when you go to set the box down the guy on the other end, there's like a long Crate Box the guy on the other end of the Box we go or putting it down. Then you got to hit down on the d-pad <mark>and</mark> set it down. I was a great game who remembers a game called Jet Set Radio or jet grind radio Jet Set Radio Future. That was a Dreamcast game. Oh my God. Countless hours in that game great soundtrack to lovely", "Start Time (s)": 408.1, "End Time (s)": 527.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Sorry. That was a that was a thing. You can work as a doc with a dock worker to make a little bit extra Yen. Okay now talking about it. I sounds fucking stupid. You can work at the as a dock worker to make extra yet. <mark>And</mark> one of the QuickTime events was you had to lift boxes up you had to move these boxes around <mark>and</mark> it was you would move the Box. <mark>And</mark> when you go to set the box down the guy on the other end, there's like a long Crate Box the guy on the other end of the Box we go or putting it down. Then you got to hit down on the d-pad <mark>and</mark> set it down. I was a great game who remembers a game called Jet Set Radio or jet grind radio Jet Set Radio Future. That was a Dreamcast game. Oh my God. Countless hours in that game great soundtrack to lovely soundtrack Jet Set Radio Radio, <mark>and</mark> there's like a weird turntable. Sorry the Dreamcast I feel was ahead of its time. Maybe that's just me. I thought there was no marketing behind the Dreamcast which is why it failed. I feel like it was a really solid console. I love the Dreamcast Crazy Taxi It's Crazy Taxi great game. There's a lot of good games on there. Actually the very first sports game I played <mark>and</mark> enjoyed was a 2K game on the Dreamcast <mark>and</mark> it was like, I think it was literally NBA 2K knows NFL 2K. It was NFL 2k, not 2K10, whatever know this was literally 2K like in the year 2000. Oh my God, those were good times. Most of you know, I'm not into sports games though. I did play to k-19 <mark>and</mark> be a <mark>and</mark> that was really fun. So speaking of sports. Let's talk", "Start Time (s)": 474.4, "End Time (s)": 592.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Jet Set Radio Radio, <mark>and</mark> there's like a weird turntable. Sorry the Dreamcast I feel was ahead of its time. Maybe that's just me. I thought there was no marketing behind the Dreamcast which is why it failed. I feel like it was a really solid console. I love the Dreamcast Crazy Taxi It's Crazy Taxi great game. There's a lot of good games on there. Actually the very first sports game I played <mark>and</mark> enjoyed was a 2K game on the Dreamcast <mark>and</mark> it was like, I think it was literally NBA 2K knows NFL 2K. It was NFL 2k, not 2K10, whatever know this was literally 2K like in the year 2000. Oh my God, those were good times. Most of you know, I'm not into sports games though. I did play to k-19 <mark>and</mark> be a <mark>and</mark> that was really fun. So speaking of sports. Let's talk about It's now anyone that knows me knows I'm not a huge fan of sports. but but I'm starting to come around. with the Who was doing that bundle we can get ESPN Hulu? <mark>And</mark> what's the other one? It's Bo Disney. You can wrap that all up for just one, you know some per month. <mark>And</mark> it's been good. I've actually been to watch I've been going back <mark>and</mark> watching all the old UFC fights which is actually gotten me excited for who is it you all Romero <mark>and</mark> who is it this Saturday or not? That's the seventh all of its. That's Saturday or Friday, but I think the title shot <mark>And</mark> I actually really excited to watch that. <mark>And</mark> I don't know if that's pay-per-view or not. So I'm either going to go somewhere <mark>and</mark> watch it", "Start Time (s)": 529.3, "End Time (s)": 648.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Most of you know, I'm not into sports games though. I did play to k-19 <mark>and</mark> be a <mark>and</mark> that was really fun. So speaking of sports. Let's talk about It's now anyone that knows me knows I'm not a huge fan of sports. but but I'm starting to come around. with the Who was doing that bundle we can get ESPN Hulu? <mark>And</mark> what's the other one? It's Bo Disney. You can wrap that all up for just one, you know some per month. <mark>And</mark> it's been good. I've actually been to watch I've been going back <mark>and</mark> watching all the old UFC fights which is actually gotten me excited for who is it you all Romero <mark>and</mark> who is it this Saturday or not? That's the seventh all of its. That's Saturday or Friday, but I think the title shot <mark>And</mark> I actually really excited to watch that. <mark>And</mark> I don't know if that's pay-per-view or not. So I'm either going to go somewhere <mark>and</mark> watch it or watch it at home on the ESPN. Plus I don't know what fights aren't pay-per-view. It's probably figure that out from just sitting with my dick in my hand looking at the TV while Warden coming on. It's what you don't want. Where's my Red Bull? Here we go. Let's see. What else what else is going on? I don't know. I'm only 11 minutes in. I don't really know I'm trying to this will be the Test episode. This will just be to figure out first of all anyone listen to this. Let me know if it sounds good. I got to make sure the sound levels are good. Excuse me. I promise next time I'm not going to have my throat all fucked up <mark>and</mark> creepy but <mark>and</mark> I don't know if I'm eventually I would love to have people like", "Start Time (s)": 583.5, "End Time (s)": 701.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Saturday or not? That's the seventh all of its. That's Saturday or Friday, but I think the title shot <mark>And</mark> I actually really excited to watch that. <mark>And</mark> I don't know if that's pay-per-view or not. So I'm either going to go somewhere <mark>and</mark> watch it or watch it at home on the ESPN. Plus I don't know what fights aren't pay-per-view. It's probably figure that out from just sitting with my dick in my hand looking at the TV while Warden coming on. It's what you don't want. Where's my Red Bull? Here we go. Let's see. What else what else is going on? I don't know. I'm only 11 minutes in. I don't really know I'm trying to this will be the Test episode. This will just be to figure out first of all anyone listen to this. Let me know if it sounds good. I got to make sure the sound levels are good. Excuse me. I promise next time I'm not going to have my throat all fucked up <mark>and</mark> creepy but <mark>and</mark> I don't know if I'm eventually I would love to have people like send me topics or questions that there are looking for input on or some comedic advice on something funny. I don't know. I was thinking maybe this would supplement. Like I said my posts on other social media platforms. I can go more in depth of what I was thinking on a post. Let's be honest if I was to sit there <mark>and</mark> try to type out everything that was on my mind beyond the fucking face books all day. Oh my god, dude, you really all you do is sit there. You don't have any time shut the fuck up. You know, I can't get a fucking stand people like that. Don't you think better do time? No, I don't know. I fucking clean cars part-time <mark>and</mark> then I kind then I do what turn on the Xbox. Yeah in between then. I write shit to piss people", "Start Time (s)": 633.9, "End Time (s)": 753.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I promise next time I'm not going to have my throat all fucked up <mark>and</mark> creepy but <mark>and</mark> I don't know if I'm eventually I would love to have people like send me topics or questions that there are looking for input on or some comedic advice on something funny. I don't know. I was thinking maybe this would supplement. Like I said my posts on other social media platforms. I can go more in depth of what I was thinking on a post. Let's be honest if I was to sit there <mark>and</mark> try to type out everything that was on my mind beyond the fucking face books all day. Oh my god, dude, you really all you do is sit there. You don't have any time shut the fuck up. You know, I can't get a fucking stand people like that. Don't you think better do time? No, I don't know. I fucking clean cars part-time <mark>and</mark> then I kind then I do what turn on the Xbox. Yeah in between then. I write shit to piss people off. That logic never doesn't make any sense. All you do is sit on Facebook. The average status takes about what? ten seconds say I make 20 statuses a day. That's only two minutes out of my day though. I guess the responding <mark>and</mark> all that stuff. I guess that would take advance. I look forward to that shitty sharpen on my toes. I've had people come to me about my Facebook before <mark>and</mark> said you have a lot of fucking weirdos on there. How are you friends that have these people listen, I don't want friends that are exactly like me. I think that's boring as fuck. Just to hang out with a bunch of Dan's all day or to bounce ideas off of a bunch of Dan's all day. Yeah, I don't feel like you can grow that way. I feel like you do grow through opposition. So if I post something <mark>and</mark> I have a good chunk of my Facebook that are against it or they're going to try to put me in my place on", "Start Time (s)": 687.8, "End Time (s)": 807.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "time? No, I don't know. I fucking clean cars part-time <mark>and</mark> then I kind then I do what turn on the Xbox. Yeah in between then. I write shit to piss people off. That logic never doesn't make any sense. All you do is sit on Facebook. The average status takes about what? ten seconds say I make 20 statuses a day. That's only two minutes out of my day though. I guess the responding <mark>and</mark> all that stuff. I guess that would take advance. I look forward to that shitty sharpen on my toes. I've had people come to me about my Facebook before <mark>and</mark> said you have a lot of fucking weirdos on there. How are you friends that have these people listen, I don't want friends that are exactly like me. I think that's boring as fuck. Just to hang out with a bunch of Dan's all day or to bounce ideas off of a bunch of Dan's all day. Yeah, I don't feel like you can grow that way. I feel like you do grow through opposition. So if I post something <mark>and</mark> I have a good chunk of my Facebook that are against it or they're going to try to put me in my place on something. I love that keeps you on your toes keeps you sharp keeps your good to go. <mark>And</mark> it is what it is. Let's see here. But yeah, I think I'm going to Release these every Monday. I don't know if I'll wait because it's what should I date these podcasts to? I should date him shouldn't I like hey, this is Dan with such <mark>and</mark> such <mark>and</mark> that's you know, Wednesday October 37th 2025. What's today? What's today, March March night. So today's March 9th. It's a Wednesday. I don't know if I'll release this <mark>and</mark> I'll wait till next Monday or if I'll just upload it now just to kind of get you know, the canary in a coal mine.", "Start Time (s)": 742.9, "End Time (s)": 862.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "bounce ideas off of a bunch of Dan's all day. Yeah, I don't feel like you can grow that way. I feel like you do grow through opposition. So if I post something <mark>and</mark> I have a good chunk of my Facebook that are against it or they're going to try to put me in my place on something. I love that keeps you on your toes keeps you sharp keeps your good to go. <mark>And</mark> it is what it is. Let's see here. But yeah, I think I'm going to Release these every Monday. I don't know if I'll wait because it's what should I date these podcasts to? I should date him shouldn't I like hey, this is Dan with such <mark>and</mark> such <mark>and</mark> that's you know, Wednesday October 37th 2025. What's today? What's today, March March night. So today's March 9th. It's a Wednesday. I don't know if I'll release this <mark>and</mark> I'll wait till next Monday or if I'll just upload it now just to kind of get you know, the canary in a coal mine. This will be the canary In a Coal Mine episode <mark>and</mark> I can iron out the details from here. So we'll see but yeah, that's it. I'm gonna log it off from here. I know this is only like 15 minutes long. Which isn't a long in the grand scheme of things, I didn't realize how hard it was to ramble bullshit for an hour half hour. All that shit. So but I guess when you have people you can sit <mark>and</mark> talk <mark>and</mark> shoot the shit with I guess it's probably easier because Lord knows I mean should I've listened to many podcast. Shout out to JRE for the hours of podcast. Let's do also shout-out to the deuce from Cleveland. No, no one except these guys is going to get this reference but there's a podcast I listened to start listening to <mark>and</mark> I was 14 years old called video game news radio", "Start Time (s)": 794.8, "End Time (s)": 914.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's a Wednesday. I don't know if I'll release this <mark>and</mark> I'll wait till next Monday or if I'll just upload it now just to kind of get you know, the canary in a coal mine. This will be the canary In a Coal Mine episode <mark>and</mark> I can iron out the details from here. So we'll see but yeah, that's it. I'm gonna log it off from here. I know this is only like 15 minutes long. Which isn't a long in the grand scheme of things, I didn't realize how hard it was to ramble bullshit for an hour half hour. All that shit. So but I guess when you have people you can sit <mark>and</mark> talk <mark>and</mark> shoot the shit with I guess it's probably easier because Lord knows I mean should I've listened to many podcast. Shout out to JRE for the hours of podcast. Let's do also shout-out to the deuce from Cleveland. No, no one except these guys is going to get this reference but there's a podcast I listened to start listening to <mark>and</mark> I was 14 years old called video game news radio was the first podcast I ever listen to a bunch of Dudes from Ohio all of which I'm friends with on Facebook <mark>and</mark> still chat with comment with regularly on their fucking awesome dudes. They're the ones that got me into the whole podcast thing the first podcast will ever listen to <mark>and</mark> I still listen to the old repeats. I don't make the episodes anymore, but I supposed to have the old repeats. I would say almost daily. So shout out to them. Yeah for making it look so fucking effortless to just sit there <mark>and</mark> be able to ramble on bullshit for as long as you guys did so All right, I'm signing off. If you have any questions or comments anything I can do to improve the show. Let me know <mark>and</mark> we will talk to you later. Alright, bye.", "Start Time (s)": 852.2, "End Time (s)": 964.7, "Clip Length (min)": 1.88, "show_uri": "spotify:show:0cco773WzL89DSXuY0wJwd", "show_name": "Breakfast With Perkins ", "show_description": "Listen to a guy from Iowa babble bullshit about everyday life! ", "publisher": "Dan Perkins", "episode_uri": "spotify:episode:2bA3SdEDHSWpbpX4BL5TUf", "episode_name": "Episode 1 - Granite City Closed?! 3/3/2020 ", "episode_description": "1st episode of the podcast! I talk talk about gaming, food, and kinda what to expect from the podcast ", "score": 6.7105885, "explanation": "{\n  \"value\": 6.7105885,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.1576812,\n      \"description\": \"weight(word_list:joe in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1576812,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5529075,\n      \"description\": \"weight(word_list:rogan in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5529075,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.324866,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4.892827e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.892827e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 445) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=54.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6267846,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 54.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.77195835,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2328.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This podcast is based on the events that have occurred in the past <mark>and</mark> is intended to communicate such events to the public in a dramatic manner any reference to artificial or natural person place caste Community race religion is factual in nature <mark>and</mark> is not intended to offend or defame as such all reporting is based on the sequence of events reported to the public <mark>and</mark> does not constitute an opinion statement or recommendation by Spotify artist producer or any of their employees. Ploys newscaster bites have been recreated for dramatic purposes. Listener discretion is advised. Hi, my name is Sue darshan. This is the big fat Indian catala a Spotify original produced by automatic.", "Start Time (s)": 0.2, "End Time (s)": 45.0, "Clip Length (min)": 0.75, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "How are you? I got it goes on more episode a book on his company you doin I sucks Cooper her just go home. India got Pablo Escobar has acted. Well narcos Allah the true narcos me Wallace in just make room. Hey or who make chair paper a blue Bat Away. Hmm, or to to zoom out card Pablo say you can take $10 also more per category or sorry dollars or Schumacher dollars. He dollars Adora radula up to simcha Indian version. Soon. Okay, one two dollars <mark>and</mark> huh Indian rupee May convert biomass. Okay to zoom in Carthage. Ah-huh. Boost your people to bundle but I assume in car. Okay, what's wrong me who's chair Page open debate ahead. I bought suspense will get del d but Arkham By Thai Abdul Kareem take more than India's biggest scam the Kingpin of the multi-thousand crowd stamp papers Camp overshadowing harshad Mehta. Stop fraud Abdul Karim. Lala also have Dengue genotype or oh, so you're talking about The stamp paper go tala would done by that Allah Allah, right look into Joe's Car nickname. Kavitha. Your everybody knows about him. I guess actually, you know methanol borrow much about Cartagena. In fact, I remember article job in yoga seed dance bar Omega Grand roadway or waffles no could do with inventive o'clock report. I possess", "Start Time (s)": 74.0, "End Time (s)": 170.8, "Clip Length (min)": 1.61, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "figure nickel chaos Again by the couch. Look at the official sources. Voltaic bees are karateka got Oliver but both reports as a huh. Use my car has a clock a clock on stamp paper the parts of this me. Sort of a those who personally stamp paper Dakota or mu J. Select a de quien Esta Noche extended version a currency Comet lab just machine wash up. Then I was image image of the alga or is people some looks I'm Curtis. I was tryna dick stamp paper thoracic. Technically, huh? Sarkar. Cacao Tai Chi just be deal Kobe transaction other stamp paper paper to government will vouch for it. What's up, Sir car can be granny. May we hear or apis? My mother who never oppose document could occur with case was solved constructeam each module. Body Beast <mark>and</mark> paper booty but to Jon caramanica kiss me as it does to Pakistan people like that Shadi me or maximum value continue these damn people. He article K subsets does to pay a minimum of patchy cigars we have with maximum purchase. Josh was Sub C valuable stamp paper. Are you print out I am I buy a jug currency print with a gnostic my Indian security pressure. Mmm jokey specifically government's related documents including stamp papers is a printed 33 passport be vibrant with them Archer take up to jogger see this about how to Kobe transaction who Who's transaction Cooper Geo tags photoes a war government in stamp papers get through college 3000 told him that loved us Loop a rubber stamp paper game sales tax the right tax be or feasts be his back. If he's very bad way just a key to not trip up a new Gamez ability <mark>and</mark> the purpose of Portugal towards the mean kakizaki a copy to garment Naki Acres security house transaction key government was document code. Maintain the", "Start Time (s)": 200.7, "End Time (s)": 320.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "print with a gnostic my Indian security pressure. Mmm jokey specifically government's related documents including stamp papers is a printed 33 passport be vibrant with them Archer take up to jogger see this about how to Kobe transaction who Who's transaction Cooper Geo tags photoes a war government in stamp papers get through college 3000 told him that loved us Loop a rubber stamp paper game sales tax the right tax be or feasts be his back. If he's very bad way just a key to not trip up a new Gamez ability <mark>and</mark> the purpose of Portugal towards the mean kakizaki a copy to garment Naki Acres security house transaction key government was document code. Maintain the correct year a cha to make Love Shah diesel acre Garden is a Laker Coy Duke of nigga merger you do. Sorry stamp papers for who they do is kill copy government capacity for the evidence, right? Exactly. Correct where someone will take doubt it. Yay, <mark>Joe</mark> does Rebecca stamp paper? I also patches are his stamp paper edge of my is value, but I think people quality make a difference with the again. My name is up same with a model of sorry stamp papers Jubilee the Serpico Apaches are Cow Monkey printing price same. Bye. To dinner stamp paper go tale capoeira Source image layer key raw material with Anika here. I was a profit margin right up here by Johan sarkar Colour Abdul Karim You are a meth addict.", "Start Time (s)": 275.6, "End Time (s)": 375.2, "Clip Length (min)": 1.66, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "papers Jubilee the Serpico Apaches are Cow Monkey printing price same. Bye. To dinner stamp paper go tale capoeira Source image layer key raw material with Anika here. I was a profit margin right up here by Johan sarkar Colour Abdul Karim You are a meth addict. Buddha brahmanas rakia shiny see that is a movie like talking to Lala Theory modern Time cake, <mark>and</mark> I'm in Kabul currently in closed loop. All Candor. Bots are a passe or possibilities. The QE exactly other is police camp with chesky game contradict a hunter is game color vision on that LG Matlab was moved checkmater a bite Cheska game sommelier. Some jokes. Napela move Casey kiyah kiyah kiyah kiyah Shruti. Mumbai say that the first movement calculus name key. Do you stamp papers Ott? Also go wash my brand new body. Take me take me take me away. Company shares currently how to work with people pay you can stamp a perpetually", "Start Time (s)": 344.0, "End Time (s)": 463.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "game contradict a hunter is game color vision on that LG Matlab was moved checkmater a bite Cheska game sommelier. Some jokes. Napela move Casey kiyah kiyah kiyah kiyah Shruti. Mumbai say that the first movement calculus name key. Do you stamp papers Ott? Also go wash my brand new body. Take me take me take me away. Company shares currently how to work with people pay you can stamp a perpetually corrupted it Nature's up to him. Okay. I've never shared slap. No, whoosh. Here's the killer could be HD, obviously Abdul Kareem of a larger part by a cardiologist <mark>and</mark> paper towel to use this over here. So as they hear the last we have Mumbai people happy, you know, kabaddi kabaddi passes stamp papers immediately. They will give me a spot cure or they'll give your vehicle body about papers rocker <mark>and</mark> go wash Kirk a brand new car keep Disney leather or by jvcom can delegate from to come connector office. To China or is silly a mostly Mumbai keep primary amine Trademark Office billion. I can't believe Kyoko o'clock hooker. OK scam survey said chemicals <mark>and</mark> okay paper cooker set a couch or B K. Omega is game Kaiser level to be for our Ghana. Of course. Donna is game called level to the yeah, Javi damn papers co-wash. Katana was trying to say is Kim Lockett eight Indian Security Plus KX employee or OSX employ in a husky. Malekith present employees. Say chi chi. Would you present employees the woods Calculate the stamp paper Muslim XR carry office mean there's our Curry comes our car cane our konichiwa Radha Lincoln by a history real knock anything", "Start Time (s)": 412.1, "End Time (s)": 528.8, "Clip Length (min)": 1.94, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Push the markets a gibe garage. Leukorrhea, India, Kenya Sonic ethnicity is me. Japan in stamp papers got demand Ott. Mojave is stamp papers vegetative or Matlab sarkari stamp paper me clay or Puccini X star. Gary document Rostrum is a guy who got the ball to very much aware. read all across the country must locate any sorry Cher who giveth coronavirus one yard agents say they arrested key butter cities <mark>and</mark> towns my family with him to mclendon-covey multi-ton covid anybody to be covid Mota commissioned a report about the veto a bill cool logo key institutions key brand value be right Colonel Jesse key about whatever institutions work with our allies you ho Gaya SBI ho Gaya the Bombay Stock Exchange via Java SE buddy company or capacity to occupy less apathetic. Discount Ms. Data or till he of course 5% discount data model of a core. Java hundred rupees case stamp paper Kelly. Sarkar. Co-op core 97", "Start Time (s)": 646.7, "End Time (s)": 766.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Cut Kolkata KX sarkari stamp paper vendors, yui module why Joe's our character of Saku stamp paper DT or vasya is cool idea. Jolly stamp paper car Matlab is poor a multi-billion. Got a leak in Neve. It jail Mercury till geekycon Eco Hindi film features a come the he x sub Z value in a separate dish could be cesare caricature, ligaya Pella 4z passport banana zika or fear high security printing press paper liquor first this time paper tape. LG kajal make ribs or anything. So student first guy <mark>Joe</mark> Pradesh. May he forgive time paper based on a negligee ROV a kit lgk Network. May trees are a police officer or nativism is a foot chase case game. Maybe I don't have any charge hourly or is necessary gear. Sorry, <mark>Joe</mark> was here. I would have become really a unique example if there is a cool chick apparently boss. Radha to be described as a possible by I don't think a brassiere Olga. Yeah, take two key Point here. Will ya Jessica game could be a clinical data to a tariff a girl to do sweetheart Magnus Carlsen be total Air Battle Gary Kasparov you Magnum Magnus Carlsen number one to fill all oh my God current affairs can equal call is in the give it a little Macabre say sriram raghavan who like twister IQ snake oil? Yay. You", "Start Time (s)": 877.6, "End Time (s)": 969.9, "Clip Length (min)": 1.54, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "up a recording who Yogi is quoted as evidence Leona quote me, right Bill cool. Soulless all Kentucky conversation record with it or in some corsetry. Alex CDs were recorded their coat my PhD I gather bye-bye. Germany YouTube has Abdul Karim teletype cricketer. The Narco test. The smoke is leaking finally year without his chest. You know that is Jessica game kabaddi interesting <mark>and</mark> do a lapel iwasawa acreage on appear on a keyboard Monte game could give up cardia the El Chico. Those are soft musk. Even advice key item Kabul. Oh totally naked made a cursory guilty applicable lie or Courtney's Ohio's Cote sulky subsidy or southeast Asia dodoka find another housekeeper subset interesting. But yeah other would also dokuro Define a data to see suggestive themes are lower but the Iana get 20 Sal Quixote looking at now is a pastime. Anita John DiMaggio potagooo stymie report baracci. Those are sad. Zeppeli kept dual-core Intel. He's HIV positive. Yeah surface iv+ me but I look at diabetes with hypertension beta in his Reb Mario clicker to Bangalore Julia or philosophical lot bigger the Cisco Bangalore. Okay, Victoria Hospital a jagga. Jasoos key death, we in the year 2017. Okay. So finally Abdul Kareem tell you go. Sahaja Yogi, he's no more Laguna Seca, Isabella, every government of Indiana is a stamp paper. M Google or is a markup. I", "Start Time (s)": 1271.8, "End Time (s)": 1391.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "At is to commemorate camera was on the skateboard. Ninety eight. Megabytes of Moodle passage alarm Michael Cutter. You were listening to the big fat Indian. Go tala a Spotify original produced by Audio Matic producers for audio Matic Rajesh the hill <mark>and</mark> of dude Conover home. Advice sudarshan Paris <mark>and</mark> emit. Oh Padre scripted by a methodical researched by saloni meghani assistant producers sahil shop area <mark>and</mark> Rahul besoin original title music an advanced aha episode sound design mix <mark>and</mark> master an urban Saga.", "Start Time (s)": 1443.8, "End Time (s)": 1520.0, "Clip Length (min)": 1.27, "show_uri": "spotify:show:0TbZLEvRcQNoFzWQFHddJ1", "show_name": "The Big Fat Indian Ghotala", "show_description": "Spotify Studios presents The Big Fat Indian Ghotala, an Original Podcast series that delves into the scams a.k.a ghotalas from across the Indian spectrum ranging from call-centre scams to banking scams. This show attempts to voice the frustration faced by middle-class India by cataloging the scale and\u00a0seriousness of the crimes but through a lens of satire.", "publisher": "Spotify Studios", "episode_uri": "spotify:episode:4ZH14XkcgkqKt3kZd91e9e", "episode_name": "Paison ki Printing Press", "episode_description": "On this episode of The Big Fat Indian Ghotala, a look into the history of a case that baffled the nation, the stamp paper scam. Featuring a man named Lala and a chase akin to a scene from a Bollywood thriller.\u00a0", "score": 6.422756, "explanation": "{\n  \"value\": 6.422756,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.045872,\n      \"description\": \"weight(word_list:joe in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.045872,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9296396,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 8.46459e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 8.46459e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:and in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.22971934,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.030978117,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.030978117,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.3768845,\n      \"description\": \"weight(word_list:musk in 131) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.3768845,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}]}